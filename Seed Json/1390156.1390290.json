{
  "pdf": "1390156.1390290",
  "title": "1390156.1390290",
  "author": "Unknown",
  "paper_id": "1390156.1390290",
  "text": "Training Restricted Boltzmann Machines using Approximations to\nthe Likelihood Gradient\nTijmen Tieleman tijmen@cs.toronto.edu\nDepartment of Computer Science, University of Toronto, Toronto, Ontario M5S 3G4, Canada\nAbstract\nA new algorithm for training Restricted\nBoltzmann Machines is introduced. The al-\ngorithm, named Persistent Contrastive Di-\nvergence, is diﬀerent from the standard Con-\ntrastive Divergence algorithms in that it\naims to draw samples from almost exactly\nthe model distribution. It is compared to\nsome standard Contrastive Divergence and\nPseudo-Likelihood algorithms on the tasks\nof modeling and classifying various types of\ndata. The Persistent Contrastive Divergence\nalgorithm outperforms the other algorithms,\nand is equally fast and simple.\n1. Introduction\nRestricted Boltzmann Machines (RBMs) (Hinton\net al., 2006; Smolensky, 1986) are neural network mod-\nels for unsupervised learning, but have recently seen a\nlot of application as feature extraction methods for\nsupervised learning algorithms (Salakhutdinov et al.,\n2007; Larochelle et al., 2007; Bengio et al., 2007;\nGehler et al., 2006; Hinton et al., 2006; Hinton &\nSalakhutdinov, 2006). The success of these models\nraises the issue of how best to train them.\nMost training algorithms are based on gradient de-\nscent, but the standard objective function (training\ndata likelihood) is intractable, so the algorithms dif-\nfer in their choice of approximation to the gradient\nof the objective function. At present, the most pop-\nular gradient approximation is the Contrastive Diver-\ngence (CD) approximation (Hinton et al., 2006; Hin-\nton, 2002; Bengio & Delalleau, 2007); more speciﬁ-\ncally the CD-1 approximation. However, it is not ob-\nvious whether it is the best. For example, the CD\nalgorithm has a parameter specifying the number of\nAppearing in Proceedings of the 25 th International Confer-\nence on Machine Learning , Helsinki, Finland, 2008. Copy-\nright 2008 by the author(s)/owner(s).\nMarkov Chain transitions performed, and although\nthe most commonly chosen value is 1, other choices\nare possible and reasonable, too (Carreira-Perpinan &\nHinton, 2005).\nIn this paper, a new gradient approximation algorithm\nis presented and compared to a variety of CD-based al-\ngorithms. The quantitative measures of test data like-\nlihood (for unsupervised learning) and classiﬁcation\nerror rate (for supervised learning) are investigated,\nand the type of feature detectors that are developed\nare also shown. We ﬁnd that the new algorithm pro-\nduces more meaningful feature detectors, and outper-\nforms the other algorithms.\nThe RBMs on which these experiments were done all\nhad binary units. However, this special case can easily\nbe generalized to other harmoniums (Smolensky, 1986;\nWelling et al., 2005) in which the units have Gaussian,\nPoisson, multinomial, or other distributions in the ex-\nponential family, and the training algorithms described\nhere require only minor modiﬁcations to work in most\nof those models.\nIn Section 2, the RBM model and CD gradient es-\ntimator are discussed. In Section 3, the Persistent\nContrastive Divergence algorithm is introduced. In\nSections 4 and 5, the experiments and results are de-\nscribed, and Section 6 concludes with a discussion and\nsome plans for future work.\n2. RBMs and the CD Gradient\nApproximation\n2.1. Restricted Boltzmann Machines\nAn RBM is an energy-based model for unsupervised\nlearning (Hinton, 2002; Smolensky, 1986). It consists\nof two layers of binary units: one visible, to represent\nthe data, and one hidden, to increase learning capac-\nity. Standard notation is to use i for indices of visible\nunits, j for indices of hidden units, and wij for the\nstrength of the connection between the ith visible unit\nand the jth hidden unit. If vi denotes the state of the\n1064\n\nT raining Restricted Boltzmann Machines using Approximations t o the Likelihood Gradient\nith visible unit, and hj denotes the state of the jth\nhidden unit, an energy function is deﬁned on states:\nE(v, h) = − ∑\ni,j vihjwij − ∑\ni vibi − ∑\nj hjbj, where b\nstands for the biases. Through these energies, proba-\nbilities are deﬁned as P (v, h) = e−E(v,h)\nZ where Z is the\nnormalizing constant Z = ∑\nx,y e−E(x,y). The proba-\nbility of a data point (represented by the state v of\nthe visible layer) is deﬁned as the marginal: P (v) =\n∑\nh P (v, h) =\nP\nh e−E(v,h)\nZ . Thus, the training data\nlikelihood, using just one training point for simplicity,\nis φ = log P (v) = φ+−φ− where φ+ = log ∑\nh e−E(v,h)\nand φ− = log Z = log ∑\nx,y e−E(x,y). The positive gra-\ndient ∂φ+\n∂wij\nis simple: ∂φ+\n∂wij\n= vi · P (hj = 1 |v). The\nnegative gradient ∂φ−\n∂wij\n= P (vi = 1 , hj = 1), however,\nis intractable. If we could get samples from the model,\nwe could Monte Carlo approximate it, but even getting\nthose samples is intractable.\n2.2. The Contrastive Divergence Gradient\nApproximation\nTo get a tractable approximation of ∂φ−\n∂wij\n, one uses\nsome algorithm to approximately sample from the\nmodel. The Contrastive Divergence (CD) algorithm\nis one way to do this. It is designed in such a way\nthat at least the direction of the gradient estimate is\nsomewhat accurate, even when the size is not. CD-1\nis, at present, the most commonly used algorithm for\ntraining RBMs. One of the algorithms we compare\nis regular CD-1; another is CD-10, which is generally\nconsidered to be better if the required computer time\nis available.\nA variation on CD is mean ﬁeld CD (Welling & Hinton,\n2002), abbreviated MF CD. This has the advantage of\nbeing a deterministic gradient estimate, which means\nthat larger learning rates can be used. We include\nmean ﬁeld CD-1 in the comparison.\n3. The Persistent Contrastive\nDivergence Algorithm\nCD-1 is fast, has low variance, and is a reasonable\napproximation to the likelihood gradient, but it is\nstill signiﬁcantly diﬀerent from the likelihood gradi-\nent when the mixing rate is low. This can be seen by\ndrawing samples from the distribution that it learns\n(see Figure 4). Generally speaking, CD- n for greater\nn is preferred over CD-1, if enough running time is\navailable. In Neal’s 1992 paper about Sigmoid Belief\nNetworks (1992), a solution is suggested for such situ-\nations. In the context of RBMs, the idea is as follows\n(see also (Yuille, 2004)).\nWhat we need for approximating ∂φ−\n∂wij\nis a sample from\nthe model distribution. The standard way to get it\nis by using a Markov Chain, but running a chain for\nmany steps is too time-consuming. However, between\nparameter updates, the model changes only slightly.\nWe can take advantage of that by initializing a Markov\nChain at the state in which it ended for the previ-\nous model. This initialization is often fairly close to\nthe model distribution, even though the model has\nchanged a bit in the parameter update. Neal uses\nthis approach with Sigmoid Belief Networks to approx-\nimately sample from the posterior distribution over\nhidden layer states given the visible layer state. For\nRBMs, the situation is a bit simpler: there is only one\ndistribution from which we need samples, as opposed\nto one distribution per training data point. Thus, the\nalgorithm can be used to produce gradient estimates\nonline or using mini-batches, using only a few train-\ning data points for the positive part of each gradient\nestimate, and only a few ’fantasy’ points for the nega-\ntive part. The fantasy points are updated by one full\nstep of the Markov Chain each time a mini-batch is\nprocessed.\nOf course this still is an approximation, because the\nmodel does change slightly with each parameter up-\ndate. With inﬁnitesimally small learning rate it be-\ncomes exact, and in general it seems to work best with\nsmall learning rates.\nWe call this algorithm Persistent Contrastive Diver-\ngence (PCD), to emphasize that the Markov Chain is\nnot reset between parameter updates.\n4. Experiments\nWe did a variety of experiments, using diﬀerent data\nsets (digit images, emails, artiﬁcial data, horse image\nsegmentations, digit image patches), diﬀerent models\n(RBMs, classiﬁcation RBMs, fully visible Markov Ran-\ndom Fields), diﬀerent training procedures (PCD, CD-\n1, CD-10, MF CD, pseudo likelihood), and diﬀerent\ntasks (unsupervised vs. supervised learning).\n4.1. Data Sets\nThe ﬁrst data set that we used was the MNIST dataset\nof handwritten digit images (LeCun & Cortes, ). The\nimages are 28 by 28 pixels, and the data set consists\nof 60,000 training cases and 10,000 test cases. To have\na validation set, we split the oﬃcial training set of\n60,000 cases into a training set of 50,000 cases and a\nvalidation set of 10,000 cases. To have binary data, we\ntreat the pixel intensities as probabilities. Each time a\nbinary data point is required, a real-valued MNIST im-\n1065\nT raining Restricted Boltzmann Machines using Approximations t o the Likelihood Gradient\nage is binarized by sampling from the given Bernoulli\ndistribution for each pixel. Thus, in eﬀect, our data\nset is a mixture of 70,000 factorial distributions: one\nfor each of the data points in the MNIST data set.\nAnother data set was obtained by taking small patches\nof 5 by 5 pixels, from the MNIST images. To\nhave somewhat smooth-looking data, we binarized by\nthresholding at 1/2. The 70,000 MNIST data points\nwere thus turned into 70,000 times (28 − 5 + 1) 2 is\n4,032,000 patches. This data set was split into train-\ning (60%), validation (20%), and test (20%) sets.\nA data set consisting of descriptions of e-mails was\nmade available by Sam Roweis. It describes 5,000 e-\nmails using a variety of binary features - mostly word\npresence vs. absence features. The e-mails are labeled\nas spam or non-spam.\nAn artiﬁcial data set was created by combining the\noutlines of rectangles and triangles. Because this data\nset is artiﬁcially generated, there is an inﬁnite amount\nof it, which helps shed some light on the reasons for\nusing weight decay regularization.\nLastly, we used a data set of image segmentations: in\npictures of horses, the segmentation indicates which\npixels are part of the horse and which are background\n(Borenstein et al., 2004). By using only the segmen-\ntation, we have a binary data set.\n4.2. Models\nThe ﬁrst model we used is an RBM, exactly as de-\nscribed above. For the MNIST and horse segmentation\ndata sets, we used 500 hidden units; for the artiﬁcial\ndata set we used 100.\nOne of the evaluations is how well the learned RBM\nmodels the test data, i.e. log likelihood. This is in-\ntractable for regular size RBMs, because the time com-\nplexity of that computation is exponential in the size\nof the smallest layer (visible or hidden). One experi-\nment, therefore, was done using only 25 hidden units,\nso that log likelihood could be calculated exactly in\nabout two hours. Another experiment uses an approxi-\nmate assessment of the normalization constant Z, that\nwas developed recently in our group (Salakhutdinov &\nMurray, 2008). This algorithm works for any num-\nber of hidden units, but its reliability has not been\nresearched extensively. Nonetheless, it seems to give a\nreasonable indication, and can be used to complement\nother results.\nRBMs, however, are models for unsupervised learning,\nso for classiﬁcation we used a slightly diﬀerent model,\ndescribed in more detail in (Hinton et al., 2006). We\nused an RBM with one added visible unit, which rep-\nresented the label. The training data points are then\ncombinations of inputs with their labels, and testing\nis done by choosing the most likely label given the in-\nput, under the learned model. This model we call a\n’classiﬁcation RBM’. Note that the label unit is not\nnecessarily binary (although in the spam classiﬁcation\ntask it is). In the MNIST classiﬁcation task it is multi-\nnomial: it can have 10 diﬀerent values. This, however,\ndoes not signiﬁcantly change the algorithms (Hinton,\n2002). For MNIST classiﬁcation we used 500 hidden\nunits; for spam classiﬁcation we used 100.\nThe third model we tested is signiﬁcantly diﬀer-\nent: a fully visible, fully connected Markov Ran-\ndom Field (MRF) (see for example (Wainwright &\nJordan, 2003)). One can use the PCD algorithm\non it, although it looks a bit diﬀerent in this case.\nWe compared its performance to the more commonly\nused Pseudo-Likelihood optimization algorithm (Be-\nsag, 1986). To have exact test data log likelihood mea-\nsurements, we used small models, with only 25 units.\n4.3. The Mini-batch Optimization Procedure\nWe used the mini-batch learning procedure: we only\nused a small number of training points for each gra-\ndient estimate. We used 100 training points in each\nmini-batch for most data sets.\n4.4. Algorithm Details\nThe PCD algorithm can be implemented in various\nways. One could, for example, choose to randomly\nreset some of the Markov Chains at regular intervals.\nInitial tests showed that the best implementation is as\nfollows: no Markov Chains get reset; one full Gibbs\nupdate is done on each of the Markov Chains for each\ngradient estimate; and the number of Markov Chains\nis equal to the number of training data points in a\nmini-batch.\nPCD for fully visible MRFs is a bit diﬀerent from PCD\nfor RBMs. A pleasant diﬀerence is that ∂φ+\n∂θ is con-\nstant, so it can be precomputed for the entire training\nset. Thus, no variance results from the use of mini-\nbatches, and the training set can be discarded after\n∂φ+\n∂θ is computed over it. An unpleasant diﬀerence is\nthat the Markov Chain deﬁned by Gibbs sampling has\nslower mixing: MRFs with connections between the\nvisible units lack the pleasant property of RBMs that\nall visible units can be updated at the same time.\nA Pseudo-Likelihood (PL) gradient computation re-\nquires more work than a PCD gradient computation,\nbecause it requires a logistic regression gradient esti-\n1066\nT raining Restricted Boltzmann Machines using Approximations t o the Likelihood Gradient\nmate for each of the units. As a result, we found that\nusing mini-batches of 50 training points instead of 100\ntook only a little bit more time per training point,\nand did allow updating the model parameters almost\ntwice as often, which is preferable in the mini-batch\noptimization procedure.\n4.5. Other T echnical Details\nThe learning rates used in the experiments are not\nconstant. In practice, decaying learning rates often\nwork better. In these experiments, the learning rate\nwas linearly decayed from some initial learning rate to\nzero, over the duration of the learning. Preliminary\nexperiments showed that this works better than the\n1\nt schedule suggested in theoretical work by (Robbins\n& Monro, 1951), which is preferable when inﬁnitely\nmuch time is available for the optimization.\nSome experiment parameters, such as the number of\nhidden units, and the size of the mini-batches, were\nﬁxed. However, the initial learning rate was chosen\nusing a validation set, as was weight decay for the\n(shorter) experiments on the spam, horses, MNIST\npatches, and artiﬁcial data sets. For each algorithm,\neach task, and each training duration, 30 runs were\nperformed with evaluation on validation data, trying\nto ﬁnd the settings that worked best. Then a choice of\ninitial learning rate and, for the shorter experiments,\nweight decay, were made, and with those chosen set-\ntings, 10 more runs were performed, evaluating on test\ndata. This provided 10 test performance numbers,\nwhich were summarized by their average and standard\ndeviation (shown as error bars).\n5. Results\n5.1. The three MNIST T asks\nThe results on the three MNIST tasks are shown in\nFigures 1, 2, and 3.\nIt is clear that PCD outperforms the other algorithms.\nPCD, CD-1, and MF CD all take approximately the\nsame amount of time per gradient estimate, with MF\nCD being a little bit faster because it does not have\nto create random numbers. CD-10 takes about four\ntimes as long as PCD, CD-1, and MF CD, but it is\nindeed better than CD-1.\nWhile CD-1 is good for some purposes, it is substan-\ntially diﬀerent from the true likelihood gradient. This\ncan be seen by drawing samples from an RBM that\nwas trained with CD-1. Figure 4 shows those next to\nsamples drawn from an RBM that was trained using\nPCD. It is clear that PCD is a better approximation\n128sec 4min 8min 17min 34min 68min 2hr 4hr 9hr 18hr−170\n−165\n−160\n−155\n−150\n−145\n−140\n−135\n−130\n−125\nCD−10\nMF CD\nCD−1\nPCD\ntest data log likelihood per case\ntraining time (logarithmic)\nFigure 1. Modeling MNIST data with 25 hidden units (ex-\nact log likelihood)\n8min 17min 34min 68min 2hr 4hr 9hr 18hr 36hr 3days−125\n−120\n−115\n−110\n−105\n−100\n−95\n−90\n−85\n−80\nCD−10\nMF CD\nCD−1\nPCD\ntest data log likelihood per case\ntraining time (logarithmic)\nFigure 2. Modeling MNIST data with 500 hidden units\n(approximate log likelihood)\n1067\nT raining Restricted Boltzmann Machines using Approximations t o the Likelihood Gradient\n8min 17min 34min 68min 2hr 4hr 9hr 18hr 36hr 3days92\n93\n94\n95\n96\n97\n98\n99\nCD−10\nMF CD\nCD−1\nPCD\npercentage correctly classified\ntraining time (logarithmic)\nFigure 3. Classiﬁcation of MNIST data\n128sec 4min 8min 17min 34min 68min 2hr 4hr−70\n−65\n−60\n−55\n−50\n−45\nCD−10\nCD−1\nMF CD\nPCD\ntest data log likelihood per case\ntraining time (logarithmic)\nFigure 5. Modeling artiﬁcial data\nto the likelihood gradient.\nClassiﬁcation is a particularly interesting task because\nit gives an indication of how well the model can extract\nrelevant features from the input. RBMs are most of-\nten used as feature detectors, and this ﬁnding suggests\nthat PCD creates feature detectors that give better\nclassiﬁcation than CD-1.\n5.2. Modeling Artiﬁcial Data\nIn Figure 5 we see essentially the same as what hap-\npened on the MNIST tasks. MF CD is clearly the\nworst of the algorithms, CD-1 works better, and CD-\n10 and PCD work best, with CD-10 being preferable\nwhen little time is available and PCD being better if\nmore time is available.\n128sec 4min 8min 17min 34min 68min 2hr 4hr\n96\n96.2\n96.4\n96.6\n96.8\n97\n97.2\n97.4\n97.6\nPCD\nMF CD\nCD−1\nCD−10\npercentage correctly classified\ntraining time (logarithmic)\nFigure 6. Classifying e-mail as spam versus non-spam\nThis data set was artiﬁcially generated, so there was\nan inﬁnite amount of data available. Thus, one might\nthink that the use of weight decay serves no purpose.\nHowever, all four algorithms did work best with some\nweight decay. The explanation for this is that CD al-\ngorithms are quite dependent on the mixing rate of the\nMarkov Chain deﬁned by the Gibbs sampler, and that\nmixing rate is higher when the parameters of the model\nare smaller. Thus, weight decay keeps the model mix-\ning reasonably well, and makes CD algorithms work\nbetter. The eﬀect is strongest for MF CD, which per-\nforms only one Gibbs update and does so without in-\ntroducing noise. MF CD worked best with a weight\ndecay strength of 10 −3. CD-1 does introduce some\nnoise in the update procedure, and required less weight\ndecay: 3 · 10−4. CD-10 performs more updates, and\nis less dependent on the mixing rate. The best weight\ndecay value for CD-10 turned out to be approximately\n1.3·10−4. Finally, the mixing mechanism used by PCD\nis even better, but it is still based on the Gibbs sam-\npler, so it, too, works better with some weight decay.\nThe best weight decay strength for PCD was approx-\nimately 2 .5 · 10−5.\n5.3. Classifying E-mail Data\nIn Figure 6 the results on the e-mail classiﬁcation task\nare shown. Because this is a small data set (5,000 data\npoints in total, i.e. only 1000 test data points), we see\nthat the error bars on the performace are quite large.\nThus, we cannot carefully compare the performance of\nCD-1, CD-10, and PCD. We only see that MF CD is,\nagain, not the best method.\nHowever, we can conclude that RBMs can be used for\nthis task, too, with acceptable performance, and that\n1068\nT raining Restricted Boltzmann Machines using Approximations t o the Likelihood Gradient\nFigure 4. Samples from an RBM that was trained using PCD (left) and an RBM that was tr ained using CD-1 (right).\nClearly, CD-1 did not produce an accurate model of the MNIST digits. N otice, however, that some of the CD-1 samples\nvaguely resemble a three.\n128sec 4min 8min 17min 34min 68min 2hr 4hr\n−350\n−300\n−250\n−200\nPCD\nMF CD\nCD−1\nCD−10\ntest data log likelihood per case\ntraining time (logarithmic)\nFigure 7. Modeling horse segmentation data\nPCD is a reasonable choice of training algorithm.\n5.4. Modeling Horse Contours\nIn Figure 7 we see a diﬀerent picture: PCD is not\nthe best algorithm here. The most plausible explana-\ntion is that although the same amount of training time\nwas used, the data is much bigger: 1024 visible units,\nand 500 hidden units. Thus, there were 20 times as\nmany connections in the RBM to be learned, which\nalso means processing one mini-batch took more than\n10 times as long as for the artiﬁcial data. Thus, we\nare essentially looking at a short optimization. Above,\nwe already saw that CD-10 is better than PCD when\nlittle time is available, and that is conﬁrmed here. We\nconjecture that, given signiﬁcantly more training time,\nPCD would perform better than the other algorithms.\n5.5. PCD on F ully Visible MRFs\nTo verify that PCD also works well with other mod-\nels, we did some experiments with fully visible, fully\nconnected MRFs. To be able to have exact test data\nlikelihood evaluation, we made the MRFs small, and\nmodeled 5 by 5 pixel patches from the MNIST digit\nimages.\nPseudo-Likelihood (PL) training works reasonably\nwell on this data set, but it does not produce the best\nprobability models. Presumably this is simply because\nPL optimizes a diﬀerent objective function. As a re-\nsult, PL needed early stopping to prevent diverging\ntoo much from the data likelihood objective function,\nand the optimal learning rates are more or less in-\nversely proportional to the duration of the optimiza-\ntion. Even with only a few seconds training time, the\nbest test data likelihood is already achieved: −5.35.\nPCD training does go more in the direction of the data\nlikelihood function - asymptotically it gives its exact\ngradient. Thus, PCD did proﬁt from having more time\nto run. Figure 8 shows the performance. The asymp-\ntotic value of approximately −5.15 does seem to be\nthe best possible model: we also used exact gradient\n1069\nT raining Restricted Boltzmann Machines using Approximations t o the Likelihood Gradient\n8sec 16sec 32sec 64sec 128sec 4min 8min−5.6\n−5.55\n−5.5\n−5.45\n−5.4\n−5.35\n−5.3\n−5.25\n−5.2\n−5.15\n−5.1\nPL\nPCD\ntest data log likelihood per case\ntraining time (logarithmic)\nFigure 8. Training a fully visible MRF\noptimization (which is slow, but possible), and this\nequally ended up with test data log likelihood of −5.15.\nHowever, the entropy of the training data distribution\nis signiﬁcantly less than 5 .15 ’nats’: it is 4 .78 nats.\nThis diﬀerence is probably due to the fact that the\nmodel has insuﬃcient complexity to completely learn\nthe training data distribution.\nIncidentally, the training data log likelihood is only\n0.004 better than the test data log likelihood - pre-\nsumably because this data set is quite large and the\nmodel is quite small.\n6. Discussion and Future Work\nOne issue not investigated is the use of weight decay. It\nis quite possible that the more approximate algorithms\n(such as CD-1 and MF CD) would beneﬁt more from\nweight decay than CD-10 and PCD. In an RBM with\nzero weights, CD-1 and MF CD give exactly the like-\nlihood gradient, and in general, in RBMs with small\nweights those algorithms give better approximations\nto the likelihood gradient than in RBMs with large\nweights. Weight decay keeps the weights small, and\nthus enables gradient estimates that approximate the\nlikelihood gradient more closely. For many tasks, how-\never, large weights may be required for good perfor-\nmance, so strong weight decay is undesirable if it can\nbe avoided.\nAlso, the amount of training time used in these ex-\nperiments is insuﬃcient to ﬁnd the asymptotic per-\nformance. In Figure 3 one can see, for example, that\nPCD clearly proﬁts from more training time. To ﬁnd\nout what its performance would be with more training\ntime is future work, but we have seen runs (with more\ntraining time and more hidden units) where as few\nas 104 out of the 10,000 test cases were misclassiﬁed.\nClearly, this is worth investigating further.\nAnother issue suggesting future work is that the clas-\nsiﬁcation RBMs in these experiments were not trained\nto maximize classiﬁcation performance. They were\ntrained to accurately model the joint distribution over\nimages and labels. It is possible to train classiﬁcation\nRBMs directly for classiﬁcation performance; the gra-\ndient is fairly simple and certainly tractable. A natu-\nral way to use this classiﬁcation error gradient is after\ntraining the RBM for joint density modeling. How-\never, in preliminary experiments we found that this\nprocedure begins to overﬁt very quickly (often after\nimproving performance by less than 0.1%), so we did\nnot include it in this paper. It is, however, still possi-\nble that combining the classiﬁcation gradient with the\ndensity modeling gradient is a method that could yield\nmore improvements. This is future work.\nThe main limitation of PCD is that it appears to re-\nquire a low learning rate in order to allow the ”fantasy”\npoints to be sampled from a distribution that is close to\nthe stationary distribution for the current weights. A\ntheoretical analysis of this requirement can be found in\n(Yuille, 2004) and (Younes, 1999). Some preliminary\nexperiments, however, suggest that PCD can be made\nto work well even when the learning rate is much larger\nthan the one suggested by the asymptotic justiﬁcation\nof PCD and we are currently exploring variations that\nallow much larger learning rates.\nAcknowledgements\nI thank Geoﬀrey Hinton and Ruslan Salakhutdinov\nfor many useful discussions and helpful suggestions.\nNikola Karamanov and Alex Levinshtein helped by\nproviding data sets. The anonymous reviewers also\nprovided many useful suggestions. This research was\nsupported by NSERC and Microsoft.\nReferences\nBengio, Y., & Delalleau, O. (2007). Justifying and gen-\neralizing contrastive divergence (Technical Report\n1311). Universit´ e de Montr´ eal.\nBengio, Y., Lamblin, P., Popovici, D., Larochelle, H.,\n& Montreal, Q. (2007). Greedy Layer-Wise Train-\ning of Deep Networks. Advances in Neural Informa-\ntion Processing Systems 19: Proceedings of the 2006\nConference.\nBesag, J. (1986). On the statistical analysis of dirty\n1070\nT raining Restricted Boltzmann Machines using Approximations t o the Likelihood Gradient\npictures. Journal of the Royal Statistical Society B ,\n48, 259–302.\nBorenstein, E., Sharon, E., & Ullman, S. (2004). Com-\nbining Top-Down and Bottom-Up Segmentation.\nComputer Vision and Pattern Recognition Work-\nshop, 2004 Conference on , 46–46.\nCarreira-Perpinan, M., & Hinton, G. (2005). On con-\ntrastive divergence learning. Artiﬁcial Intelligence\nand Statistics, 2005 .\nGehler, P., Holub, A., & Welling, M. (2006). The rate\nadapting poisson model for information retrieval\nand object recognition. Proceedings of the 23rd in-\nternational conference on Machine learning , 337–\n344.\nHinton, G. (2002). Training Products of Experts by\nMinimizing Contrastive Divergence. Neural Compu-\ntation, 14, 1771–1800.\nHinton, G., & Salakhutdinov, R. (2006). Reducing\nthe Dimensionality of Data with Neural Networks.\nScience, 313, 504–507.\nHinton, G. E., Osindero, S., & Teh, Y. W. (2006). A\nfast learning algorithm for deep belief nets. Neural\nComputation, 18.\nLarochelle, H., Erhan, D., Courville, A., Bergstra, J.,\n& Bengio, Y. (2007). An empirical evaluation of\ndeep architectures on problems with many factors\nof variation. Proceedings of the 24th international\nconference on Machine learning , 473–480.\nLeCun, Y., & Cortes, C. The MNIST database of\nhandwritten digits.\nNeal, R. (1992). Connectionist learning of belief net-\nworks. Artiﬁcial Intelligence , 56, 71–113.\nRobbins, H., & Monro, S. (1951). A Stochastic Ap-\nproximation Method. The Annals of Mathematical\nStatistics, 22, 400–407.\nSalakhutdinov, R., Mnih, A., & Hinton, G. (2007). Re-\nstricted Boltzmann machines for collaborative ﬁlter-\ning. Proceedings of the 24th international conference\non Machine learning , 791–798.\nSalakhutdinov, R., & Murray, I. (2008). On the quan-\ntitative analysis of deep belief networks. Proceedings\nof the International Conference on Machine Learn-\ning.\nSmolensky, P. (1986). Information processing in dy-\nnamical systems: foundations of harmony theory .\nMIT Press Cambridge, MA, USA.\nWainwright, M., & Jordan, M. (2003). Graphical mod-\nels, exponential families, and variational inference.\nUC Berkeley, Dept. of Statistics, Technical Report ,\n649.\nWelling, M., & Hinton, G. (2002). A New Learning Al-\ngorithm for Mean Field Boltzmann Machines. Ar-\ntiﬁcial Neural Networks-Icann 2002: International\nConference, Madrid, Spain, August 28-30, 2002:\nProceedings.\nWelling, M., Rosen-Zvi, M., & Hinton, G. (2005). Ex-\nponential family harmoniums with an application to\ninformation retrieval. Advances in Neural Informa-\ntion Processing Systems , 17, 1481–1488.\nYounes, L. (1999). On the convergence of markovian\nstochastic algorithms with rapidly decreasing ergod-\nicity rates. Stochastics An International Journal of\nProbability and Stochastic Processes , 65, 177–228.\nYuille, A. (2004). The Convergence of Contrastive Di-\nvergences. Advances in Neural Information Process-\ning Systems , 3, 4.\n1071",
  "values": {
    "Beneficence": "No",
    "Not socially biased": "No",
    "Explicability": "No",
    "Respect for Persons": "No",
    "Non-maleficence": "No",
    "Critiqability": "No",
    "Deferral to humans": "No",
    "Fairness": "No",
    "User influence": "No",
    "Respect for Law and public interest": "No",
    "Collective influence": "No",
    "Justice": "No",
    "Autonomy (power to decide)": "No",
    "Privacy": "No",
    "Transparent (to users)": "No",
    "Interpretable (to users)": "No"
  }
}