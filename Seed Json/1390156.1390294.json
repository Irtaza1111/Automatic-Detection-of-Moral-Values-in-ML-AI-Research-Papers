{
  "pdf": "1390156.1390294",
  "title": "1390156.1390294",
  "author": "Unknown",
  "paper_id": "1390156.1390294",
  "text": "Extracting and Composing Robust Features with Denoising\nAutoencoders\nPascal Vincent vincentp@iro.umontreal.ca\nHugo Larochelle larocheh@iro.umontreal.ca\nY oshua Bengio bengioy@iro.umontreal.ca\nPierre-Antoine Manzagol manzagop@iro.umontreal.ca\nUniversit´ e de Montr´ eal, Dept. IRO, CP 6128, Succ. Centre-Ville, Montral, Qubec, H3C 3J7, Canada\nAbstract\nPrevious work has shown that the diﬃcul-\nties in learning deep generative or discrim-\ninative models can be overcome by an ini-\ntial unsupervised learning step that maps in-\nputs to useful intermediate representations.\nWe introduce and motivate a new training\nprinciple for unsupervised learning of a rep-\nresentation based on the idea of making the\nlearned representations robust to partial cor-\nruption of the input pattern. This approach\ncan be used to train autoencoders, and these\ndenoising autoencoders can be stacked to ini-\ntialize deep architectures. The algorithm can\nbe motivated from a manifold learning and\ninformation theoretic perspective or from a\ngenerative model perspective. Comparative\nexperiments clearly show the surprising ad-\nvantage of corrupting the input of autoen-\ncoders on a pattern classiﬁcation benchmark\nsuite.\n1. Introduction\nRecent theoretical studies indicate that deep architec-\ntures (Bengio & Le Cun, 2007; Bengio, 2007) may be\nneeded to eﬃciently model complex distributions and\nachieve better generalization performance on challeng-\ning recognition tasks. The belief that additional levels\nof functional composition will yield increased repre-\nsentational and modeling power is not new (McClel-\nland et al., 1986; Hinton, 1989; Utgoﬀ & Stracuzzi,\n2002). However, in practice, learning in deep archi-\ntectures has proven to be diﬃcult. One needs only\nAppearing in Proceedings of the 25 th International Confer-\nence on Machine Learning , Helsinki, Finland, 2008. Copy-\nright 2008 by the author(s)/owner(s).\nto ponder the diﬃcult problem of inference in deep\ndirected graphical models, due to “explaining away”.\nAlso looking back at the history of multi-layer neural\nnetworks, their diﬃcult optimization (Bengio et al.,\n2007; Bengio, 2007) has long prevented reaping the ex-\npected beneﬁts of going beyond one or two hidden lay-\ners. However this situation has recently changed with\nthe successful approach of (Hinton et al., 2006; Hinton\n& Salakhutdinov, 2006; Bengio et al., 2007; Ranzato\net al., 2007; Lee et al., 2008) for training Deep Belief\nNetworks and stacked autoencoders.\nOne key ingredient to this success appears to be the\nuse of an unsupervised training criterion to perform\na layer-by-layer initialization: each layer is at ﬁrst\ntrained to produce a higher level (hidden) represen-\ntation of the observed patterns, based on the repre-\nsentation it receives as input from the layer below,\nby optimizing a local unsupervised criterion. Each\nlevel produces a representation of the input pattern\nthat is more abstract than the previous level’s, be-\ncause it is obtained by composing more operations.\nThis initialization yields a starting point, from which\na global ﬁne-tuning of the model’s parameters is then\nperformed using another training criterion appropriate\nfor the task at hand. This technique has been shown\nempirically to avoid getting stuck in the kind of poor\nsolutions one typically reaches with random initializa-\ntions. While unsupervised learning of a mapping that\nproduces “good” intermediate representations of the\ninput pattern seems to be key, little is understood re-\ngarding what constitutes “good” representations for\ninitializing deep architectures, or what explicit crite-\nria may guide learning such representations. We know\nof only a few algorithms that seem to work well for\nthis purpose: Restricted Boltzmann Machines (RBMs)\ntrained with contrastive divergence on one hand, and\nvarious types of autoencoders on the other.\nThe present research begins with the question of what\n1096\n\nExtracting and Composing Robust F eatures with Denoising Autoencoders\nexplicit criteria a good intermediate representation\nshould satisfy. Obviously, it should at a minimum re-\ntain a certain amount of “information” about its input,\nwhile at the same time being constrained to a given\nform (e.g. a real-valued vector of a given size in the\ncase of an autoencoder). A supplemental criterion that\nhas been proposed for such models is sparsity of the\nrepresentation (Ranzato et al., 2008; Lee et al., 2008).\nHere we hypothesize and investigate an additional spe-\nciﬁc criterion: robustness to partial destruction\nof the input , i.e., partially destroyed inputs should\nyield almost the same representation. It is motivated\nby the following informal reasoning: a good represen-\ntation is expected to capture stable structures in the\nform of dependencies and regularities characteristic of\nthe (unknown) distribution of its observed input. For\nhigh dimensional redundant input (such as images) at\nleast, such structures are likely to depend on evidence\ngathered from a combination of many input dimen-\nsions. They should thus be recoverable from partial\nobservation only. A hallmark of this is our human\nability to recognize partially occluded or corrupted im-\nages. Further evidence is our ability to form a high\nlevel concept associated to multiple modalities (such\nas image and sound) and recall it even when some of\nthe modalities are missing.\nTo validate our hypothesis and assess its usefulness as\none of the guiding principles in learning deep architec-\ntures, we propose a modiﬁcation to the autoencoder\nframework to explicitly integrate robustness to par-\ntially destroyed inputs. Section 2 describes the algo-\nrithm in details. Section 3 discusses links with other\napproaches in the literature. Section 4 is devoted to\na closer inspection of the model from diﬀerent theo-\nretical standpoints. In section 5 we verify empirically\nif the algorithm leads to a diﬀerence in performance.\nSection 6 concludes the study.\n2. Description of the Algorithm\n2.1. Notation and Setup\nLet X and Y be two random variables with joint prob-\nability density p(X, Y ), with marginal distributions\np(X) and p(Y ). Throughout the text, we will use\nthe following notation: Expectation: E Ep(X)[f (X)] =∫\np(x)f (x)dx. Entropy: I H(X) = I H(p) =\nE Ep(X)[− log p(X)]. Conditional entropy: I H(X|Y ) =\nE Ep(X,Y )[− log p(X|Y )]. Kullback-Leibler divergence:\nI DKL(p∥q) = E Ep(X)[log p(X)\nq(X) ]. Cross-entropy: I H(p∥q) =\nE Ep(X)[− log q(X)] = I H(p) + I DKL(p∥q). Mutual infor-\nmation: I(X; Y ) = I H(X) − I H(X|Y ). Sigmoid: s(x) =\n1\n1+e− x and s(x) = ( s(x1), . . . , s (xd))T . Bernoulli dis-\ntribution with mean µ: Bµ (x). and by extension\nBµ (x) = ( Bµ 1(x1), . . . , Bµ d(xd)).\nThe setup we consider is the typical supervised learn-\ning setup with a training set of n (input, target) pairs\nDn = {(x(1), t (1)) . . . , (x(n), t (n))}, that we suppose\nto be an i.i.d. sample from an unknown distribution\nq(X, T ) with corresponding marginals q(X) and q(T ).\n2.2. The Basic Autoencoder\nWe begin by recalling the traditional autoencoder\nmodel such as the one used in (Bengio et al., 2007)\nto build deep networks. An autoencoder takes an\ninput vector x ∈ [0, 1]d, and ﬁrst maps it to a hid-\nden representation y ∈ [0, 1]d′\nthrough a deterministic\nmapping y = fθ(x) = s(Wx + b), parameterized by\nθ = {W, b}. W is a d′ × d weight matrix and b\nis a bias vector. The resulting latent representation\ny is then mapped back to a “reconstructed” vector\nz ∈ [0, 1]d in input space z = gθ′(y) = s(W′y + b′)\nwith θ′ = {W′, b′}. The weight matrix W′ of the\nreverse mapping may optionally be constrained by\nW′ = WT , in which case the autoencoder is said to\nhave tied weights . Each training x(i) is thus mapped\nto a corresponding y(i) and a reconstruction z(i). The\nparameters of this model are optimized to minimize\nthe average reconstruction error:\nθ⋆, θ ′⋆ = arg min\nθ,θ ′\n1\nn\nn∑\ni=1\nL\n(\nx(i), z(i)\n)\n= arg min\nθ,θ ′\n1\nn\nn∑\ni=1\nL\n(\nx(i), g θ′(fθ(x(i)))\n)\n(1)\nwhere L is a loss function such as the traditional\nsquared error L(x, z) = ∥x − z∥2. An alternative loss,\nsuggested by the interpretation of x and z as either\nbit vectors or vectors of bit probabilities (Bernoullis)\nis the reconstruction cross-entropy:\nLI H(x, z)= I H(Bx∥Bz)\n= −\nd∑\nk=1\n[xk log zk +(1 − xk) log(1 − zk)] (2)\nNote that if x is a binary vector, LI H(x, z) is a negative\nlog-likelihood for the example x, given the Bernoulli\nparameters z. Equation 1 with L = LI Hcan be written\nθ⋆, θ ′⋆ = arg min\nθ,θ ′\nE Eq0(X) [LI H(X, g θ′(fθ(X)))] (3)\nwhere q0(X) denotes the empirical distribution asso-\nciated to our n training inputs. This optimization will\ntypically be carried out by stochastic gradient descent.\n1097\nExtracting and Composing Robust F eatures with Denoising Autoencoders\n2.3. The Denoising Autoencoder\nTo test our hypothesis and enforce robustness to par-\ntially destroyed inputs we modify the basic autoen-\ncoder we just described. We will now train it to recon-\nstruct a clean “repaired” input from a corrupted, par-\ntially destroyed one. This is done by ﬁrst corrupting\nthe initial input x to get a partially destroyed version\n˜x by means of a stochastic mapping ˜x ∼ qD(˜x|x). In\nour experiments, we considered the following corrupt-\ning process, parameterized by the desired proportion ν\nof “destruction”: for each input x, a ﬁxed number νd\nof components are chosen at random, and their value\nis forced to 0, while the others are left untouched. All\ninformation about the chosen components is thus re-\nmoved from that particuler input pattern, and the au-\ntoencoder will be trained to “ﬁll-in” these artiﬁcially\nintroduced “blanks”. Note that alternative corrupting\nnoises could be considered 1. The corrupted input ˜x is\nthen mapped, as with the basic autoencoder, to a hid-\nden representation y = fθ(˜x) = s(W˜x+b) from which\nwe reconstruct a z = gθ′(y) = s(W′y + b′) (see ﬁgure\n1 for a schematic representation of the process). As\nbefore the parameters are trained to minimize the av-\nerage reconstruction error LI H(x, z) = I H(Bx∥Bz) over\na training set, i.e. to have z as close as possible to the\nuncorrupted input x. But the key diﬀerence is that z\nis now a deterministic function of ˜x rather than x and\nthus the result of a stochastic mapping of x.\nfθ\nxx˜x\nqD\ny\nz\nLH(x, z)gθ′\nFigure 1. An example x is corrupted to ˜x. The autoen-\ncoder then maps it to y and attempts to reconstruct x.\nLet us deﬁne the joint distribution\nq0(X, ˜X, Y ) = q0(X)qD( ˜X|X)δfθ( eX)(Y ) (4)\nwhere δu(v) puts mass 0 when u ̸= v. Thus Y is a\ndeterministic function of ˜X. q0(X, ˜X, Y ) is param-\neterized by θ. The objective function minimized by\nstochastic gradient descent becomes:\narg min\nθ,θ ′\nE Eq0(X, eX)\n[\nLI H\n(\nX, g θ′(fθ( ˜X))\n)]\n. (5)\nSo from the point of view of the stochastic gradient de-\nscent algorithm, in addition to picking an input sam-\nple from the training set, we will also produce a ran-\ndom corrupted version of it, and take a gradient step\n1The approach we describe and our analysis is not spe-\nciﬁc to a particular kind of corrupting noise.\ntowards reconstructing the uncorrupted version from\nthe corrupted version. Note that in this way, the au-\ntoencoder cannot learn the identity, unlike the basic\nautoencoder, thus removing the constraint that d′ < d\nor the need to regularize speciﬁcally to avoid such a\ntrivial solution.\n2.4. Layer-wise Initialization and Fine T uning\nThe basic autoencoder has been used as a building\nblock to train deep networks (Bengio et al., 2007), with\nthe representation of the k-th layer used as input for\nthe ( k + 1)-th, and the ( k + 1)-th layer trained after\nthe k-th has been trained. After a few layers have been\ntrained, the parameters are used as initialization for a\nnetwork optimized with respect to a supervised train-\ning criterion. This greedy layer-wise procedure has\nbeen shown to yield signiﬁcantly better local minima\nthan random initialization of deep networks , achieving\nbetter generalization on a number of tasks (Larochelle\net al., 2007).\nThe procedure to train a deep network using the de-\nnoising autoencoder is similar. The only diﬀerence is\nhow each layer is trained, i.e., to minimize the crite-\nrion in eq. 5 instead of eq. 3. Note that the corrup-\ntion process qD is only used during training, but not\nfor propagating representations from the raw input to\nhigher-level representations. Note also that when layer\nk is trained, it receives as input the uncorrupted out-\nput of the previous layers.\n3. Relationship to Other Approaches\nOur training procedure for the denoising autoencoder\ninvolves learning to recover a clean input from a cor-\nrupted version, a task known as denoising. The prob-\nlem of image denoising, in particular, has been exten-\nsively studied in the image processing community and\nmany recent developments rely on machine learning\napproaches (see e.g. Roth and Black (2005); Elad and\nAharon (2006); Hammond and Simoncelli (2007)). A\nparticular form of gated autoencoders has also been\nused for denoising in Memisevic (2007). Denoising us-\ning autoencoders was actually introduced much ear-\nlier (LeCun, 1987; Gallinari et al., 1987), as an alter-\nnative to Hopﬁeld models (Hopﬁeld, 1982). Our ob-\njective however is fundamentally diﬀerent from that of\ndeveloping a competitive image denoising algorithm.\nWe investigate explicit robustness to corrupting noise\nas a novel criterion guiding the learning of suitable in-\ntermediate representations to initialize a deep network.\nThus our corruption+denoising procedure is applied\nnot only on the input, but also recursively to interme-\ndiate representations.\n1098\nExtracting and Composing Robust F eatures with Denoising Autoencoders\nThe approach also bears some resemblance to the well\nknown technique of augmenting the training data with\nstochastically “transformed” patterns. E.g. augment-\ning a training set by transforming original bitmaps\nthrough small rotations, translations, and scalings is\nknown to improve ﬁnal classiﬁcation performance. In\ncontrast to this technique our approach does not use\nany prior knowledge of image topology, nor does it pro-\nduce extra labeled examples for supervised training.\nWe use corrupted patterns in a generic (i.e. not spe-\nciﬁc to images) unsupervised initialization step, while\nthe supervised training phase uses the unmodiﬁed orig-\ninal data.\nThere is a well known link between “training with\nnoise” and regularization: they are equivalent for small\nadditive noise (Bishop, 1995). By contrast, our cor-\nruption process is a large, non-additive, destruction\nof information. We train autoencoders to ”ﬁll in the\nblanks”, not merely be smooth functions (regulariza-\ntion). Also in our experience, regularized autoencoders\n(i.e. with weight decay) do not yield the quantitative\njump in performance and the striking qualitative dif-\nference observed in the ﬁlters that we get with denois-\ning autoencoders.\nThere are also similarities with the work of (Doi et al.,\n2006) on robust coding over noisy channels. In their\nframework, a linear encoder is to encode a clean input\nfor optimal transmission over a noisy channel to a de-\ncoder that reconstructs the input. This work was later\nextended to robustness to noise in the input, in a pro-\nposal for a model of retinal coding (Doi & Lewicki,\n2007). Though some of the inspiration behind our\nwork comes from neural coding and computation, our\ngoal is not to account for experimental data of neu-\nronal activity as in (Doi & Lewicki, 2007). Also, the\nnon-linearity of our denoising autoencoder is crucial\nfor its use in initializing a deep neural network.\nIt may be objected that, if our goal is to handle missing\nvalues correctly, we could have more naturally deﬁned\na proper latent variable generative model, and infer the\nposterior over the latent (hidden) representation in the\npresence of missing inputs. But this usually requires\na costly marginalization 2 which has to be carried out\nfor each new example. By contrast, our approach tries\nto learn a fast and robust deterministic mapping fθ\nfrom examples of already corrupted inputs. The bur-\nden is on learning such a constrained mapping during\ntraining, rather than on unconstrained inference at use\ntime. We expect this may force the model to capture\nimplicit invariances in the data, and result in interest-\n2as for RBMs, where it is exponential in the number of\nmissing values\ning features. Also note that in section 4.2 we will see\nhow our learning algorithm for the denoising autoen-\ncoder can be viewed as a form of variational inference\nin a particular generative model.\n4. Analysis of Denoising Autoencoders\nThe above intuitive motivation for the denoising au-\ntoencoder was given with the perspective of discover-\ning robust representations. In the following, which can\nbe skipped without hurting the remainder of the paper,\nwe propose alternative perspectives on the algorithm.\n4.1. Manifold Learning Perspective\nThe process of mapping a corrupted example to an\nuncorrupted one can be visualized in Figure 2, with\na low-dimensional manifold near which the data con-\ncentrate. We learn a stochastic operator p(X|˜X) that\nmaps an ˜X to an X, p(X|˜X) = Bgθ′(fθ( eX))(X). The\ncorrupted examples will be much more likely to be\noutside and farther from the manifold than the uncor-\nrupted ones. Hence the stochastic operator p(X|˜X)\nlearns a map that tends to go from lower probability\npoints ˜X to high probability points X, generally on\nor near the manifold. Note that when ˜X is farther\nfrom the manifold, p(X|˜X) should learn to make big-\nger steps, to reach the manifold. At the limit we see\nthat the operator should map even far away points to\na small volume near the manifold.\nThe denoising autoencoder can thus be seen as a way\nto deﬁne and learn a manifold. The intermediate rep-\nresentation Y = f (X) can be interpreted as a coordi-\nnate system for points on the manifold (this is most\nclear if we force the dimension of Y to be smaller than\nthe dimension of X). More generally, one can think of\nY = f (X) as a representation of X which is well suited\nto capture the main variations in the data, i.e., on the\nmanifold. When additional criteria (such as sparsity)\nare introduced in the learning model, one can no longer\ndirectly view Y = f (X) as an explicit low-dimensional\ncoordinate system for points on the manifold, but it\nretains the property of capturing the main factors of\nvariation in the data.\n4.2. T op-down, Generative Model Perspective\nIn this section we recover the training criterion for\nour denoising autoencoder (eq. 5) from a generative\nmodel perspective. Speciﬁcally we show that training\nthe denoising autoencoder as described in section 2.3\nis equivalent to maximizing a variational bound on a\nparticular generative model.\nConsider the generative model p(X, ˜X, Y ) =\np(Y )p(X|Y )p( ˜X|X) where p(X|Y ) = Bs(W′Y +b′) and\n1099\nExtracting and Composing Robust F eatures with Denoising Autoencoders\np( ˜X|X) = qD( ˜X|X). p(Y ) is a uniform prior over\nY ∈ [0, 1]d′\n. This deﬁnes a generative model with pa-\nrameter set θ′ = {W′, b′}. We will use the previ-\nously deﬁned q0(X, ˜X, Y ) = q0(X)qD( ˜X|X)δfθ( eX)(Y )\n(equation 4) as an auxiliary model in the context of\na variational approximation of the log-likelihood of\np( ˜X). Note that we abuse notation to make it lighter,\nand use the same letters X, ˜X and Y for diﬀerent\nsets of random variables representing the same quan-\ntity under diﬀerent distributions: p or q0. Keep in\nmind that whereas we had the dependency structure\nX → ˜X → Y for q or q0, we have Y → X → ˜X for p.\nSince p contains a corruption operation at the last\ngenerative stage, we propose to ﬁt p( ˜X) to corrupted\ntraining samples. Performing maximum likelihood ﬁt-\nting for samples drawn from q0( ˜X) corresponds to min-\nimizing the cross-entropy, or maximizing\nH = max\nθ′\n{−I H(q0( ˜X)∥p( ˜X))}\n= max\nθ′\n{E Eq0( eX)[log p( ˜X)]}. (6)\nLet q⋆(X, Y |˜X) be a conditional density, the quan-\ntity L(q⋆, ˜X) = E Eq⋆(X,Y |eX)\n[\nlog p(X, eX,Y )\nq⋆(X,Y |eX)\n]\nis a lower\nbound on log p( ˜X) since the following can be shown to\nbe true for any q⋆:\nlog p( ˜X) = L(q⋆, ˜X) + I DKL(q⋆(X, Y |˜X)∥p(X, Y |˜X))\nAlso it is easy to verify that the bound is tight when\nq⋆(X, Y |˜X) = p(X, Y |˜X), where the I DKL becomes 0.\nWe can thus write log p( ˜X) = max q⋆ L(q⋆, ˜X), and\nconsequently rewrite equation 6 as\nH = max\nθ′\n{E Eq0( eX)[max\nq⋆ L(q⋆, ˜X)]}\n= max\nθ′,q ⋆\n{E Eq0( eX)[L(q⋆, ˜X)]} (7)\nx\nx\n˜x\n˜xqD(˜x|x)\ngθ′(fθ(˜x))\nFigure 2. Manifold learning perspective. Suppose\ntraining data ( × ) concentrate near a low-dimensional man-\nifold. Corrupted examples ( . ) obtained by applying cor-\nruption process qD( eX|X) will lie farther from the manifold.\nThe model learns with p(X|eX) to “project them back” onto\nthe manifold. Intermediate representation Y can be inter-\npreted as a coordinate system for points on the manifold.\nwhere we moved the maximization outside of the ex-\npectation because an unconstrained q⋆(X, Y |˜X) can\nin principle perfectly model the conditional distribu-\ntion needed to maximize L(q⋆, ˜X) for any ˜X. Now\nif we replace the maximization over an unconstrained\nq⋆ by the maximization over the parameters θ of our\nq0 (appearing in fθ that maps an x to a y), we get\na lower bound on H: H ≥ maxθ′,θ {E Eq0( eX)[L(q0, ˜X)]}\nMaximizing this lower bound, we ﬁnd\narg max\nθ,θ ′\n{E Eq0( eX)[L(q0, ˜X)]}\n= arg max\nθ,θ ′\nE Eq0(X, eX,Y )\n[\nlog p(X, ˜X, Y )\nq0(X, Y |˜X)\n]\n= arg max\nθ,θ ′\nE Eq0(X, eX,Y )\n[\nlog p(X, ˜X, Y )\n]\n+ E Eq0( eX)\n[\nI H[q0(X, Y |˜X)]\n]\n= arg max\nθ,θ ′\nE Eq0(X, eX,Y )\n[\nlog p(X, ˜X, Y )\n]\n.\nNote that θ only occurs in Y = fθ( ˜X), and θ′ only\noccurs in p(X|Y ). The last line is therefore obtained\nbecause q0(X|˜X) ∝ qD( ˜X|X)q0(X) (none of which de-\npends on ( θ, θ ′)), and q0(Y |˜X) is deterministic, i.e., its\nentropy is constant, irrespective of ( θ, θ ′). Hence the\nentropy of q0(X, Y |˜X) = q0(Y |˜X)q0(X|˜X), does not\nvary with ( θ, θ ′). Finally, following from above, we\nobtain our training criterion (eq. 5):\narg max\nθ,θ ′\nE Eq0( eX)[L(q0, ˜X)]\n= arg max\nθ,θ ′\nE Eq0(X, eX,Y )[log[p(Y )p(X|Y )p( ˜X|X)]]\n= arg max\nθ,θ ′\nE Eq0(X, eX,Y )[log p(X|Y )]\n= arg max\nθ,θ ′\nE Eq0(X, eX)[log p(X|Y = fθ( ˜X))]\n= arg min\nθ,θ ′\nE Eq0(X, eX)\n[\nLI H\n(\nX, g θ′(fθ( ˜X))\n)]\nwhere the third line is obtained because ( θ, θ ′)\nhave no inﬂuence on E Eq0(X, eX,Y )[log p(Y )] because\nwe chose p(Y ) uniform, i.e. constant, nor on\nE Eq0(X, eX)[log p( ˜X|X)], and the last line is obtained\nby inspection of the deﬁnition of LI H in eq. 2, when\np(X|Y = fθ( ˜X)) is a Bgθ′(fθ( eX)).\n4.3. Other Theoretical Perspectives\nInformation Theoretic Perspective: Consider\nX ∼ q(X), q unknown, Y = fθ( ˜X). It can easily\nbe shown (Vincent et al., 2008) that minimizing the\nexpected reconstruction error amounts to maximizing\n1100\nExtracting and Composing Robust F eatures with Denoising Autoencoders\na lower bound on mutual information I(X; Y ). Denois-\ning autoencoders can thus be justiﬁed by the objective\nthat Y captures as much information as possible about\nX even as Y is a function of corrupted input.\nStochastic Operator Perspective: Extending the\nmanifold perspective, the denoising autoencoder can\nalso be seen as corresponding to a semi-parametric\nmodel from which we can sample (Vincent et al., 2008):\np(X) = 1\nn\n∑ n\ni=1\n∑\n˜x p(X|˜X = ˜x)qD(˜x|xi),\nwhere xi is one of the n training examples.\n5. Experiments\nWe performed experiments with the proposed algo-\nrithm on the same benchmark of classiﬁcation prob-\nlems used in (Larochelle et al., 2007) 3. It contains\ndiﬀerent variations of the MNIST digit classiﬁcation\nproblem (input dimensionality d = 28 × 28 = 784),\nwith added factors of variation such as rotation ( rot),\naddition of a background composed of random pixels\n(bg-rand) or made from patches extracted from a set of\nimages ( bg-img), or combinations of these factors ( rot-\nbg-img). These variations render the problems par-\nticularly challenging for current generic learning al-\ngorithms. Each problem is divided into a training,\nvalidation, and test set (10000, 2000, 50000 examples\nrespectively). A subset of the original MNIST prob-\nlem is also included with the same example set sizes\n(problem basic). The benchmark also contains addi-\ntional binary classiﬁcation problems: discriminating\nbetween convex and non-convex shapes ( convex), and\nbetween wide and long rectangles ( rect, rect-img).\nNeural networks with 3 hidden layers initialized by\nstacking denoising autoencoders (SdA-3), and ﬁne\ntuned on the classiﬁcation tasks, were evaluated on all\nthe problems in this benchmark. Model selection was\nconducted following a similar procedure as Larochelle\net al. (2007). Several values of hyper parameters (de-\nstruction fraction ν, layer sizes, number of unsuper-\nvised training epochs) were tried, combined with early\nstopping in the ﬁne tuning phase. For each task, the\nbest model was selected based on its classiﬁcation per-\nformance on the validation set.\nTable 1 reports the resulting classiﬁcation error on the\ntest set for the new model (SdA-3), together with the\nperformance reported in Larochelle et al. (2007) 4 for\n3All the datasets for these problems are available at\nhttp://www.iro.umontreal.ca/∼ lisa/icml2007.\n4Except that rot and rot-bg-img, as reported on the web-\nsite from which they are available, have been regenerated\nsince Larochelle et al. (2007), to ﬁx a problem in the initial\ndata generation process. We used the updated data and\ncorresponding benchmark results given on this website.\nSVMs with Gaussian and polynomial kernels, 1 and 3\nhidden layers deep belief network (DBN-1 and DBN-3)\nand a 3 hidden layer deep network initialized by stack-\ning basic autoencoders (SAA-3). Note that SAA-3 is\nequivalent to a SdA-3 with ν = 0% destruction. As can\nbe seen in the table, the corruption+denoising train-\ning works remarkably well as an initialization step, and\nin most cases yields signiﬁcantly better classiﬁcation\nperformance than basic autoencoder stacking with no\nnoise. On all but one task the SdA-3 algorithm per-\nforms on par or better than the best other algorithms,\nincluding deep belief nets. Due to space constraints,\nwe do not report all selected hyper-parameters in the\ntable (only showing ν). But it is worth mentioning\nthat, for the majority of tasks, the model selection\nprocedure chose best performing models with an over-\ncomplete ﬁrst hidden layer representation (typically\nof size 2000 for the 784-dimensional MNIST-derived\ntasks). This is very diﬀerent from the traditional “bot-\ntleneck” autoencoders, and made possible by our de-\nnoising training procedure. All this suggests that the\nproposed procedure was indeed able to produce more\nuseful feature detectors.\nNext, we wanted to understand qualitatively the ef-\nfect of the corruption+denoising training. To this end\nwe display the ﬁlters obtained after initial training of\nthe ﬁrst denoising autoencoder on MNIST digits. Fig-\nure 3 shows a few of these ﬁlters as little image patches,\nfor diﬀerent noise levels. Each patch corresponds to a\nrow of the learnt weight matrix W, i.e. the incoming\nweights of one of the hidden layer neurons. The beneﬁ-\ncial eﬀect of the denoising training can clearly be seen.\nWithout the denoising procedure, many ﬁlters appear\nto have learnt no interesting feature. They look like\nthe ﬁlters obtained after random initialization. But\nwhen increasing the level of destructive corruption, an\nincreasing number of ﬁlters resemble sensible feature\ndetectors. As we move to higher noise levels, we ob-\nserve a phenomenon that we expected: ﬁlters become\nless local, they appear sensitive to larger structures\nspread out across more input dimensions.\n6. Conclusion and Future Work\nWe have introduced a very simple training principle\nfor autoencoders, based on the objective of undoing a\ncorruption process. This is motivated by the goal of\nlearning representations of the input that are robust to\nsmall irrelevant changes in input. We also motivated\nit from a manifold learning perspective and gave an\ninterpretation from a generative model perspective.\nThis principle can be used to train and stack autoen-\ncoders to initialize a deep neural network. A series\n1101\nExtracting and Composing Robust F eatures with Denoising Autoencoders\nTable 1. Comparison of stacked denoising autoencoders (SdA-3) with other models.\nTest error rate on all considered classiﬁcation problems is reported together with a 95% conﬁdence interval. Best performer\nis in bold, as well as those for which conﬁdence intervals overlap. SdA-3 appears to achieve performance superior or\nequivalent to the best other model on all problems except bg-rand. For SdA-3, we also indicate the fraction ν of destroyed\ninput components, as chosen by proper model selection. Note that SAA-3 is equivalent to SdA-3 with ν = 0%.\nDataset SVMrbf SVMpoly DBN-1 SAA-3 DBN-3 SdA-3 (ν)\nbasic 3.03± 0.15 3.69± 0.17 3.94± 0.17 3.46± 0.16 3.11± 0.15 2.80± 0.14 (10%)\nrot 11.11± 0.28 15.42± 0.32 14.69± 0.31 10.30± 0.27 10.30± 0.27 10.29± 0.27 (10%)\nbg-rand 14.58± 0.31 16.62± 0.33 9.80± 0.26 11.28± 0.28 6.73± 0.22 10.38± 0.27 (40%)\nbg-img 22.61± 0.37 24.01± 0.37 16.15± 0.32 23.00± 0.37 16.31± 0.32 16.68± 0.33 (25%)\nrot-bg-img 55.18± 0.44 56.41± 0.43 52.21± 0.44 51.93± 0.44 47.39± 0.44 44.49± 0.44 (25%)\nrect 2.15± 0.13 2.15± 0.13 4.71± 0.19 2.41± 0.13 2.60± 0.14 1.99± 0.12 (10%)\nrect-img 24.04± 0.37 24.05± 0.37 23.69± 0.37 24.05± 0.37 22.50± 0.37 21.59± 0.36 (25%)\nconvex 19.13± 0.34 19.82± 0.35 19.92± 0.35 18.41± 0.34 18.63± 0.34 19.06± 0.34 (10%)\n(a) No destroyed inputs\n (b) 25% destruction\n (c) 50% destruction\n(d) Neuron A (0%, 10%, 20%, 50% destruction)\n (e) Neuron B (0%, 10%, 20%, 50% destruction)\nFigure 3. Filters obtained after training the ﬁrst denoising autoencoder.\n(a-c) show some of the ﬁlters obtained after training a denoising autoencoder on MNIST samples, with increasing\ndestruction levels ν. The ﬁlters at the same position in the three images are related only by the fact that the autoencoders\nwere started from the same random initialization point.\n(d) and (e) zoom in on the ﬁlters obtained for two of the neurons, again for increasing destruction levels.\nAs can be seen, with no noise, many ﬁlters remain similarly uninteresting (undistinctive almost uniform grey patches).\nAs we increase the noise level, denoising training forces the ﬁlters to diﬀerentiate more, and capture more distinctive\nfeatures. Higher noise levels tend to induce less local ﬁlters, as expected. One can distinguish diﬀerent kinds of ﬁlters,\nfrom local blob detectors, to stroke detectors, and some full character detectors at the higher noise levels.\n1102\nExtracting and Composing Robust F eatures with Denoising Autoencoders\nof image classiﬁcation experiments were performed to\nevaluate this new training principle. The empirical re-\nsults support the following conclusions: unsupervised\ninitialization of layers with an explicit denoising crite-\nrion helps to capture interesting structure in the input\ndistribution. This in turn leads to intermediate rep-\nresentations much better suited for subsequent learn-\ning tasks such as supervised classiﬁcation. It is possi-\nble that the rather good experimental performance of\nDeep Belief Networks (whose layers are initialized as\nRBMs) is partly due to RBMs encapsulating a simi-\nlar form of robustness to corruption in the represen-\ntations they learn, possibly because of their stochas-\ntic nature which introduces noise in the representation\nduring training. Future work inspired by this observa-\ntion should investigate other types of corruption pro-\ncess, not only of the input but of the representation\nitself as well.\nAcknowledgments\nWe thank the anonymous reviewers for their useful\ncomments that helped improved the paper. We are\nalso very grateful for ﬁnancial support of this work by\nNSERC, MITACS and CIF AR.\nReferences\nBengio, Y. (2007). Learning deep architectures for AI\n(Technical Report 1312). Universit´ e de Montr´ eal, dept.\nIRO.\nBengio, Y., Lamblin, P., Popovici, D., & Larochelle, H.\n(2007). Greedy layer-wise training of deep networks.\nAdvances in Neural Information Processing Systems 19\n(pp. 153–160). MIT Press.\nBengio, Y., & Le Cun, Y. (2007). Scaling learning algo-\nrithms towards AI. In L. Bottou, O. Chapelle, D. De-\nCoste and J. Weston (Eds.), Large scale kernel machines.\nMIT Press.\nBishop, C. M. (1995). Training with noise is equivalent to\ntikhonov regularization. Neural Computation , 7, 108–\n116.\nDoi, E., Balcan, D. C., & Lewicki, M. S. (2006). A theo-\nretical analysis of robust coding over noisy overcomplete\nchannels. In Y. Weiss, B. Sch¨ olkopf and J. Platt (Eds.),\nAdvances in neural information processing systems 18 ,\n307–314. Cambridge, MA: MIT Press.\nDoi, E., & Lewicki, M. S. (2007). A theory of retinal pop-\nulation coding. NIPS (pp. 353–360). MIT Press.\nElad, M., & Aharon, M. (2006). Image denoising via sparse\nand redundant representations over learned dictionaries.\nIEEE Transactions on Image Processing , 15, 3736–3745.\nGallinari, P., LeCun, Y., Thiria, S., & Fogelman-Soulie, F.\n(1987). Memoires associatives distribuees. Proceedings\nof COGNITIV A 87. Paris, La Villette.\nHammond, D., & Simoncelli, E. (2007). A machine learning\nframework for adaptive combination of signal denoising\nmethods. 2007 International Conference on Image Pro-\ncessing (pp. VI: 29–32).\nHinton, G. (1989). Connectionist learning procedures. Ar-\ntiﬁcial Intelligence , 40, 185–234.\nHinton, G., & Salakhutdinov, R. (2006). Reducing the\ndimensionality of data with neural networks. Science,\n313, 504–507.\nHinton, G. E., Osindero, S., & Teh, Y. (2006). A fast learn-\ning algorithm for deep belief nets. Neural Computation ,\n18, 1527–1554.\nHopﬁeld, J. (1982). Neural networks and physical systems\nwith emergent collective computational abilities. Pro-\nceedings of the National Academy of Sciences, USA , 79.\nLarochelle, H., Erhan, D., Courville, A., Bergstra, J., &\nBengio, Y. (2007). An empirical evaluation of deep ar-\nchitectures on problems with many factors of variation.\nProceedings of the 24 th International Conference on Ma-\nchine Learning (ICML’2007) (pp. 473–480).\nLeCun, Y. (1987). Mod` eles connexionistes de\nl’apprentissage. Doctoral dissertation, Universit´ e\nde Paris VI.\nLee, H., Ekanadham, C., & Ng, A. (2008). Sparse deep be-\nlief net model for visual area V2. In J. Platt, D. Koller,\nY. Singer and S. Roweis (Eds.), Advances in neural in-\nformation processing systems 20 . Cambridge, MA: MIT\nPress.\nMcClelland, J., Rumelhart, D., & the PDP Re-\nsearch Group (1986). Parallel distributed processing:\nExplorations in the microstructure of cognition , vol. 2.\nCambridge: MIT Press.\nMemisevic, R. (2007). Non-linear latent factor models for\nrevealing structure in high-dimensional data . Doctoral\ndissertation, Departement of Computer Science, Univer-\nsity of Toronto, Toronto, Ontario, Canada.\nRanzato, M., Boureau, Y.-L., & LeCun, Y. (2008). Sparse\nfeature learning for deep belief networks. In J. Platt,\nD. Koller, Y. Singer and S. Roweis (Eds.), Advances in\nneural information processing systems 20 . Cambridge,\nMA: MIT Press.\nRanzato, M., Poultney, C., Chopra, S., & LeCun, Y.\n(2007). Eﬃcient learning of sparse representations with\nan energy-based model. Advances in Neural Information\nProcessing Systems (NIPS 2006) . MIT Press.\nRoth, S., & Black, M. (2005). Fields of experts: a frame-\nwork for learning image priors. IEEE Conference on\nComputer Vision and Pattern Recognition (pp. 860–\n867).\nUtgoﬀ, P., & Stracuzzi, D. (2002). Many-layered learning.\nNeural Computation , 14, 2497–2539.\nVincent, P., Larochelle, H., Bengio, Y., & Manzagol, P.-A.\n(2008). Extracting and composing robust features with\ndenoising autoencoders (Technical Report 1316). Uni-\nversit´ e de Montr´ eal, dept. IRO.\n1103",
  "values": {
    "Autonomy (power to decide)": "Yes",
    "Transparent (to users)": "Yes",
    "Respect for Law and public interest": "Yes",
    "Interpretable (to users)": "Yes",
    "Non-maleficence": "Yes",
    "Deferral to humans": "Yes",
    "Beneficence": "Yes",
    "User influence": "Yes",
    "Critiqability": "Yes",
    "Respect for Persons": "Yes",
    "Fairness": "Yes",
    "Explicability": "Yes",
    "Collective influence": "Yes",
    "Justice": "Yes",
    "Privacy": "Yes",
    "Not socially biased": "Yes"
  }
}