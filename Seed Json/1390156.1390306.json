{
  "pdf": "1390156.1390306",
  "title": "1390156.1390306",
  "author": "Unknown",
  "paper_id": "1390156.1390306",
  "text": "Listwise Approach to Learning to Rank - Theory and Algorithm\nF en Xia* fen.xia@ia.ac.cn\nInstitute of Automation, Chinese Academy of Sciences, Beijing, 100190, P. R. China.\nTie-Y an Liu tyliu@microsoft.com\nMicrosoft Research Asia, Sigma Center, No.49 Zhichun Road, Haidian District, Beijing, 100190, P. R. China.\nJue W ang jue.wang@ia.ac.cn\nW ensheng Zhang wensheng.zhang@ia.ac.cn\nInstitute of Automation, Chinese Academy of Sciences, Beijing, 100190, P. R. China.\nHang Li hangli@microsoft.com\nMicrosoft Research Asia, Sigma Center, No.49 Zhichun Road, Haidian District, Beijing, 100190, P. R. China.\nAbstract\nThis paper aims to conduct a study on the\nlistwise approach to learning to rank. The\nlistwise approach learns a ranking function by\ntaking individual lists as instances and min-\nimizing a loss function deﬁned on the pre-\ndicted list and the ground-truth list. Exist-\ning work on the approach mainly focused on\nthe development of new algorithms; methods\nsuch as RankCosine and ListNet have been\nproposed and good performances by them\nhave been observed. Unfortunately, the un-\nderlying theory was not suﬃciently studied\nso far. To amend the problem, this paper\nproposes conducting theoretical analysis of\nlearning to rank algorithms through inves-\ntigations on the properties of the loss func-\ntions, including consistency, soundness, con-\ntinuity, diﬀerentiability, convexity, and eﬃ-\nciency. A suﬃcient condition on consistency\nfor ranking is given, which seems to be the\nﬁrst such result obtained in related research.\nThe paper then conducts analysis on three\nloss functions: likelihood loss, cosine loss,\nand cross entropy loss. The latter two were\nused in RankCosine and ListNet. The use of\nthe likelihood loss leads to the development of\nAppearing in Proceedings of the 25 th International Confer-\nence on Machine Learning , Helsinki, Finland, 2008. Copy-\nright 2008 by the author(s)/owner(s).\n*The work was performed when the ﬁrst author was an\nintern at Microsoft Research Asia.\na new listwise method called ListMLE, whose\nloss function oﬀers better properties, and also\nleads to better experimental results.\n1. Introduction\nRanking, which is to sort objects based on certain fac-\ntors, is the central problem of applications such as in-\nformation retrieval (IR) and information ﬁltering. Re-\ncently machine learning technologies called ‘learning\nto rank’ have been successfully applied to ranking, and\nseveral approaches have been proposed, including the\npointwise, pairwise, and listwise approaches.\nThe listwise approach addresses the ranking problem\nin the following way. In learning, it takes ranked lists\nof objects (e.g., ranked lists of documents in IR) as\ninstances and trains a ranking function through the\nminimization of a listwise loss function deﬁned on the\npredicted list and the ground truth list. The listwise\napproach captures the ranking problems, particularly\nthose in IR in a conceptually more natural way than\nprevious work. Several methods such as RankCosine\nand ListNet have been proposed. Previous experi-\nments demonstrate that the listwise approach usually\nperforms better than the other approaches (Cao et al.,\n2007)(Qin et al., 2007).\nExisting work on the listwise approach mainly fo-\ncused on the development of new algorithms, such as\nRankCosine and ListNet. However, there was no suf-\nﬁcient theoretical foundation laid down. Furthermore,\nthe strength and limitation of the algorithms, and the\nrelations between the proposed algorithms were still\n1192\n\nListwise Approach to Learning to Rank - Theory and Algorithm\nnot clear. This largely prevented us from deeply un-\nderstanding the approach, more critically, from devis-\ning more advanced algorithms.\nIn this paper, we aim to conduct an investigation on\nthe listwise approach.\nFirst, we give a formal deﬁnition of the listwise ap-\nproach. In ranking, the input is a set of objects, the\noutput is a permutation of the objects 1, and the model\nis a ranking function which maps a given input to an\noutput. In learning, the training data is drawn i.i.d.\naccording to an unknown but ﬁxed joint probability\ndistribution between input and output. Ideally we\nwould minimize the expected 0 ¡ 1 loss deﬁned on the\npredicted list and the ground truth list. Practically\nwe instead manage to minimize an empirical surrogate\nloss with respect to the training data.\nSecond, we evaluate a surrogate loss function from four\naspects: (a) consistency, (b) soundness, (c) mathemat-\nical properties of continuity, diﬀerentiability, and con-\nvexity, and (d) computational eﬃciency in learning.\nWe give analysis on three loss functions: likelihood\nloss, cosine loss, and cross entropy loss. The ﬁrst one\nis newly proposed in this paper, and the last two were\nused in RankCosine and ListNet, respectively.\nThird, we propose a novel method for the listwise ap-\nproach, which we call ListMLE. ListMLE formalizes\nlearning to rank as a problem of minimizing the likeli-\nhood loss function, equivalently maximizing the likeli-\nhood function of a probability model. Due to the nice\nproperties of the loss function, ListMLE stands to be\nmore eﬀective than RankCosine and ListNet.\nFinally, we have experimentally veriﬁed the correct-\nness of the theoretical ﬁndings. We have also found\nthat ListMLE can signiﬁcantly outperform RankCo-\nsine and ListNet.\nThe rest of the paper is organized as follows. Section\n2 introduces related work. Section 3 gives a formal\ndeﬁnition to the listwise approach. Section 4 conducts\ntheoretical analysis of listwise loss functions. Section 5\nintroduces the ListMLE method. Experimental results\nare reported in Section 6 and the conclusion and future\nwork are given in the last section.\n2. Related Work\nExisting methods for learning to rank fall into three\ncategories. The pointwise approach (Nallapati, 2004)\ntransforms ranking into regression or classiﬁcation on\n1In this paper, we use permutation and ranked list in-\nterchangeably.\nsingle objects. The pairwise approach (Herbrich et al.,\n1999) (Freund et al., 1998) (Burges et al., 2005) trans-\nforms ranking into classiﬁcation on object pairs. The\nadvantage for these two approaches is that existing\ntheories and algorithms on regression or classiﬁcation\ncan be directly applied, but the problem is that they\ndo not model the ranking problem in a straightforward\nfashion. The listwise approach can overcome the draw-\nback of the aforementioned two approaches by tackling\nthe ranking problem directly, as explained below.\nFor instance, Cao et al. (2007) proposed one of the ﬁrst\nlistwise methods, called ListNet. In ListNet, the list-\nwise loss function is deﬁned as cross entropy between\ntwo parameterized probability distributions of permu-\ntations; one is obtained from the predicted result and\nthe other is from the ground truth. Qin et al. (2007)\nproposed another method called RankCosine. In the\nmethod, the listwise loss function is deﬁned on the ba-\nsis of cosine similarity between two score vectors from\nthe predicted result and the ground truth 2. Experi-\nmental results show that the listwise approach usually\noutperforms the pointwise and pariwise approaches.\nIn this paper, we aim to investigate the listwise ap-\nproach to learning to rank, particularly from the view-\npoint of loss functions. Actually similar investigations\nhave also been conducted for classiﬁcation. For in-\nstance, in classiﬁcation, consistency and soundness of\nloss functions are well studied. Consistency forms the\nbasis for the success of a loss function. It is known\nthat if a loss function is consistent, then the learned\nclassiﬁer can achieve the optimal Bayes error rate in\nthe large sample limit. Many well known loss func-\ntions such as hinge loss, exponential loss, and logis-\ntic loss are all consistent (cf., (Zhang, 2004)(Bartlett\net al., 2003)(Lin, 2002)). Soundness of a loss func-\ntion guarantees that the loss can represent well the\ntargeted learning problem. That is, an incorrect pre-\ndiction should receive a larger penalty than a correct\nprediction, and the penalty should reﬂect the conﬁ-\ndence of prediction. For example, hinge loss, exponen-\ntial loss, and logistic loss are sound for classiﬁcation.\nIn contrast, square loss is sound for regression but not\nfor classiﬁcation (Hastie et al., 2001).\n3. Listwise Approach\nWe give a formal deﬁnition of the listwise approach\nto learning to rank. Let X be the input space whose\n2In a broad sense, methods directly optimizing evalua-\ntion measures, such as SVM-MAP (Yue et al., 2007) and\nAdaRank (Xu & Li, 2007) can also be regarded as listwise\nalgorithms. We will, however, limit our discussions in this\npaper on algorithms like ListNet and RankCosine.\n1193\nListwise Approach to Learning to Rank - Theory and Algorithm\nelements are sets of objects to be ranked, Y be the out-\nput space whose elements are permutations of objects,\nand PXY be an unknown but ﬁxed joint probability\ndistribution of X and Y . Let h : X ! Y be a ranking\nfunction, and H be the corresponding function space\n(i.e., h 2 H). Let x 2 X and y 2 Y , and let y(i) be\nthe index of object which is ranked at position i. The\ntask is to learn a ranking function that can minimize\nthe expected loss R(h), deﬁned as:\nR(h) =\n∫\nX×Y\nl(h(x), y)dP (x, y), (1)\nwhere l(h(x), y) is the 0 ¡ 1 loss function such that\nl(h(x), y) =\n{ 1, if h(x) 6= y\n0, if h(x) = y, (2)\nThat is to say, we formalize the ranking problem as\na new ‘classiﬁcation’ problem on permutations. If the\npermutation of the predicted result is the same as the\nground truth, then we have zero loss; otherwise we\nhave one loss. In real ranking applications, the loss\ncan be cost-sensitive, i.e., depending on the positions\nof the incorrectly ranked objects. We will leave this\nas our future work and focus on the 0 ¡ 1 loss in this\npaper ﬁrst. Actually, in the literature of classiﬁcation,\npeople also studied the 0 ¡ 1 loss ﬁrst, before they\neventually moved onto the cost-sensitive case.\nIt is easy to see that the optimal ranking func-\ntion which can minimize the expected loss R(hB) =\ninf R(h) is given by the Bayes rule,\nhB(x) = arg max\ny∈Y\nP (yjx), (3)\nSince PXY is unknown, formula (1) cannot be directly\nsolved and thus hB(x) cannot be easily obtained. In\npractice, we are given independently and identically\ndistributed (i.i.d) samples S = f(x(i), y(i))gm\ni=1 »\nPXY , we instead try to obtain a ranking function\nh 2 H that minimizes the empirical loss.\nRS(h) = 1\nm\nm∑\ni=1\nl(h(x(i)), y(i)). (4)\nNote that for eﬃciency consideration, in practice the\nranking function usually works on individual objects.\nIt assigns a score to each object (by employing a scor-\ning function g), sorts the objects in descending order of\nthe scores, and ﬁnally creates the ranked list. That is\nto say, h(x(i)) is decomposable with respect to objects.\nIt is deﬁned as\nh(x(i)) = sort(g(x(i)\n1 ), . . . , g(x(i)\nni )). (5)\nwhere x(i)\nj 2 x(i), ni denotes the number of objects\nin x(i), g(¢) denotes the scoring function, and sort(¢)\ndenotes the sorting function. As a result, (4) becomes:\nRS(g) = 1\nm\nm∑\ni=1\nl(sort(g(x(i)\n1 ), . . . , g(x(i)\nni )), y(i)). (6)\nDue to the nature of the sorting function and the\n0 ¡ 1 loss function, the empirical loss in (6) is inher-\nently non-diﬀerentiable with respect to g, which poses\na challenge to the optimization of it. To tackle this\nproblem, we can introduce a surrogate loss as an ap-\nproximation of (6), following a common practice in\nmachine learning.\nRφ\nS(g) = 1\nm\nm∑\ni=1\nφ(g(x(i)), y(i)), (7)\nwhere φ is a surrogate loss function and g(x(i)) =\n(g(x(i)\n1 ), . . . , g(x(i)\nni )). For convenience in notation, in\nthe following sections, we sometimes write φy(g) for\nφ(g(x), y) and use bold symbols such as g to denote\nvectors since for a given x, g(x) becomes a vector.\n4. Theoretical Analysis\n4.1. Properties of Loss F unction\nWe analyze the listwise approach from the viewpoint\nof surrogate loss function. Speciﬁcally, we look at\nthe following properties 3 of it: (a) consistency , (b)\nsoundness, (c) continuity, diﬀerentiability, and convex-\nity, and (d) computational eﬃciency in learning.\nConsistency is about whether the obtained ranking\nfunction can converge to the optimal one through the\nminimization of the empirical surrogate loss (7), when\nthe training sample size goes to inﬁnity. It is a nec-\nessary condition for a surrogate loss function to be a\ngood one for a learning algorithm (cf., Zhang (2004)).\nSoundness is about whether the loss function can in-\ndeed represent loss in ranking. For example, an in-\ncorrect ranking should receive a larger penalty than\na correct ranking, and the penalty should reﬂect the\nconﬁdence of the ranking. This property is particu-\nlarly important when the size of training data is small,\nbecause it can directly aﬀect the training results.\n4.2. Consistency\nWe conduct analysis on learning to rank algorithms\nfrom the viewpoint of consistency. As far as we know,\n3In addition, convergence rate is another issue to con-\nsider. We leave it as future work.\n1194\nListwise Approach to Learning to Rank - Theory and Algorithm\nthis is the ﬁrst work discussing the consistency issue\nfor ranking.\nIn the large sample limit, minimizing the empirical\nsurrogate loss (7) amounts to minimizing the following\nexpected surrogate loss\nRφ(g) = EX,Y fφy(g(x))g = EX fQ(g(x))g (8)\nwhere Q(g(x)) =\n∑\ny∈Y\nP (yjx)φy(g(x)).\nHere we assume g(x) is chosen from a vector Borel\nmeasurable function set, whose elements can take any\nvalue from Ω ½ Rn.\nWhen the minimization of (8) can lead to the min-\nimization of the expected 0 ¡ 1 loss (1), we say the\nsurrogate loss function is consistent. A equivalent def-\ninition can be found in Deﬁnition 2. Actually this\nequivalence relationship has been discussed in related\nwork on the consistency of classiﬁcation (Zhang, 2004).\nDeﬁnition 1. We deﬁne Λy as the space of all possible\nprobabilities on the permutation space Y, i.e., ΛY ,\nfp 2 R| Y | : ∑\ny∈Y py = 1, py ¸ 0g.\nDeﬁnition 2. The loss φy(g) is consistent on a set\nΩ ½ Rn with respect to the ranking loss (1), if the\nfollowing conditions hold: 8p 2 ΛY , assume y∗ =\narg maxy∈Y py and Y c\ny∗ denotes the space of permu-\ntations after removing y∗, we have\ninf\ng∈Ω\nQ(g) < inf\ng∈Ω,sort(g)∈Y c\ny∗\nQ(g)\nWe next give suﬃcient conditions of consistency in\nranking.\nDeﬁnition 3. A permutation probability space ΛY is\norder preserving with respect to object i and j, if the\nfollowing conditions hold: 8y 2 Yi,j , fy 2 Y :\ny−1(i) < y −1(j)g where y−1(i) denotes the position for\nobject i in y, denote σ−1y as the permutation which\nexchanges the positions of object i and j while hold\nothers unchanged for y, we have py > p σ−1y.\nDeﬁnition 4. The loss φy(g) is order sensitive on a\nset Ω ½ Rn, if φy(g) is a non-negative diﬀerentiable\nfunction and the following two conditions hold:\n1. 8y 2 Y , 8i < j , denote σy as the permutation\nwhich exchanges the object on position i and that\non position j while holds others unchanged for y,\nif gy(i) < g y(j), then φy(g) ¸ φσy(g) and with at\nleast one y, the strict inequality holds.\n2. If gi = gj, then either 8y 2 Yi,j, ∂φy(g)\n∂gi\n· ∂φy(g)\n∂gj\n,\nor 8y 2 Yi,j, ∂φy(g)\n∂gi\n¸ ∂φy(g)\n∂gj\n, and with at least\none y, the strict inequality holds.\nTheorem 5. Let φy(g) be an order sensitive loss func-\ntion on Ω ½ Rn. 8n objects, if its permutation prob-\nability space is order preserving with respect to n ¡ 1\nobjective pairs (j1, j2), (j2, j3), ¢ ¢ ¢ , (jn ¡ 1, jn). Then\nthe loss φy(g) is consistent with respect to (1).\nDue to space limitations, we only give the proof sketch.\nFirst, we can show if the permutation probability space\nis order preserving with respect to n¡1 objective pairs\n(j1, j2), (j2, j3), ¢ ¢ ¢ , (jn ¡ 1, jn), then the permutation\nwith the maximum probability is y∗ = (j1, j2, ¢ ¢ ¢ , jn).\nSecond, for an order sensitive loss function, for any or-\nder preserving object pairs ( j1, j2), the vector g which\nminimizes Q(g) in (8) should assign a larger score to\nj1 than to j2. This can be proven by the change of loss\ndue to exchanging the scores of j1 and j2. Given all\nthese results and Deﬁnition 2, we can prove Theorem\n5 by means of contradiction.\nTheorem 5 gives suﬃcient conditions for a surrogate\nloss function to be consistent: the permutation prob-\nability space should be order preserving and the func-\ntion should be order sensitive. Actually, the assump-\ntion of order preserving has already been made when\nwe use the scoring function and sorting function for\nranking. The property of order preserving has also\nbeen explicitly or implicitly used in previous work,\nsuch as Cossock and Zhang (2006). The property of\norder sensitive shows that starting with a ground truth\npermutation, the loss will increase if we exchange the\npositions of two objects in it, and the speed of increase\nin loss is sensitive to the positions of objects.\n4.3. Case Studies\nWe look at the four properties of three loss functions.\n4.3.1. Likelihood Loss\nWe introduce a new loss function for listwise approach,\nwhich we call likelihood loss. The likelihood loss func-\ntion is deﬁned as:\nφ(g(x), y) = ¡ log P (yjx; g) (9)\nwhere P (yjx; g) =\nn∏\ni=1\nexp(g(xy(i)))∑n\nk=i exp(g(xy(k))) .\nNote that we actually deﬁne a parameterized exponen-\ntial probability distribution over all the permutations\ngiven the predicted result (by the ranking function),\nand deﬁne the loss function as the negative log likeli-\nhood of the ground truth list. The probability distri-\nbution turns out to be a Plackett-Luce model (Marden,\n1995).\nThe likelihood loss function has the nice properties as\nbelow.\n1195\nListwise Approach to Learning to Rank - Theory and Algorithm\nFirst, the likelihood loss is consistent. The following\nproposition shows that the likelihood loss is order sen-\nsitive. Therefore, according to Theorem 5, it is consis-\ntent. Due to the space limitations, we omit the proof.\nProposition 6. The likelihood loss (9) is order sen-\nsitive on Ω ½ Rn.\nSecond, the likelihood loss function is sound. For sim-\nplicity, suppose that there are two objects to be ranked\n(similar argument can be made when there are more\nobjects). The two objects receive scores of g1 and g2\nfrom a ranking function. Figure 1(a) shows the scores,\nand the point g = ( g1, g2). Suppose that the ﬁrst ob-\nject is ranked below the second object in the ground\ntruth. Then the upper left area above line g2 = g1 cor-\nresponds to correct ranking; and the lower right area\nincorrect ranking. According to the deﬁnition of likeli-\nhood loss, all the points on the line g2 = g1 + d has the\nsame loss. Therefore, we say the likelihood loss only\ndepends on d. Figure 1(b) shows the relation between\nthe loss function and d. We can see the loss function\ndecreases monotonously as d increases. It penalizes\nnegative values of d more heavily than positive ones.\nThis will make the learning algorithm focus more on\navoiding incorrect rankings. In this regard, the loss\nfunction is a good approximation of the 0 ¡ 1 loss.\n2d\ndgg =− 12\n12 gg =\n2g\n1g\ng\n(a)\nd\nφ (b)\nFigure 1. (a) Ranking scores of predicted result; (b) Loss\nφ v.s. d for the likelihood loss.\nThird, it is easy to verify that the likelihood loss is\ncontinuous, diﬀerentiable, and convex (Boyd & Van-\ndenberghe, 2004). Furthermore, the loss can be com-\nputed eﬃciently, with time complexity of linear order\nto the number of objects.\nWith the above good properties, a learning algorithm\nwhich optimizes the likelihood loss will become pow-\nerful for creating a ranking function.\n4.3.2. Cosine Loss\nThe cosine loss is the loss function used in RankCosine\n(Qin et al., 2007), a listwise method. It is deﬁned on\nthe basis of the cosine similarity between the score\nvector of the ground truth and that of the predicted\nresult.\nφ(g(x), y) = 1\n2 (1 ¡ ψy(x)T g(x)\nkψy(x)kkg(x)k ). (10)\nThe score vector of the ground truth is produced by a\nmapping ψy(¢) : Rd ! R, which retains the order in a\npermutation, i.e, ψy(xy(1)) > ¢ ¢ ¢ > ψ y(xy(n)).\nFirst, we can prove that the cosine loss is consistent,\ngiven the following proposition. Due to space limita-\ntions, we omit the proof.\nProposition 7. The cosine loss (10) is order sensitive\non Ω ½ Rn.\nSecond, the cosine loss is not very sound. Let us again\nconsider the case of ranking two objects. Figure 2(a)\nshows point g = (g1, g2) representing the scores of the\npredicted result and point gψ representing the ground\ntruth (which depends on the mapping function ψ). We\ndenote the angle from point g to line g2 = g1 as α, and\nthe angle from gψ to line g2 = g1 as αgψ . We inves-\ntigate the relation between the loss and the angle α.\nFigure 2(b) shows the cosine loss as a function of α.\nFrom this ﬁgure, we can see that the cosine loss is\nnot a monotonously decreasing function of α. When\nα > α gψ , it increases quickly, which means that it\ncan heavily penalize correct rankings. Furthermore,\nthe mapping function and thus αgψ can also aﬀect the\nloss function. Speciﬁcally, the curve of the loss func-\ntion can shift from left to right with diﬀerent values\nof αgψ . Only when αgψ = π/2, it becomes a rela-\ntively satisfactory representation of loss for the learn-\ning problem.\nψg\n1g\n2g\n12 gg =g\nα\n(a)\n−π αgψ π α\nφ (b)\nFigure 2. (a) Ranking scores of predicted result and ground\ntruth; (b) Loss φ v.s. angle α for the cosine loss.\nThird, it is easy to see that the cosine loss is contin-\nuous, diﬀerentiable, but not convex. It can also be\ncomputed in an eﬃcient manner with a time complex-\nity linear to the number of objects.\n1196\nListwise Approach to Learning to Rank - Theory and Algorithm\n4.3.3. Cross Entropy Loss\nThe cross entropy loss is the loss function used in List-\nNet (Cao et al., 2007), another listwise method. The\ncross entropy loss function is deﬁned as:\nφ(g(x), y) = D(P (πjx; ψy)jjP (πjx; g)) (11)\nwhere P (πjx; ψy) =\nn∏\ni=1\nexp(ψy(xπ(i)))∑n\nk=i exp(ψy(xπ(k)))\nP (πjx; g) =\nn∏\ni=1\nexp(g(xπ(i)))∑n\nk=i exp(g(xπ(k)))\nwhere ψ is a mapping function whose deﬁnition is sim-\nilar to that in RankCosine.\nFirst, we can prove that the cross entropy loss is con-\nsistent, given the following proposition. Due to space\nlimitations, we omit the proof.\nProposition 8. The cross entropy loss (11) is order\nsensitive on Ω ½ Rn.\nSecond, the cross entropy loss is not very sound.\nAgain, we look at the case of ranking two objects.\ng = (g1, g2) denotes the ranking scores of the predicted\nresult. gψ denotes the ranking scores of the ground\ntruth (depending on the mapping function). Similar\nto the discussions in the likelihood loss, the cross en-\ntropy loss only depends on the quantity d. Figure 3(a)\nillustrates the relation between g, gψ, and d. Figure\n3(b) shows the cross entropy loss as a function of d. As\ncan be seen that the loss function achieves its minimum\nat point dgψ , and then increases as d increases. That\nmeans it can heavily penalize those correct rankings\nwith higher conﬁdence. Note that the mapping func-\ntion also aﬀects the penalization. According to map-\nping functions, the penalization on correct rankings\ncan be even larger than that on incorrect rankings.\n2d\ndgg =− 12\n12 gg =\n2g\n1g\nψgg\n(a)\ndgψ d\nφ (b)\nFigure 3. (a) Ranking scores of predicted result and ground\ntruth; (b) Loss φ v.s. d for the cross entropy loss.\nThird, it is easy to see that the cross entropy loss is\ncontinuous and diﬀerentiable. It is also convex because\nthe log of a convex function is still convex, and the\nAlgorithm 1 ListMLE Algorithm\nInput: training data f(x(1), y(1)), . . . ,(x(m), y(m))g\nParameter: learning rate η, tolerance rate ²\nInitialize parameter ω\nrepeat\nfor i = 1 to m do\nInput ( x(i), y(i)) to Neural Network and compute\ngradient 4ω with current ω\nUpdate ω = ω ¡ η £ 4ω\nend for\ncalculate likelihood loss on the training set\nuntil change of likelihood loss is below ²\nOutput: Neural Network model ω\nset of convex function is closed under addition (Boyd\n& Vandenberghe, 2004). However, it cannot be com-\nputed in an eﬃcient manner. The time complexity is\nof exponential order to the number of objects.\nTable 1 gives a summary of the properties of the loss\nfunctions. All the three loss functions as aforemen-\ntioned are consistent, as well as continuous and diﬀer-\nentiable. The likelihood loss is better than the cosine\nloss in terms of convexity and soundness, and is better\nthan the cross entropy loss in terms of time complexity\nand soundness.\n5. ListMLE\nWe propose a novel listwise method referred to as\nListMLE. In learning of ListMLE, we employ the like-\nlihood loss as the surrogate loss function, since it is\nproven to have all the nice properties as a surrogate\nloss. On the training data, we actually maximize the\nsum of the likelihood function with respect to all the\ntraining queries.\nm∑\ni=1\nlog P (y(i)jx(i); g). (12)\nWe choose Stochastic Gradient Descent (SGD) as the\nalgorithm for conducting the minimization. As rank-\ning model, we choose linear Neural Network (param-\neterized by ω). Algorithm 1 shows the learning algo-\nrithm based on SGD.\n6. Experimental Results\nWe conducted two experiments to verify the correct-\nness of the theoretical ﬁndings. One data set is syn-\nthetic data, and the other is the LETOR benchmark\ndata for learning to rank (Liu et al., 2007).\n1197\nListwise Approach to Learning to Rank - Theory and Algorithm\nTable 1. Comparison between diﬀerent surrogate losses.\nLoss Consistency Soundness Continuity Diﬀerentiability Convexity Complexity\nLikelihood p p p p p O(n)\nCosine p £ p p £ O(n)\nCross entropy p £ p p p O(n! ¢ n)\n6.1. Experiment on Synthetic Data\nWe conducted an experiment using a synthetic data\nset. We created the data as follows. First, we ran-\ndomly sample a point according to the uniform dis-\ntribution on the square area [0 , 1] £ [0, 1]. Then we\nassign to the point a score using the following rule,\ny = x1 + 10x2 + ² where ² denotes a random variable\nnormally distributed with mean of zero and standard\ndeviation of 0 .005. In total, we generate 15 points and\ntheir scores in this way, and create a permutation on\nthe points based on their scores, which forms an in-\nstance of ranking. We repeat the process and make\n100 training instances, 100 validation instances, and\n100 testing instances. We applied RankCosine, List-\nNet4, and ListMLE to the data.\nWe tried diﬀerent score mapping functions for\nRankCosine and ListNet, and used ﬁve most represen-\ntative ones, i.e., log(15 ¡ r), p15 ¡ r, 15 ¡ r, (15 ¡ r)2\nand exp(15 ¡ r), where r denotes the positions of ob-\njects. We denote the mapping functions as log, sqrt,\nl, q, and exp for simplicity. The experiments were re-\npeated 20 times with diﬀerent initial values of param-\neters in the Neural Network model. Table 2 shows\nthe means and standard deviations of the accuracies\nand Mean Average Precision (MAP)(Baeza-Yates &\nRibeiro-Neto, 1999) of the three algorithms. The ac-\ncuracy measures the proportion of correctly ranked in-\nstances and MAP 5 is a commonly used measure in IR.\nAs shown in the table, ListMLE achieves the best per-\nformance among all the algorithms in terms of both\naccuracy and MAP, owing to good properties of its loss\nfunction. The accuracies of RankCosine and ListNet\nvary according to the mapping functions. Especially,\nRankCosine achieves an accuracy of only 0 .047 when\nusing the mapping function exp while 0.917 when using\nthe mapping function l. This result indicates that the\nperformances of the cosine loss and the cross entropy\nloss depend on the mapping functions, while ﬁnding a\nsuitable mapping function is not easy. Furthermore,\nRankCosine has a larger variance than ListMLE and\nListNet. The likely explanation is that RankCosine’s\n4The top-1 version of the cross entropy loss was em-\nployed as in the original work (Cao et al., 2007).\n5When calculating MAP, we treated the top-1 items as\nrelevant and the other as irrelevant.\nTable 2. The performance of three algorithms on the syn-\nthetic data set.\nAlgorithm Accuracy MAP\nListMLE 0.92 § 0.011 0 .999 § 0.002\nListNet-log 0.905 § 0.010 0 .999 § 0.002\nListNet-sqrt 0.917 § 0.009 0 .999 § 0.002\nListNet-l 0.767 § 0.021 0 .995 § 0.003\nListNet-q 0.868 § 0.028 0 .999 § 0.002\nListNet-exp 0.832 § 0.074 0 .997 § 0.004\nRankCosine-log 0 .180 § 0.217 0 .948 § 0.034\nRankCosine-sqrt 0 .080 § 0.159 0 .886 § 0.056\nRankCosine-l 0 .917 § 0.112 0 .999 § 0.002\nRankCosine-q 0 .102 § 0.161 0 .890 § 0.060\nRankCosine-exp 0 .047 § 0.163 0 .746 § 0.136\nperformance is sensitive to the initial values of param-\neters due to the non-convexity of its loss function.\n6.2. Experiment on OHSUMED Data\nWe also conducted an experiment on OHSUMED, a\nbenchmark data set for learning to rank provided in\nLETOR. There are in total 106 queries, and 16,140\nquery-document pairs upon which relevance judg-\nments are made. The relevance judgments are either\ndeﬁnitely relevant, possibly relevant, or not relevant.\nThe data was in the form of feature vector and rele-\nvance label. There are in total 25 features. We used\nthe data split provided in LETOR to conduct ﬁve-fold\ncross validation experiments. In evaluation, besides\nMAP, we adopted another measures commonly used in\nIR: Normalized Discounted Cumulative Gain (NDCG)\n(Jarvelin & Kekanainen, 2000).\nNote that here the ground truth in the data is given as\npartial ranking, while the methods need to use total\nranking (permutation) in training. To bridge the gap,\nfor RankCosine and ListNet, we adopted the methods\nproposed in the papers (Cao et al., 2007) (Qin et al.,\n2007). For ListMLE we randomly selected one perfect\npermutation for each query from among the possible\nperfect permutations based on the ground truth.\nWe applied RankCosine, ListNet, and ListMLE to\nthe data. The results reported below are those aver-\naged over ﬁve trials. As shown in Figure 4, ListMLE\nachieves the best performance among all the algo-\nrithms. Especially, on NDCG@1, it has more than\n1198\nListwise Approach to Learning to Rank - Theory and Algorithm\n5-point gains over RankCosine which is at the sec-\nond place. We also conducted the t-test on the im-\nprovements of ListMLE over the other two algorithms.\nThe results show that the improvements are statisti-\ncally signiﬁcant for NDCG@5, NDCG@7, NDCG@8,\nNDCG@9, and NDCG@10 (p-value < 0.05).\n0.5 \n0.52 \n0.54 \n0.56 \n0.58 \nListMLE \nListNet \n0.42 \n0.44 \n0.46 \n0.48 \n0.5 \nMAP NDCG@1 NDCG@2 NDCG@3 NDCG@4 NDCG@5 NDCG@6 NDCG@7 NDCG@8 NDCG@9 NDCG@10 \nRankCosine \nFigure 4. Ranking performance on OHSUMED data.\n7. Conclusion\nIn this paper, we have investigated the theory and al-\ngorithms of the listwise approach to learning to rank.\nWe have pointed out that to understand the eﬀective-\nness of a learning to rank algorithm, it is necessary to\nconduct theoretical analysis on its loss function. We\npropose investigating a loss function from the view-\npoints of (a) consistency, (b) soundness, (c) continu-\nity, diﬀerentiability, convexity, and (d) eﬃciency. We\nhave obtained some theoretical results on consistency\nof ranking. We have conducted analysis on the likeli-\nhood loss, cosine loss, and cross entropy loss. The re-\nsult indicates that the likelihood loss has better prop-\nerties than the other two losses. We have then de-\nveloped a new learning algorithm using the likelihood\nloss, called ListMLE and demonstrated its eﬀective-\nness through experiments.\nThere are several directions which we can further ex-\nplore. (1) We want to conduct more theoretical anal-\nysis on the properties of loss functions, for example,\nweaker conditions for consistency and the rates of con-\nvergence. (2) We plan to study the case where cost-\nsensitive loss function is used instead of the 0 ¡ 1 loss\nfunction in deﬁning the expected loss. (3) We plan\nto investigate other surrogate loss functions with the\ntools we have developed in this paper.\nReferences\nBaeza-Yates, R., & Ribeiro-Neto, B. (Eds.). (1999). Mod-\nern information retrieval . Addison Wesley.\nBartlett, P. L., Jordan, M. I., & McAuliﬀe, J. D. (2003).\nConvexity, classiﬁcation, and risk bounds (Technical Re-\nport 638). Statistics Department, University of Califor-\nnia, Berkeley.\nBoyd, S., & Vandenberghe, L. (Eds.). (2004). Convex op-\ntimization. Cambridge University.\nBurges, C., Shaked, T., Renshaw, E., Lazier, A., Deeds,\nM., Hamilton, N., & Hullender, G. (2005). Learning to\nrank using gradient descent. Proceedings of ICML 2005\n(pp. 89–96).\nCao, Z., Qin, T., Liu, T. Y., Tsai, M. F., & Li, H. (2007).\nLearning to rank: From pairwise approach to listwise\napproach. Proceedings of the 24th International Con-\nference on Machine Learning (pp. 129–136). Corvallis,\nOR.\nCossock, D., & Zhang, T. (2006). Subset ranking using\nregression. COLT (pp. 605–619).\nFreund, Y., Iyer, R., Schapire, R. E., & Singer, Y. (1998).\nAn eﬃcient boosting algorithm for combining prefer-\nences. Proceedings of ICML (pp. 170–178).\nHastie, T., Tibshirani, R., & Friedman, J. H. (Eds.).\n(2001). The elements of statistical learning: Data min-\ning, inference and prediction . Springer.\nHerbrich, R., Graepel, T., & Obermayer, K. (1999). Sup-\nport vector vector learning for ordinal regression. Pro-\nceedings of ICANN (pp. 97–102).\nJarvelin, K., & Kekanainen, J. (2000). Ir evaluation meth-\nods for retrieving highly relevant documents. Proceed-\nings of SIGIR (pp. 41–48).\nLin, Y. (2002). Support vector machines and the bayes rule\nin classiﬁcation. Data Mining and Knowledge Discovery ,\n259–275.\nLiu, T. Y., Qin, T., Xu, J., Xiong, W. Y., & Li, H. (2007).\nLetor: Benchmark dataset for research on learning to\nrank for information retrieval. Proceedings of SIGIR.\nMarden, J. I. (Ed.). (1995). Analyzing and modeling rank\ndata. London: Chapman and Hall.\nNallapati, R. (2004). Discriminative models for informa-\ntion retrieval. Proceedings of SIGIR (pp. 64–71).\nQin, T., Zhang, X.-D., Tsai, M.-F., Wang, D.-S., Liu, T.-\nY., & Li, H. (2007). Query-level loss functions for infor-\nmation retrieval. Information processing and manage-\nment.\nXu, J., & Li, H. (2007). Adarank: a boosting algorithm\nfor information retrieval. Proceedings of SIGIR (pp. 391–\n398).\nYue, Y., Finley, T., Radlinski, F., & Joachims, T. (2007).\nA support vector method for optimization average pre-\ncision. Proceedings of SIGIR (pp. 271–278).\nZhang, T. (2004). Statistical analysis of some multi-\ncategory large margin classiﬁcation methods. Journal\nof Machine Learning Research , 5, 1225–1251.\n1199",
  "values": {
    "Privacy": "Yes",
    "Justice": "Yes",
    "Critiqability": "Yes",
    "User influence": "Yes",
    "Respect for Persons": "Yes",
    "Collective influence": "Yes",
    "Explicability": "Yes",
    "Not socially biased": "Yes",
    "Fairness": "Yes",
    "Beneficence": "Yes",
    "Deferral to humans": "Yes",
    "Non-maleficence": "Yes",
    "Interpretable (to users)": "Yes",
    "Respect for Law and public interest": "Yes",
    "Transparent (to users)": "Yes",
    "Autonomy (power to decide)": "Yes"
  }
}