{
  "pdf": "1553374.1553434",
  "title": "An accelerated gradient method for trace norm minimization",
  "author": "Shuiwang Ji, Jieping Ye",
  "paper_id": "1553374.1553434",
  "text": "An Accelerated\nGradient Method for Trace Norm Minimization\nShuiw\nang Ji shuiwang.ji@asu.edu\nJieping Y e jieping.ye@asu.edu\nDepartment of Computer Science and Engineering, Arizona State University, Tempe, AZ 85287, USA\nAbstract\nWe consider the minimization of a smooth\nloss function regularized by the trace norm\nof the matrix variable. Such formulation ﬁnds\napplications in many machine learning tasks\nincluding multi-task learning, matrix classi-\nﬁcation, and matrix completion. The stan-\ndard semideﬁnite programming formulation\nfor this problem is computationally expen-\nsive. In addition, due to the non-smooth na-\nture of the trace norm, the optimal ﬁrst-order\nblack-box method for solving such class of\nproblems converges as O( 1\n√\nk ), where k is\nthe\niteration counter. In this paper, we exploit\nthe special structure of the trace norm, based\non which we propose an extended gradient al-\ngorithm that converges as O( 1\nk ). W\ne further\npropose an accelerated gradient algorithm,\nwhich achieves the optimal convergence rate\nof O( 1\nk2 ) for\nsmooth problems. Experiments\non multi-task learning problems demonstrate\nthe eﬃciency of the proposed algorithms.\n1. Introduction\nThe problem of minimizing the rank of a matrix vari-\nable subject to certain constraints arises in many ﬁelds\nincluding machine learning, automatic control, and\nimage compression. For example, in collaborative ﬁl-\ntering we are given a partially ﬁlled rating matrix and\nthe task is to predict the missing entries. Since it is\ncommonly believed that only a few factors contribute\nto an individual’s tastes, it is natural to approximate\nthe given rating matrix by a low-rank matrix. How-\never, the matrix rank minimization problem is NP-\nhard in general due to the combinatorial nature of the\nrank function. A commonly-used convex relaxation of\nthe rank function is the trace norm (nuclear norm)\nAppearing\nin Proceedings of the 26 th International Confer-\nence on Machine Learning , Montreal, Canada, 2009. Copy-\nright 2009 by the author(s)/owner(s).\n(Fazel et al., 2001), deﬁned as the sum of the singu-\nlar values of the matrix, since it is the convex enve-\nlope of the rank function over the unit ball of spectral\nnorm. A number of recent work has shown that the low\nrank solution can be recovered exactly via minimizing\nthe trace norm under certain conditions (Recht et al.,\n2008a; Recht et al., 2008b; Cand´ es & Recht, 2008).\nIn practice, the trace norm relaxation has been shown\nto yield low-rank solutions and it has been used widely\nin many scenarios. In (Srebro et al., 2005; Rennie &\nSrebro, 2005; Weimer et al., 2008a; Cai et al., 2008; Ma\net al., 2008) the matrix completion problem was formu-\nlated as a trace norm minimization problem. In prob-\nlems where multiple related tasks are learned simul-\ntaneously, the models for diﬀerent tasks can be con-\nstrained to share certain information. Recently, this\nconstraint has been expressed as the trace norm regu-\nlarization on the weight matrix in the context of multi-\ntask learning (Abernethy et al., 2006; Argyriou et al.,\n2008; Abernethy et al., 2009; Obozinski et al., 2009),\nmulti-class classiﬁcation (Amit et al., 2007), and mul-\ntivariate linear regression (Yuan et al., 2007; Lu et al.,\n2008). For two-dimensional data such as images, the\nmatrix classiﬁcation formulation (Tomioka & Aihara,\n2007; Bach, 2008) applies a weight matrix, regular-\nized by its trace norm, on the data. It was shown\n(Tomioka & Aihara, 2007) that such formulation leads\nto improved performance over conventional methods.\nA practical challenge in employing the trace norm reg-\nularization is to develop eﬃcient algorithms to solve\nthe resulting non-smooth optimization problems. It is\nwell-known that the trace norm minimization problem\ncan be formulated as a semideﬁnite program (Fazel\net al., 2001; Srebro et al., 2005). However, such formu-\nlation is computationally expensive. To overcome this\nlimitation, a number of algorithms have been devel-\noped recently (Rennie & Srebro, 2005; Weimer et al.,\n2008a; Weimer et al., 2008b; Cai et al., 2008; Ma et al.,\n2008). In these algorithms some form of approxima-\ntion is usually employed to deal with the non-smooth\ntrace norm term. However, a fast global convergence\n457\n\nAn Accelerated\nGradient Method for T race Norm Minimization\nrate for these algorithms is diﬃcult to guarantee.\nDue to the non-smooth nature of the trace norm, a\nsimple approach to solve these problems is the subgra-\ndient method (Bertsekas, 1999; Nesterov, 2003), which\nconverges as O( 1\n√\nk ) where k is\nthe iteration counter.\nIt is known from the complexity theory of convex opti-\nmization (Nemirovsky & Yudin, 1983; Nesterov, 2003)\nthat this convergence rate is already optimal for non-\nsmooth optimization under the ﬁrst-order black-box\nmodel, where only the function values and ﬁrst-order\nderivatives are used.\nIn this paper we propose eﬃcient algorithms with fast\nglobal convergence rates to solve trace norm regu-\nlarized problems. Speciﬁcally, we show that by ex-\nploiting the special structure of the trace norm, the\nclassical gradient method for smooth problems can\nbe adapted to solve the trace norm regularized non-\nsmooth problems. This results in an extended gra-\ndient algorithm with the same convergence rate of\nO( 1\nk ) as\nthat for smooth problems. Following the Nes-\nterov’s method for accelerating the gradient method\n(Nesterov, 1983; Nesterov, 2003), we show that the\nextended gradient algorithm can be further acceler-\nated to converge as O( 1\nk2 ), whic\nh is the optimal con-\nvergence rate for smooth problems. Hence, the non-\nsmoothness eﬀect of the trace norm regularization is\neﬀectively removed. The proposed algorithms extend\nthe algorithms in (Nesterov, 2007; Tseng, 2008; Beck\n& Teboulle, 2009) to the matrix case. Experiments\non multi-task learning problems demonstrate the eﬃ-\nciency of the proposed algorithms in comparison with\nexisting ones. Note that while the present paper was\nunder review, we became aware of a recent preprint by\nToh and Yun (2009) who independently developed an\nalgorithm that is similar to ours.\n2. Problem Formulation\nIn this paper we consider the following problem:\nmin\nW\nF (W ) = f (W ) + λ||W||∗ (1)\nwhere W ∈ Rm×n is the decision matrix, f (·) repre-\nsents the loss induced by some convex smooth (diﬀer-\nentiable) loss function ℓ(·, ·), and || · ||∗ denotes the\ntrace norm deﬁned as the sum of the singular values.\nWe assume that the gradient of f (·), denoted as ▽f (·),\nis Lipschitz continuous with constant L, i.e.,\n|| ▽f (X) − ▽f(Y )||F ≤ L||X− Y ||F , ∀X, Y ∈Rm×n,\nwhere || · ||F denotes the Frobenius norm. Such formu-\nlation arises in many machine learning tasks such as in\nmulti-task learning, matrix classiﬁcation, and matrix\ncompletion problems.\n• Multi-task learning (Argyriou et al., 2008):\nf (W ) = ∑n\ni=1\n∑si\nj=1 ℓ(yj\ni , wT\ni xj\ni ), where n is the\nnumber of tasks, (x j\ni , yj\ni ) ∈Rm ×R is the jth sam-\nple in the ith task, si is the number of samples in\nthe ith task, and W = [w1, · · · , wn] ∈Rm×n.\n• Matrix classiﬁcation (Tomioka & Aihara, 2007;\nBach, 2008): f (W ) = ∑s\ni=1 ℓ(yi, Tr(WT Xi)),\nwhere ( Xi, yi) ∈Rm×n ×R is the ith sample.\n• Matrix completion (Srebro et al., 2005; Cand´ es\n& Recht, 2008; Recht et al., 2008a; Ma et al.,\n2008): f (W ) = ∑\n(i,j)∈Ω ℓ(Mij, Wij), where M ∈\nRm×n is the partially observed matrix with the\nentries in Ω being observed.\nSince the trace norm term in the objective function in\nEq. (1) is non-smooth, a natural approach for solving\nthis problem is the subgradient method in which a\nsequence of approximate solutions are generated as\nWk = Wk−1 − 1\ntk\nF ′(Wk−1), (2)\nwhere Wk is the\napproximate solution at the kth it-\neration, 1\ntk\nis the\nstep size, and F ′(W ) ∈ ∂F (W ) is\nthe subgradient of F (W ) at W and ∂F (W ) denotes\nthe subdiﬀerential (Bertsekas, 1999; Nesterov, 2003)\nof F (W ) at W . It is known (Nesterov, 2003) that the\nsubgradient method converges as O( 1\n√\nk ), i.e.,\nF (\nWk) − F (W ∗) ≤ c 1√\nk\n, (3)\nfor some\nconstant c, where W ∗ = arg minW F (W ).\nIt is known from the complexity theory of convex\noptimization (Nemirovsky & Yudin, 1983; Nesterov,\n2003) that this convergence rate is already optimal\nfor non-smooth problems under the ﬁrst-order black-\nbox model. Hence, the convergence rate cannot be im-\nproved if a black-box model, which does not exploit\nany special structure of the objective function, is em-\nployed. We show in the following that by exploiting\nthe structure of the trace norm, its non-smoothness\ncan be eﬀectively overcome and the convergence rate\nof the algorithm for solving the trace norm regularized\nproblem in Eq. (1) can be improved signiﬁcantly.\n3. An Extended Gradient Method\nFirst, consider the minimization of the smooth loss\nfunction without the trace norm regularization:\nmin\nW\nf (W ). (4)\n458\nAn Accelerated\nGradient Method for T race Norm Minimization\nIt is known (Bertsekas, 1999) that the gradient step\nWk = Wk−1 − 1\ntk\n▽ f (Wk−1) (5)\nfor\nsolving this smooth problem can be reformulated\nequivalently as a proximal regularization of the lin-\nearized function f (W ) at Wk−1 as\nWk = arg min\nW\nPtk (W, Wk−1), (6)\nwhere\nPtk (W, Wk−1) = f (Wk−1) + ⟨W − Wk−1, ▽f (Wk−1)⟩\n+ tk\n2 ||W − Wk−1||2\nF , (7)\nand ⟨A, B⟩ =\nTr(AT B) denotes the matrix inner prod-\nuct. It has been shown (Nesterov, 2003) that the con-\nvergence rate of this algorithm is O( 1\nk ). Note\nthat the\nfunction Ptk deﬁned in Eq. (7) can be considered as a\nlinear approximation of the function f at point Wk−1\nregularized by a quadratic proximal term.\nBased on this equivalence relationship, we propose to\nsolve the optimization problem in Eq. (1) by the fol-\nlowing iterative step:\nWk=arg min\nW\nQtk (W, Wk−1)≜Ptk (W, Wk−1) + λ||W||∗.\n(8)\nA key motivation for this formulation is that if the\noptimization problem in Eq. (8) can be easily solved\nby exploiting the structure of the trace norm, the con-\nvergence rate of the resulting algorithm is expected\nto be the same as that of gradient method, since no\napproximation on the non-smooth term is employed.\nBy ignoring terms that do not depend on W , the ob-\njective in Eq. (8) can be expressed equivalently as\ntk\n2\n⏐⏐⏐⏐\n⏐\n⏐⏐⏐W −\n(\nWk−1 − 1\ntk\n▽ f (Wk−1)\n)⏐\n⏐⏐⏐\n⏐\n⏐⏐⏐\n2\nF\n+ λ ||W ||∗ .\n(9)\nIt turns\nout that the minimization of the objective in\nEq. (9) can be solved by ﬁrst computing the singular\nvalue decomposition (SVD) of Wk−1 − 1\ntk\n▽ f (Wk−1)\nand then\napplying some soft-thresholding on the sin-\ngular values. This is summarized in the following the-\norem (Cai et al., 2008).\nTheorem 3.1. Let C ∈ Rm×n and let C = U ΣV T\nbe the SVD of C where U ∈ Rm×r and V ∈ Rn×r\nhave orthonormal columns, Σ ∈Rr×r is diagonal, and\nr = rank(C). Then\nTλ(C) ≡ arg min\nW\n{ 1\n2 ||W − C||2\nF + λ||W||∗\n}\n(10)\nis given\nby Tλ(C) = U ΣλV T , where Σλ is diagonal\nwith (Σλ)ii = max{0,Σii − λ}.\nThe proof of this theorem is in the Appendix.\nThe above discussion shows that the problem in\nEq. (8) can be readily solved by SVD. Furthermore,\nwe show in the following that if the step size 1\ntk\nof the\ngradien\nt method is chosen properly, we can achieve\nthe same convergence rate as in the smooth case, i.e.,\nO( 1\nk ), despite\nthe presence of the non-smooth trace\nnorm regularization.\n3.1. Step Size Estimation\nTo choose an appropriate step size we impose a con-\ndition on the relationship between the function values\nof F and Qtk at a certain point in Lemma 3.1. We\nshow in Theorem 3.2 below that once this condition is\nsatisﬁed at each step by choosing an appropriate step\nsize, the convergence rate of the resulting sequence can\nbe guaranteed.\nLemma 3.1. Let\npµ(Y ) = arg min\nX\nQµ(X, Y ) (11)\nwhere Q is deﬁned in Eq. (8). Assume the following\ninequality holds:\nF (pµ(Y )) ≤ Qµ(pµ(Y ), Y ). (12)\nThen for any X ∈Rm×n we have\nF (X) − F (pµ(Y )) ≥ µ\n2 ||pµ(Y ) − Y ||2\nF (13)\n+µ⟨Y − X,\npµ(Y ) − Y ⟩.\nThe proof of this lemma is in the Appendix.\nAt each step of the algorithm we need to ﬁnd an ap-\npropriate value for µ such that Wk = pµ(Wk−1) and\nthe condition\nF (Wk) ≤ Qµ(Wk, Wk−1) (14)\nis satisﬁed. Note that since the gradient of f (·) is Lip-\nschitz continuous with constant L, we have (Nesterov,\n2003)\nf (X) ≤ f (Y ) +⟨X − Y, ▽f (Y )⟩ + L\n2 ||X − Y ||2\nF , ∀X,\nY.\nHence, when µ ≥ L we have\nF (pµ(Y ))≤Pµ(pµ(Y ), Y )+λ||pµ(Y )||∗ =Qµ(pµ(Y ), Y ).\nThis shows that the condition in Eq. (14) is always\nsatisﬁed if the update rule\nWk = pL(Wk−1) (15)\n459\nAn Accelerated\nGradient Method for T race Norm Minimization\nis applied. However, L may not be known or it is ex-\npensive to compute in practice. We propose to employ\nthe following step size estimation strategy to ensure\nthe condition in Eq. (14): Given an initial estimate\nof L as L0, we increase this estimate with a multi-\nplicative factor γ > 1 repeatedly until the condition in\nEq. (14) is satisﬁed. This results in the extended gra-\ndient method in Algorithm 1 for solving the problem\nin Eq. (1).\nAlgorithm 1 Extended\nGradient Algorithm\nInitialize L0, γ\n, W0 ∈Rm×n\nIterate:\n1. Set ¯L = Lk−1\n2. While F (p ¯L(Wk−1)) > Q ¯L(p ¯L(Wk−1), Wk−1), set\n¯L := γ ¯L\n3. Set Lk = ¯L and Wk = pLk (Wk−1)\nSince when Lk ≥ L the\ncondition in Eq. (14) is always\nsatisﬁed, we have\nLk ≤ γL, ∀k. (16)\nNote that the sequence of function values generated\nby this algorithm is non-increasing as\nF (Wk)≤QLk (Wk, Wk−1)≤QLk (Wk−1, Wk−1)=F (Wk−1).\n3.2. Convergence Analysis\nWe show in the following theorem that when the con-\ndition in Eq. (14) is satisﬁed at each iteration, the\nextended gradient algorithm converges as O( 1\nk ).\nTheorem 3.2. L\net {Wk}be the sequence generated by\nAlgorithm 1. Then for any k ≥ 1 we have\nF (Wk) − F (W ∗) ≤ γL||W0 − W ∗||2\nF\n2k , (17)\nwhere W ∗ =\narg minW F (W ).\nThe proof of this theorem is in the Appendix.\n4. An Accelerated Gradient Method\nIt is known (Nesterov, 1983; Nesterov, 2003) that when\nthe objective function is smooth, the gradient method\ncan be accelerated to achieve the optimal convergence\nrate of O( 1\nk2 ). It\nwas shown recently (Nesterov, 2007;\nTseng, 2008; Beck & Teboulle, 2009) that a similar\nscheme can be applied to accelerate optimization prob-\nlems where the objective function consists of a smooth\npart and a non-smooth part provided that the non-\nsmooth part is “simple”. In particular, it was shown\nthat the ℓ1-norm regularized problems can be acceler-\nated even though they are not smooth. In this section\nwe show that the extended gradient method in Algo-\nrithm 1 can also be accelerated to achieve the optimal\nconvergence rate of smooth problems even though the\ntrace norm is not smooth. This results in the acceler-\nated gradient method in Algorithm 2.\nAlgorithm 2 Accelerated\nGradient Algorithm\nInitialize L0, γ\n, W0 = Z1 ∈Rm×n, α1 = 1\nIterate:\n1. Set ¯L = Lk−1\n2. While F (p ¯L(Zk−1)) > Q ¯L(p ¯L(Zk−1), Zk−1), set\n¯L := γ ¯L\n3. Set Lk = ¯L and update\nWk = pLk (Zk)\nαk+1 = 1 +\n√\n1 +\n4α2\nk\n2 (18)\nZk+1 = Wk +\n( αk − 1\nαk+1\n)\n(Wk − Wk−1) (19)\n4.1. Discussion\nIn\nthe accelerated gradient method, two sequences\n{Wk} and {Zk} are updated recursively. In partic-\nular, Wk is the approximate solution at the kth step\nand Zk is called the search point (Nesterov, 1983; Nes-\nterov, 2003), which is constructed as a linear combina-\ntion of the latest two approximate solutions Wk−1 and\nWk−2. The key diﬀerence between the extended and\nthe accelerated algorithms is that the gradient step\nis performed at the current approximate solution Wk\nin the extended algorithm, while it is performed at\nthe search point Zk in the accelerated scheme. The\nidea of constructing the search point is motivated by\nthe investigation of the information-based complexity\n(Nemirovsky & Yudin, 1983; Nesterov, 2003), which\nreveals that for smooth problems the convergence rate\nof the gradient method is not optimal, and thus meth-\nods with a faster convergence rate should exist. The\nderivation of the search point is based on the concept\nof estimate sequence and more details can be found in\n(Nesterov, 2003). Note that the sequence αk can be\nupdated in many ways as long as certain conditions\nare satisﬁed (Nesterov, 2003). Indeed, it was shown\nin (Tseng, 2008) that other schemes of updating αk\n460\nAn Accelerated\nGradient Method for T race Norm Minimization\nTable\n1. Comparison of the three multi-task learning algorithms (EGM, AGM, and MFL) in terms of the computation\ntime (in seconds). In each case, the computation time reported is the time used to train the model for a given parameter\nvalue obtained by cross validation, and the averaged training time over ten random trials is reported.\nDa\nta set yeast letters digits dmoz\nPercent\nage 5% 10% 5% 10% 5% 10% 5% 10%\nEGM 2.24 3.37 4.74 5.67 62.51 29.59 133.21 146.58\nAGM 0.34 0.49 0.62 0.91 2.41 2.39 1.59 1.42\nMFL 2.33 17.27 2.49 9.66 15.50 42.64 74.24 31.49\n0 20 40 60 80 100350\n400\n450\n500\n550\n600\nIteration\nObjective value\n \n \nAGM\nEGM\n0 20 40 60 80 100 120750\n800\n850\n900\n950\n1000\n1050\nIteration\nObjective value\n \n \nAGM\nEGM\nFigure 1. The\nconvergence of EGM and AGM on the yeast data set when 5% (left ﬁgure) and 10% (right ﬁgure) of the\ndata are used for training. On the ﬁrst data set EGM and AGM take 81 and 1122 iterations, respectively, to converge,\nwhile on the second data set they take 108 and 773 iterations, respectively.\ncan lead to better practical performance, though the\ntheoretical convergence rate remains the same. Note\nthat the sequence of objective values generated by the\naccelerated scheme may increase. It, however, can be\nmade non-increasing by a simple modiﬁcation of the\nalgorithm as in (Nesterov, 2005).\n4.2. Convergence Analysis\nWe show in the following that by performing the gra-\ndient step at the search point Zk instead of at the\napproximate solution Wk, the convergence rate of the\ngradient method can be accelerated to O( 1\nk2 ). This\nresult\nis summarized in the following theorem.\nTheorem 4.1. Let {Wk} and {Zk} be the sequences\ngenerated by Algorithm 2. Then for any k ≥ 1 we have\nF (Wk) − F (W ∗) ≤ 2γL||W0 − W ∗||2\nF\n(k + 1)2 . (20)\nThe\nproof of this theorem follows the same strategy as\nin (Beck & Teboulle, 2009) and it is in the Appendix.\n5. Experiments\nWe evaluate the proposed extended gradient method\n(EGM) and the accelerated gradient method (AGM)\non four multi-task data sets. The yeast data set was\nderived from a yeast gene classiﬁcation problem con-\nsisting of 14 tasks. The letters and digits are hand-\nwritten words and digits data sets (Obozinski et al.,\n2009), which consist of 8 and 10 tasks, respectively.\nThe dmoz is a text categorization data set obtained\nfrom DMOZ (http://www.dmoz.org/) in which each\nof the 10 tasks corresponds to one of the subcategories\nof the Arts category. For each data set we randomly\nsample 5% and 10% of the data from each task for\ntraining.\nTo evaluate the eﬃciency of the proposed formula-\ntions, we report the computation time of the multi-\ntask feature learning (MFL) algorithm (Argyriou\net al., 2008), as MFL involves a formulation that is\nequivalent to EGM and AGM. For all methods, we\nterminate the algorithms when the relative changes in\nthe objective is below 10 −8, since the objective values\nof MFL and EGM/AGM are not directly comparable.\n461\nAn Accelerated\nGradient Method for T race Norm Minimization\nThe a veraged computation time over ten random trials\nfor each method is reported in Table 1. We can ob-\nserve that AGM is by far the most eﬃcient method in\nall cases. The relative eﬃciency of EGM and AGM dif-\nfers signiﬁcantly across data sets, demonstrating that\nthe performance of AGM is very stable for diﬀerent\nproblems. In order to investigate the convergence be-\nhaviors of EGM and AGM, we plot the objective values\nof these two methods on the yeast data set in Figure 1.\nWe can observe that in both cases AGM converges\nmuch faster than EGM, especially at early iterations.\nThis is consistent with our theoretical results and con-\nﬁrms that the proposed accelerated scheme can reach\nthe optimal objective value rapidly.\n6. Conclusion and Discussion\nIn this paper we propose eﬃcient algorithms to solve\ntrace norm regularized problems. We show that by ex-\nploiting the special structure of the trace norm, the\noptimal convergence rate of O( 1\n√\nk ) for\ngeneral non-\nsmooth problems can be improved to O( 1\nk ). W\ne fur-\nther show that this convergence rate can be accelerated\nto O( 1\nk2 ) b\ny employing the Nesterov’s method. Exper-\niments on multi-task learning problems demonstrate\nthe eﬃciency of the proposed algorithms.\nAs pointed out in the paper, another important ap-\nplication of the trace norm regularization is in ma-\ntrix completion problems. We plan to apply the pro-\nposed formulations to this problem in the future. The\nproposed algorithms require the computation of SVD,\nwhich may be computationally expensive for large-\nscale problems. We will investigate approximate SVD\ntechniques in the future to further reduce the compu-\ntational cost.\nAppendix\nProof of Theorem 3.1\nProof. Since the objective function in Eq. (10) is\nstrongly convex, a unique solution exists for this prob-\nlem and hence it remains to show that the solution is\nTλ(C). Recall that Z ∈Rm×n is the subgradient of a\nconvex function h :Rm×n →R at X0 if\nh(X) ≥ h(X0) + ⟨Z, X − X0⟩ (21)\nfor any X. The set of subgradients of h at X0 is called\nthe subdiﬀerential of h at X0 and it is denoted as\n∂h(X0). It is well-known (Nesterov, 2003) that W ∗\nis the optimal solution to the problem in Eq. (10) if\nand only if 0 ∈Rm×n is a subgradient of the objective\nfunction at W ∗, i.e.,\n0 ∈ W ∗ − C + λ∂||W ∗||∗. (22)\nLet W = P1ΛP T\n2 be the SVD of W where P1 ∈Rm×s\nand P2 ∈Rn×s have orthonormal columns, Σ ∈Rs×s\nis diagonal, and s = rank(W ). It can be veriﬁed that\n(Bach, 2008; Recht et al., 2008a)\n∂||W||∗ = {P1P T\n2 + S : S ∈Rm×n, P T\n1 S = 0,\nSP2 = 0, ||S||2 ≤ 1}, (23)\nwhere || · ||2 denotes the spectral norm of a matrix.\nDecomposing the SVD of C as\nC = U0Σ0V T\n0 + U1Σ1V T\n1 ,\nwhere U0Σ0V T\n0 corresponds to the part of SVD with\nsingular values greater than λ. Then we have the SVD\nof Tλ(C) as\nTλ(C) = U0(Σ0 − λI)V T\n0\nand thus\nC − Tλ(C) = λ(U0V T\n0 + S)\nwhere S = 1\nλ U1Σ1V T\n1 . It\nfollows from the facts that\nU T\n0 S = 0, SV0 = 0, and ||S||2 ≤ 1 that\nC − Tλ(C) ∈ λ∂||Tλ(C)||∗,\nwhich shows that Tλ(C) is an optimal solution.\nProof\nof Lemma 3.1\nProof. Since both the loss function f and the trace\nnorm are convex, we have\nf (X) ≥ f (Y ) + ⟨X − Y, ▽f (Y )⟩,\nλ||X||∗ ≥ λ||pµ(Y )||∗ + λ⟨X − pµ(Y ), g(pµ(Y ))⟩,\nwhere g(pµ(Y )) ∈ ∂||pµ(Y )||∗ is the subgradient of the\ntrace norm at pµ(Y ). Summing up the above two in-\nequalities we obtain that\nF (X) ≥ f (Y ) + ⟨X − Y, ▽f (Y )⟩ (24)\n+λ||pµ(Y )||∗ + λ⟨X − pµ(Y ), g(pµ(Y ))⟩.\nBy combining the condition in Eq. (14), the result in\nEq. (24), and the relation\nQµ(pµ(Y ), Y ) = Pµ(pµ(Y ), Y ) + λ||pµ(Y )||∗,\nwe obtain that\nF (X) − F (pµ(Y )) ≥ F (X) − Qµ(pµ(Y ), Y )\n≥ ⟨ X − pµ(Y ), ▽f (Y ) + λg(pµ(Y ))⟩ − µ\n2 ||pµ(Y ) − Y ||2\nF\n= µ⟨X − pµ(Y ), Y − pµ(\nY )⟩ − µ\n2 ||pµ(Y ) − Y ||2\nF\n= µ⟨Y − X,\npµ(Y ) − Y ⟩ + µ\n2 ||pµ(Y ) − Y ||2\nF ,\n462\nAn Accelerated\nGradient Method for T race Norm Minimization\nwhere the ﬁrst equality follows from that pµ(Y ) is a\nminimizer of Qµ(X, Y ) as in Eq. (11), and thus\n▽f (Y ) + µ(pµ(Y ) − Y ) + λg(pµ(Y )) = 0.\nThis completes the proof of the lemma.\nProof\nof Theorem 3.2\nProof. Applying Lemma 3.1 with ( X = W ∗, Y =\nWn, µ = Ln+1) and making use of the fact that for\nany three matrices A, B, and C of the same size\n||B− A||2\nF + 2⟨B − A, A− C⟩ = ||B− C||2\nF − ||A− C||2\nF ,\n(25)\nwe obtain that\n2\nLn+1\n(F (W ∗)−F (Wn+1))≥||Wn\n+1−W ∗||2\nF −||Wn−W ∗||2\nF .\nSumming the above inequality over n = 0 , · · · , k − 1\nand making use of the inequality in Eq. (16), we get\nk−1∑\nn=0\n(F (Wn+1)−F (W ∗))≤γL\n2 (||W0−W ∗||2\nF −||Wk−W ∗||2\nF ).\nIt follo\nws from F (Wn+1) ≤ F (Wn) and F (Wn) ≥\nF (W ∗) that\nk(F (Wk) − F (W ∗)) ≤\nk−1∑\nn=0\n(F (Wn+1) − F (W ∗))\n≤ γL\n2 ||W0 − W ∗||2\nF ,\nwhich\nleads to Eq. (17).\nProof\nof Theorem 4.1\nProof. Let us denote\nvk = F (Wk) − F (W ∗),\nUk = αkWk − (αk − 1)Wk−1 − W ∗.\nApplying Lemma 3.1 with (X = Wk, Y = Zk+1, L =\nLk+1) and ( X = W ∗, Y = Zk+1, L = Lk+1), respec-\ntively, we obtain the following two inequalities:\n2\nLk+1\n(vk − vk+1) ≥ ||\nWk+1 − Zk+1||2\nF (26)\n+2⟨Wk+1 − Zk+1, Zk+1 − Wk⟩,\n− 2\nLk+1\nvk+1 ≥ ||\nWk+1 − Zk+1||2\nF (27)\n+2⟨Wk+1 − Zk+1, Zk+1 − W ∗⟩.\nMultiplying both sides of Eq. (26) by ( αk+1 − 1) and\nadding it to Eq. (27), we get\n2\nLk+1\n((αk+1 − 1)vk−αk+1vk+1)≥αk+1||Wk+1−Zk+1||2\nF\n+2⟨Wk+1 − Zk+1, αk+1Zk+1 − (\nαk+1 − 1)Wk − W ∗⟩.\nMultiplying the last inequality by αk+1 and making\nuse of the equality α2\nk = α2\nk+1 − αk+1 derived from\nEq. (18), we get\n2\nLk+1\n(α2\nkvk − α2\nk+1vk+1) ≥ ||αk+1(\nWk+1 − Zk+1)||2\nF\n+2αk+1⟨Wk+1−Zk+1, αk+1Zk+1−(αk+1 − 1)Wk−W ∗⟩.\nApplying the equality in Eq. (25) to the right-hand\nside of the above inequality, we get\n2\nLk+1\n(α2\nkvk−α2\nk+1vk+1) ≥||αk+1Wk+1 − (αk+1 − 1)\nWk\n−W ∗||2\nF − ||αk+1Zk+1 − (αk+1 − 1)Wk − W ∗||2\nF .\nIt follows from Eq. (19) and the deﬁnition of Uk that\n2\nLk+1\n(α2\nkvk − α2\nk+1vk+1) ≥ ||\nUk+1||2\nF − ||Uk||2\nF ,\nwhich combined with Lk+1 ≥ Lk leads to\n2\nLk\nα2\nkvk − 2\nLk+1\nα2\nk+1vk+1 ≥ ||Uk+1||2\nF −\n||Uk||2\nF . (28)\nApplying Lemma 3.1 with (X = W ∗, Y = Z1, L = L1),\nwe obtain\nF (W ∗) − F (W1) = F (W ∗) − F (pL1(Z1))\n≥ L1\n2 ||pL1(Z1) − Z1||2 + L1⟨Z1 − W ∗, pL1 (\nZ1) − Z1⟩\n= L1\n2 ||W1 − Z1||2 + L1⟨Z1 − W ∗, W1 − Z1⟩\n= L1\n2 ||W1 − W ∗||2 − L1\n2 ||Z1 − W ∗||2 .\nHence, w\ne have\n2\nL1\nv1 ≤ ||Z1 − W ∗||2 −\n||W1 − W ∗||2 . (29)\nIt follows from Eqs. (28) and (29) that 2\nLk\nα2\nkvk ≤\n||W0 − W ∗||2 , which\ncombined with αk ≥ (k + 1)/2\nyields\nF (Wk) − F (W ∗)≤ 2Lk||W0−W ∗||2\n(k + 1)2 ≤ 2\nγL||W0−W ∗||2\n(k + 1)2 .\nThis\ncompletes the proof of the theorem.\nAckno\nwledgments\nThis work was supported by NSF IIS-0612069, IIS-\n0812551, CCF-0811790, NIH R01-HG002516, and\nNGA HM1582-08-1-0016.\n463\nAn Accelerated\nGradient Method for T race Norm Minimization\nReferences\nAberneth\ny, J., Bach, F., Evgeniou, T., & Vert, J.-\nP. (2006). Low-rank matrix factorization with at-\ntributes (Technical Report N24/06/MM). Ecole des\nMines de Paris.\nAbernethy, J., Bach, F., Evgeniou, T., & Vert, J.-P.\n(2009). A new approach to collaborative ﬁltering:\nOperator estimation with spectral regularization. J.\nMach. Learn. Res. , 10, 803–826.\nAmit, Y., Fink, M., Srebro, N., & Ullman, S. (2007).\nUncovering shared structures in multiclass classiﬁca-\ntion. In Proceedings of the International Conference\non Machine Learning, 17–24.\nArgyriou, A., Evgeniou, T., & Pontil, M. (2008). Con-\nvex multi-task feature learning. Machine Learning,\n73, 243–272.\nBach, F. R. (2008). Consistency of trace norm mini-\nmization. J. Mach. Learn. Res. , 9, 1019–1048.\nBeck, A., & Teboulle, M. (2009). A fast iterative\nshrinkage-thresholding algorithm for linear inverse\nproblems. SIAM Journal on Imaging Sciences, 2,\n183–202.\nBertsekas, D. P. (1999). Nonlinear programming .\nAthena Scientiﬁc. 2nd edition.\nCai, J.-F., Cand´ es, E. J., & Shen, Z. (2008). A sin-\ngular value thresholding algorithm for matrix com-\npletion (Technical Report 08-77). UCLA Computa-\ntional and Applied Math.\nCand´ es, E. J., & Recht, B. (2008). Exact matrix com-\npletion via convex optimization (Technical Report\n08-76). UCLA Computational and Applied Math.\nFazel, M., Hindi, H., & Boyd, S. P. (2001). A rank\nminimization heuristic with application to minimum\norder system approximation. In Proceedings of the\nAmerican Control Conference, 4734–4739.\nLu, Z., Monteiro, R. D. C., & Yuan, M. (2008). Con-\nvex optimization methods for dimension reduction\nand coeﬃcient estimation in multivariate linear re-\ngression. Submitted to Mathematical Programming .\nMa, S., Goldfarb, D., & Chen, L. (2008). Fixed point\nand Bregman iterative methods for matrix rank min-\nimization (Technical Report 08-78). UCLA Compu-\ntational and Applied Math.\nNemirovsky, A. S., & Yudin, D. B. (1983). Problem\ncomplexity and method eﬃciency in optimization.\nJohn Wiley & Sons Ltd.\nNesterov, Y. (1983). A method for solving a con-\nvex programming problem with convergence rate\nO(1/k2). Soviet Math. Dokl. , 27, 372–376.\nNesterov, Y. (2003). Introductory lectures on con-\nvex optimization: A basic course . Kluwer Academic\nPublishers.\nNesterov, Y. (2005). Smooth minimization of non-\nsmooth functions. Mathematical Programming, 103,\n127–152.\nNesterov, Y. (2007). Gradient methods for minimiz-\ning composite objective function (Technical Report\n2007/76). CORE, Universit´ e catholique de Louvain.\nObozinski, G., Taskar, B., & Jordan, M. I. (2009).\nJoint covariate selection and joint subspace selection\nfor multiple classiﬁcation problems. Statistics and\nComputing. In press.\nRecht, B., Fazel, M., & Parrilo, P. (2008a). Guaran-\nteed minimum-rank solutions of linear matrix equa-\ntions via nuclear norm minimization. Submitted to\nSIAM Review .\nRecht, B., Xu, W., & Hassibi, B. (2008b). Necessary\nand suﬃcient condtions for success of the nuclear\nnorm heuristic for rank minimization. In Proceed-\nings of the 47th IEEE Conference on Decision and\nControl, 3065–3070.\nRennie, J. D. M., & Srebro, N. (2005). Fast maximum\nmargin matrix factorization for collaborative predic-\ntion. In Proceedings of the International Conference\non Machine Learning, 713–719.\nSrebro, N., Rennie, J. D. M., & Jaakkola, T. S. (2005).\nMaximum-margin matrix factorization. In Advances\nin Neural Information Processing Systems , 1329–\n1336.\nToh, K.-C., & Yun, S. (2009). An accelerated prox-\nimal gradient algorithm for nuclear norm regular-\nized least squares problems. Preprint, Department\nof Mathematics, National University of Singapore,\nMarch 2009.\nTomioka, R., & Aihara, K. (2007). Classifying matri-\nces with a spectral regularization. In Proceedings of\nthe International Conference on Machine Learning,\n895–902.\nTseng, P. (2008). On accelerated proximal gradient\nmethods for convex-concave optimization. Submit-\nted to SIAM Journal on Optimization .\nWeimer, M., Karatzoglou, A., Le, Q., & Smola, A.\n(2008a). COFI rank - maximum margin matrix fac-\ntorization for collaborative ranking. In Advances in\nNeural Information Processing Systems , 1593–1600.\nWeimer, M., Karatzoglou, A., & Smola, A. (2008b).\nImproving maximum margin matrix factorization.\nMachine Learning, 72, 263–276.\nYuan, M., Ekici, A., Lu, Z., & Monteiro, R. (2007).\nDimension reduction and coeﬃcient estimation in\nmultivariate linear regression. Journal of the Royal\nStatistical Society: Series B , 69, 329–346.\n464",
  "values": {
    "Interpretable (to users)": "Yes",
    "Transparent (to users)": "Yes",
    "Privacy": "No",
    "Autonomy (power to decide)": "No",
    "Explicability": "No",
    "Deferral to humans": "No",
    "Non-maleficence": "No",
    "Respect for Persons": "No",
    "Justice": "No",
    "Beneficence": "No",
    "Respect for Law and public interest": "No",
    "Critiqability": "No",
    "Not socially biased": "No",
    "Collective influence": "No",
    "User influence": "No",
    "Fairness": "No"
  }
}