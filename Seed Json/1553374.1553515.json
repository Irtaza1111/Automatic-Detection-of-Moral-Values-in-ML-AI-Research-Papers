{
  "pdf": "1553374.1553515",
  "title": "Evaluation methods for topic models",
  "author": "Hanna M. Wallach, Iain Murray, Ruslan Salakhutdinov, David Mimno",
  "paper_id": "1553374.1553515",
  "text": "Evaluation Methods for Topic Models\nHanna M. W allach wallach@cs.umass.edu\nDepartment of Computer Science, University of Massachusetts, Amherst, MA 01003 USA\nIain Murray murray@cs.toronto.edu\nRuslan Salakhutdinov rsalakhu@cs.toronto.edu\nDepartment of Computer Science, University of Toronto, Toronto, Ontario M5S 3G4 CANADA\nDavid Mimno mimno@cs.umass.edu\nDepartment of Computer Science, University of Massachusetts, Amherst, MA 01003 USA\nAbstract\nA natural evaluation metric for statistical\ntopic models is the probability of held-out\ndocuments given a trained model. While\nexact computation of this probability is in-\ntractable, several estimators for this prob-\nability have been used in the topic model-\ning literature, including the harmonic mean\nmethod and empirical likelihood method. In\nthis paper, we demonstrate experimentally\nthat commonly-used methods are unlikely to\naccurately estimate the probability of held-\nout documents, and propose two alternative\nmethods that are both accurate and eﬃcient.\n1. Introduction\nStatistical topic modeling is an increasingly useful\ntool for analyzing large unstructured text collections.\nThere is a signiﬁcant body of work introducing and\ndeveloping sophisticated topic models and their appli-\ncations. To date, however, there have not been any\npapers speciﬁcally addressing the issue of evaluating\ntopic models. Evaluation is an important issue: the\nunsupervised nature of topic models makes model se-\nlection diﬃcult. For some applications there may be\nextrinsic tasks, such as information retrieval or docu-\nment classiﬁcation, for which performance can be eval-\nuated. However, there is a need for a universal method\nthat measures the generalization capability of a topic\nmodel in a way that is accurate, computationally eﬃ-\ncient, and independent of any speciﬁc application.\nAppearing in Proceedings of the 26th International Confer-\nence on Machine Learning, Montreal, Canada, 2009. Copy-\nright 2009 by the author(s)/owner(s).\nIn this paper we consider only the simplest topic\nmodel, latent Dirichlet allocation (LDA), and compare\na number of methods for estimating the probability\nof held-out documents given a trained model. Most\nof the methods presented, however, are applicable to\nmore complicated topic models. In addition to com-\nparing evaluation methods that are currently used in\nthe topic modeling literature, we propose several al-\nternative methods. We present empirical results on\nsynthetic and real-world data sets showing that the\ncurrently-used estimators are less accurate and have\nhigher variance than the proposed new estimators.\n2. Latent Dirichlet allocation\nLatent Dirichlet allocation (LDA), originally intro-\nduced by Blei et al. (2003), is a generative model for\ntext. In this model, a “topic” t is a discrete distribu-\ntion over words with probability vector φt. Dirichlet\npriors, with concentration parameter β and base mea-\nsuren, are placed over the topics Φ= {φ1,... φT }:\nP (Φ) = ∏\nt Dir (φt;βn). (1)\nEach document, indexed by d, is assumed to have its\nown distribution over topics given by probabilities θd.\nThe priors over Θ = {θ1,... θD} are also Dirichlet,\nwith concentration parameter α and base measurem:\nP (Θ) = ∏\nd Dir (θd;αm). (2)\nThe tokens in a document w(d) = {w(d)\nn }Nd\nn=1 are asso-\nciated with topic assignments z(d) = {z(d)\nn }Nd\nn=1, drawn\ni.i.d. from the document-speciﬁc topic distribution:\nP (z(d) |θd) = ∏\nnθz(d)\nn |d. (3)\nThe tokens are drawn from the topics’ distributions:\nP (w(d) |z(d), Φ) = ∏\nnφw(d)\nn |z(d)\nn\n. (4)\n1105\n\nEvaluation Methods for T opic Models\nA data set of documents W = {w(1),w(2),...,w(D)}\nis observed, while the underlying corresponding topic\nassignments Z = {z(1),z(2),...,z(D)} are unobserved.\nConjugacy of Dirichlets with multinomials allows the\nparameters to be marginalized out. For example,\nP (z(d) |αm) =\n∫\ndθdP (z(d) |θd)P (θd |αm)\n= Γ(α)\nΓ(Nd +α)\n∏\nt\nΓ(Nt|d +αmt)\nΓ(αmt) , (5)\nwhere topic t occurs Nt|d times in z(d) of length Nd.\n3. Evaluating LDA\nLDA is typically evaluated by either measuring perfor-\nmance on some secondary task, such as document clas-\nsiﬁcation or information retrieval, or by estimating the\nprobability of unseen held-out documents given some\ntraining documents. A better model will give rise to a\nhigher probability of held-out documents, on average.\nThe probability of a set of held-out documentsW given\na set of training documents W′, can be written as\nP (W | W′)=\n∫\ndΦ dα dmP (W | Φ,αm)P (Φ,αm | W′).\nThis integral can be approximated by averaging\nP (W | Φ,αm) under samples from P (Φ,αm | W′), or\nevaluating at a point estimate. We take the latter ap-\nproach. Variational methods (Blei et al., 2003) and\nMCMC methods (Griﬃths & Steyvers, 2004) are ef-\nfective at marginalizing out the topic assignments Z\nassociated with the training data to infer Φ and αm.\nIn this paper, we focus on evaluating\nP (W | Φ,αm) = ∏\ndP (w(d) | Φ,αm). (6)\nSince the topic assignments for one document are in-\ndependent of the topic assignments for all other docu-\nments, each held-out document can be evaluated sep-\narately. For the rest of this paper, we refer to the\ncurrent document as w, its latent topic assignments\nasz, and its document-speciﬁc topic distribution asθ.\nMany of the evaluation methods in this paper require\nthe ability to obtain a set of topic assignments z for\ndocument w using Gibbs sampling. Gibbs sampling\ninvolves sequentially resampling each zn from its con-\nditional posterior givenw, Φ,αm andz\\n (the current\nlatent topic assignments for all other tokens):\nP (zn =t |w,z\\n, Φ,αm)\n∝P (wn |zn =t, Φ)P (zn =t |z\\n,αm)\n∝φwn|t\n{Nt}\\n +αmt\nN − 1 +α , (7)\nwhere {Nt}\\n is the number of times topic t occurs in\nthe document in question, excluding position n, and\nN is the total number of tokens in the document.\n4. Estimating P (w | Φ,αm)\nThe evaluation probability P (w | Φ,αm) for held-out\ndocumentw can be thought of as the normalizing con-\nstant that relates the posterior distribution over z to\nthe joint distribution over w andz in Bayes’ rule:\nP (z |w, Φ,αm) = P (z,w | Φ,αm)\nP (w | Φ,αm) . (8)\nThere are many existing methods for estimating nor-\nmalizing constants. In this section, we review some of\nthese methods, as previously applied to topic models,\nand also outline two alternative methods: a Chib-style\nestimator and a “left-to-right” evaluation algorithm.\n4.1. Importance sampling methods\nIn general, given a model with observed variables\nw and unknown variables h, importance sampling\ncan be used to approximate the probability of the\nobserved variables, either P (w) = ∑\nhP (w,h) or∫\ndhP (w,h). If Q(h) is some simple, tractable distri-\nbution overh—the “proposal distribution”—then\nP (w) ≃ 1\nS\n∑\ns\nP (w,h(s))\nQ(h(s)) , h(s) ∼Q(h), (9)\nis an unbiased estimator. To ensure low variance,Q(h)\nmust be similar to the “target distribution” P (h |w)\nand must be non-zero wherever P (w,h) is non-zero.\nIn this section, we explain how P (w | Φ,αm) can be\nestimated using importance sampling by either (a) in-\ntegrating out θ and using the prior over h =z as the\nproposal distribution, or (b) using the prior overh=θ\nas the proposal distribution, thereby allowing the topic\nassignmentsz to be marginalized out directly.\nIf the proposal distribution is the prior over z,\nP (w | Φ,αm) =\n∑\nz\nP (w |z, Φ)P (z |αm)\n≃ 1\nS\n∑\ns\nP (w |z(s), Φ), (10)\nwherez(s) ∼ P (z |αm). Unfortunately, topic assign-\nments drawn from the prior, without consideration of\nthe corresponding tokens, are unlikely to provide a\ngood explanation of w. The prior is not usually close\nto the target distribution unless w is very short.\nBetter proposal distributions for z(s) can be con-\nstructed by taking w into account. The simplest way\n1106\nEvaluation Methods for T opic Models\nis to form a distribution over topics for each token\nwn, ignoring dependencies between tokens: Q(zn) ∝\nαmznφwn|zn. A more sophisticated method, which we\ncall “iterated pseudo-counts,” involves iteratively up-\ndatingQ(zn) every sampling iteration. After initializ-\ning Q(zn)(0) ∝αmznφwn|zn, the update rule is\nQ(zn)(s) ∝ (αmzn +\n∑\nn′̸=n\nQ(zn′)(s−1))φwn|zn. (11)\nAlternatively,P (w | Φ,αm) can be written as an inte-\ngral over the document-speciﬁc topic distribution θ:\nP (w | Φ,αm) =\n∫\ndθP (w |θ, Φ)P (θ |αm)\n≃ 1\nS\n∑\ns\nP (w |θ(s), Φ), (12)\nwhere θ(s) is drawn from P (θ |αm) = Dir (θ ;αm).\nThe estimator in (12) is easily computed because the\ntopic assignments are independent given θ:\nP (w |θ(s), Φ) =\n∏\nn\nP (wn |θ(s), Φ)\n=\n∏\nn\n∑\nzn\nP (wn,zn |θ(s), Φ). (13)\nIf the probabilities P (w |θ(s), Φ) are estimated from\na synthetic document, randomly-generated using θ(s),\nthe resultant estimator corresponds to the empiri-\ncal likelihood method described by Li and McCal-\nlum (2006). Used directly, however, (13) will give\nthe same result as using inﬁnitely long synthetic doc-\numents and is how the empirical likelihood method is\nimplemented in MALLET (McCallum, 2002).\nImportance sampling does not work well when sam-\npling from high-dimensional distributions. Unless the\nproposal distribution is a near-perfect approximation\nto the target distribution, the variance of the estimator\nwill be very large. When sampling continuous values,\nsuch asθ, the estimator may have inﬁnite variance.\n4.2. Harmonic mean method\nThe harmonic mean method (Newton & Raftery, 1994)\nis based on the following unbiased estimator:\n1\nP (w) =\n∑\nz\nP (z |w)\nP (w |z) ≃ 1\nS\n∑\ns\n1\nP (w |z(s)), (14)\nwherez(s) is drawn fromP (z |w). Conditioning on Φ\nand αm gives an estimator for P (w | Φ,αm):\nP (w | Φ,αm) ≃ 1\n1\nS\n∑\ns\n1\nP(w| z(s),Φ)\n= HM ({P(w |z(s), Φ)}S\ns=1), (15)\nwherez(s) ∼P (z |w, Φ,αm) and HM (·) denotes the\nharmonic mean. In practice, {z(s)}S\ns=1 are S samples\ntaken from a Gibbs sampler after a burn-in period of\nB iterations. Since the samples are used to approx-\nimate an expectation, they need not be independent\nand thinning is unnecessary. Consequently, the cost of\nthe estimator is that of S +B Gibbs iterations.\nNewton and Raftery (1994) expressed reservations\nabout the harmonic mean method when introducing it,\nand Neal added further criticism in the discussion. De-\nspite these criticisms, it has been used in several topic\nmodeling papers (Griﬃths & Steyvers, 2004; Griﬃths\net al., 2005; Wallach, 2006), due to its ease of imple-\nmentation and relative computational eﬃciency.\n4.3. Annealed importance sampling\nAnnealed importance sampling (AIS) can be viewed\nas a variant of simple importance sampling deﬁned on\na higher-dimensional state space (Neal, 2001). Many\nauxiliary variables are introduced in order to make the\nproposal distribution closer to the target distribution.\nWhen used to approximateP (w | Φ,αm), AIS uses the\nfollowing sequence of probability distributions:\nPs(z) ∝P (w |z, Φ)τsP (z |αm),\ndeﬁned by a set of “inverse temperatures,” 0 = τ0 <\nτ1 <...<τ S = 1. When s = 0,τs = 0 and soP0(z) is\nthe prior distribution P (z |αm). Similarly, when s =\nS,PS(z) is the posterior distribution P (z |w, Φ,αm).\nIntermediate values of s interpolate between the prior\nand posterior distributions. For each s = 1,...,S − 1,\na Markov chain transition operator Ts(z′ ←z) that\nleaves Ps(z) invariant must also be deﬁned. When\napproximating P (w | Φ,αm), Ts(z′ ←z) is the Gibbs\nsampling operator that samples sequentially from\nPs(zn |z\\n) ∝P (wn |zn, Φ)τsP (zn |z\\n,αm). (16)\nSampling from (16) is as easy as sampling from (7).\nAIS builds a proposal distribution Q(Z) over the ex-\ntended state space Z = {z(1),..., z(S)} by ﬁrst sam-\npling from the tractable priorP0(z) and then applying\na series of transition operators T1,T 2,...,T S−1 that\n“move” the sample through the intermediate distribu-\ntions Ps(z) towards the posterior PS(z). The proba-\nbility of the resultant state sequence Z is given by\nQ(Z) =P0(z(1))\nS−1∏\ns=1\nTs(z(s+1) ←z(s)). (17)\nThe target distribution for the proposal Q(Z) is\nP (Z) =PS(z(S))\nS−1∏\ns=1\n˜Ts(z(s) ←z(s+1)), (18)\n1107\nEvaluation Methods for T opic Models\n1: initialize 0 = τ0 <τ 1 <...<τ S = 1\n2: sample z(1) from the prior P0(z) =P (z |αm).\n3: for s = 2 :S do\n4: sample z(s) ∼Ts−1(z(s) ←z(s−1))\n5: end for\n6: P (w | Φ,αm) ≃ QS\ns=1P (w |z(s), Φ)τs−τs−1\nAlgorithm 1: Annealed importance sampling.\nwhere ˜Ts is the reverse transition operator, given by\n˜Ts(z′ ←z) =Ts(z ←z′)Ps(z′)\nPs(z). (19)\nHaving sampled a sequence of topic assignments from\nQ(Z), a scalar importance weight is constructed:\nwAIS = P (w | Φ,αm)P (Z)\nQ(Z)\n= P (w,z(S) | Φ,αm) ∏S−1\ns=1 ˜Ts(z(s) ←z(s+1))\nP0(z(1)) ∏S−1\ns=1 Ts(z(s+1) ←z(s))\n=\nS∏\ns=1\nP (w |z(s), Φ)τs−τs−1.\nGiven a set of samples from Q(Z), the correspond-\ning importance weights can be used to approximate\nP (w | Φ,αm) because of the following equality:\nP (w | Φ,αm) =P (w | Φ,αm)\n∑\nZ\nP (Z)\n= EQ(Z) [wAIS]. (20)\nThe transition operators do not necessarily need to\nbe ergodic. The simple importance sampling approx-\nimation in (10), in which the proposal distribution is\nP (z |αm), is recovered by using transition operators\nthat do nothing: Ts(z′ ←z) =δ (z′ −z) for all s.\nThe AIS algorithm is summarized in algorithm 1.\n4.4. Chib-style estimation\nFor any “special” set of latent topic assignments z⋆,\nBayes’ rule gives rise to the following identity:\nP (w | Φ,αm) = P (z⋆,w | Φ,αm)\nP (z⋆ |w, Φ,αm). (21)\nChib (1995) introduced a family of estimators that\nﬁrst pick a z⋆ and then estimate the denominator,\nP (z⋆ |w, Φ,αm). The numerator P (z⋆,w | Φ,αm) =\nP (w |z⋆, Φ)P (z⋆ |αm) is known from (4) and (5).\nAny Markov chain operator T for sampling from the\nposterior, including the Gibbs sampler, satisﬁes\nP (z⋆ |w, Φ,αm)\n=\n∑\nz\nT (z⋆ ←z)P (z |w, Φ,αm). (22)\n1: initialize z∗ to a high posterior probability state\n2: sample s uniformly from {1,...,S }\n3: sample z(s) ∼ eT (z(s) ←z⋆)\n4: for s′ = (s + 1) :S do\n5: sample z(s′) ∼T (z(s′) ←z(s′−1))\n6: end for\n7: for s′ = (s − 1) : −1 : 1 do\n8: sample z(s′) ∼ eT (z(s′) ←z(s′+1))\n9: end for\n10: P (w | Φ,αm) ≃\nP (w,z⋆ | Φ,αm)\n.\n1\nS\nP\ns′T (z⋆ ←z(s′))\nAlgorithm 2: A Chib-style estimator.\n(22) can be substituted into (21) to give\nP (w | Φ,αm) = P (z⋆,w | Φ,αm)∑\nzT (z⋆ ←z)P (z |w, Φ,αm)\n≃ P (z⋆,w | Φ,αm)\n1\nS\n∑S\ns=1T (z⋆ ←z(s))\n,\nwhere Z = {z(1),..., z(S)} can be obtained by Gibbs\nsampling fromP (z |w, Φ,αm). Murray and Salakhut-\ndinov (2009) showed that this estimator can overesti-\nmate the desired probability in expectation. Instead,\nthey constructed the following proposal distribution:\nQ(Z) = 1\nS\nS∑\ns=1\n˜T (z(s) ←z⋆)\nS∏\ns′=s+1\nT (z(s′) ←z(s′−1))\n·\ns−1∏\ns′=1\n˜T (z(s′) ←z(s′+1)).\nSince the forward operator transition T consists of se-\nquentially applying (7) for positions 1 to N (in that\norder), the reverse transition operator ˜T can be con-\nstructed by simply applying (7) in the reverse order.\nUsing the deﬁnition of ˜T in (19) it can be shown that\nP (w | Φ,αm) ≃ P (z⋆,w | Φ,αm)\n1\nS\n∑S\ns=1T (z⋆ ←z(s))\n, (23)\nunder samples from Q(Z). In this application, with\nforwards and reverse Gibbs samplers, the estimator is\nformally unbiased, even for ﬁnite runs of the chain.\nThe probability of moving to z⋆ is given by\nT (z⋆ ←z) =\n∏\nn\nP (z⋆\nn |z⋆\n<n,z>n,w, Φ,αm). (24)\nThis Chib-style estimator is valid for any choice of\n“special state” z⋆. We set z⋆ by iteratively maximiz-\ning (7) for positions 1,...,N , after a few iterations of\nregular Gibbs sampling. In all our experiments, less\nthan 1% of computer time was spent setting z⋆.\nThe Chib-style method is summarized in algorithm 2.\n1108\nEvaluation Methods for T opic Models\n1: initialize l := 0\n2: for each position n inw do\n3: initialize pn := 0\n4: for each particle r = 1 to R do\n5: for n′ <n do\n6: sample z(r)\nn′ ∼P (z(r)\nn′ |wn′, {z(r)\n<n}\\n′, Φ,αm)\n7: end for\n8: pn :=pn + P\ntP (wn,z (r)\nn =t |z(r)\n<n, Φ,αm)\n9: sample z(r)\nn ∼P (z(r)\nn |wn,z(r)\n<n, Φ,αm)\n10: end for\n11: pn :=pn/R\n12: l :=l + logpn\n13: end for\n14: log P (w | Φ,αm) ≃l\nAlgorithm 3: A “left-to-right” evaluation algorithm.\n4.5. “Left-to-right” evaluation algorithm\nAnother approach for approximating P (w | Φ,αm)\nwas recently proposed by Wallach (2008). This\nmethod, which operates in an incremental, “left-to-\nright” fashion, decomposes P (w | Φ,αm) as\nP (w | Φ,αm)\n= ∏\nnP (wn |w<n, Φ,αm)\n= ∏\nn\n∑\nz≤n\nP (wn,z≤n |w<n, Φ,αm). (25)\nEach sum over z≤n can then be approximated us-\ning an approach inspired by sequential Monte Carlo\nmethods (Del Moral et al., 2006), as in algo-\nrithm 3. This method is appropriate for a wider range\nof applications—including predictive text entry and\nspeech recognition systems—than the other methods\nin this section, because of its “left-to-right” operation.\n4.6. Relative costs of the methods\nThe majority of the methods described above are\nbased on Gibbs sampling, which dominates their costs:\ncomputingP (zn |wn,z\\n, Φ,αm) is signiﬁcantly more\ncostly than computing P (wn |zn, Φ)—the quantity\nused to construct the estimators given the samples.\nThe Chib-style method is an exception: constructing\nthe estimator itself has a cost roughly equal to that of\nGibbs sampling. None-the-less, the approximate cost\nof each method can be reported in terms of the num-\nber of Gibbs sampling site updates required (i.e., the\nnumber of zn variables updated) as shown in table 1.\nImportance sampling using the prior overθ as the sam-\npling distribution does not involve Gibbs sampling.\nHowever, ∑\nzn\nP (zn,wn |θ(s), Φ) must be computed\nfor each held-out token wn, which has a similar cost\nto a Gibbs sampling site update. The cost of sim-\nple importance sampling using a distribution over z is\nharder to express, and will be implementation depen-\ndent. Slightly unfairly to these methods, we assume\n1: initialize 0 = τ0 <τ 1 <...<τ S = 1\n2: sample z(1) from P0(z) =P (z |w(1), Φ,αm).\n3: for s = 2 :S do\n4: sample z(s) ∼Ts−1(z(s) ←z(s−1))\n5: end for\n6: P (w(2)|w(1), Φ,αm) ≃\nSY\ns=1\nP (w(2)|z(s),w(1), Φ)τs−τs−1\nAlgorithm 4: AIS for document completion.\nthat the cost of generating samples is directly compa-\nrable to Gibbs sampling. The cost could be examined\nmore closely were such a method to yield good results.\n5. Document completion\nAnother way of evaluating topic models is to com-\npare predictive performance by estimating the prob-\nability of the second half of a document, given the\nﬁrst (Rosen-Zvi et al., 2004). This is typically accom-\nplished by adding the ﬁrst half of each held-out docu-\nment to the training data, while retaining the second\nhalf for evaluation. Letting w(1) be the ﬁrst half of w\nandw(2) be the second half, the goal is to compute\nP (w(2) |w(1), Φ,αm) = P (w(2),w(1) | Φ,αm)\nP (w(1) | Φ,αm) , (26)\nwhich is a ratio of normalizing constants. Any\nof the methods for estimating P (w | Φ,αm) ≡\nP (w(2),w(1) | Φ,αm) described in the previous sec-\ntion can be re-run on only w(1) to estimate\nP (w(1) | Φ,αm), thereby allowing evaluation of (26).\nHowever, specialized techniques may be more eﬃcient.\n5.1. Estimated θ\nThe estimated θ method involves drawing samples\nz(1,s) ∼P (z(1) |w(1), Φ,αm) and then forming\nˆθ(s)\nt =P (t |z(1,s),αm) = N(1,s)\nt +αmt\nN(1) +α , (27)\nwhere N(1) is the number of tokens in w(1). If the\npredictive probability of t is clamped to ˆθ(s)\nt for the\nremainder of the document, i.e., for w(2), then\nP (w(2) |w(1), Φ,αm) ≃ 1\nS\n∑\ns\n∏\nn\n∑\nt\nφw(2)\nn |t\nˆθ(s)\nt .\n5.2. Importance sampling and AIS\nThe importance sampling algorithms described in sec-\ntions 4.1 and 4.3 can all be adapted to estimate (26)\ndirectly by using samples conditioned on w(1). For\nAIS, we use the following sequence of distributions:\nPs(z) ∝P (w(1),w(2) |z, Φ)τsP (z |w(1), Φ,αm).\n(26) can then be approximated as in algorithm 4.\n1109\nEvaluation Methods for T opic Models\nTable 1. Summary of methods for estimating P (w | Φ,αm) with approximate costs for a document of length N. CS\n(S = 1000) and LR (R = 20) on a 200 word synthetic document each run in 3.2 seconds on a 1000MHz Opteron 175.\nMethod Parameters Description Cost (# Gibbs site updates)\nAIS # temperatures S Annealed importance sampling SN\nHM burn-in B, # samples S Harmonic mean method N(B +S)\nLR # particles R “Left-to-right” evaluation algorithm RN(N − 1)/ 2\nCS chain length S Chib-style estimator 2SN\nIS-PT # samples S Importance sampling from P (θ |αm) SN\nIS-IP # iterations I, # samples S Importance sampling, Q(z) from (11) (I +S)N\nIS-PZW # samples S Importance sampling, Q(zn) ∝αmznφwn|zn SN\n−\n−\n− − − − − −\n−184000 −174000\nAIS\nHM\nLR\nCS\nIS−PT 2\nIS−PT 1\nIS−IP\nIS−PZW\n−\n−\n− − − −\n−\n−\n−75000 −63000\nAIS\nHM\nLR\nCS\nIS−PT 2\nIS−PT 1\nIS−IP\nIS−PZW\n−\n−\n− −\n− −\n−\n−\n−61000 −50000\nAIS\nHM\nLR\nCS\nIS−PT 2\nIS−PT 1\nIS−IP\nIS−PZW\n−\n−\n− −\n− −\n−\n−\n−47000 −38000\nAIS\nHM\nLR\nCS\nIS−PT 2\nIS−PT 1\nIS−IP\nIS−PZW\n−\n−\n− −\n− −\n−\n−\n−97000 −81000\nAIS\nHM\nLR\nCS\nIS−PT 2\nIS−PT 1\nIS−IP\nIS−PZW\n−\n− − − − −\n−183584 −183579\n3−synth\nAIS\nLR 2\nLR 1\nCS 2\nCS 1\nIS−IP\n−\n−\n−\n− −\n−\n−70970 −70940\n50−synth\nAIS\nLR 2\nLR 1\nCS 2\nCS 1\nIS−IP\n−\n−\n− −\n− −\n−\n−51640 −51470\n20 News\nAIS 2\nAIS 1\nLR 2\nLR 1\nCS 2\nCS 1\nIS−IP\n− − −\n− −\n−\n−41007 −40810\nPMC\nAIS\nLR 2\nLR 1\nCS 2\nCS 1\nIS−IP\n− − −\n− −\n−\n−87380 −86970\nNYT\nAIS\nLR 2\nLR 1\nCS 2\nCS 1\nIS−IP\nFigure 1. P\nd logP (w(d) | Φ,αm) for all ﬁve data sets. The top ﬁgures show results for all methods, while the bottom\nﬁgures focus on the most competitive methods. To demonstrate convergence, in some cases, we report results for the same\nmethod twice, the second time with double the computation: e.g., “CS 1” uses S = 1000 while “CS 2” uses S = 2000.\n5.3. “Left-to-right” evaluation algorithm\nThe “left-to-right” algorithm described in section 4.5\ncan estimate P (w(2) |w(1), Φ,αm) directly. If the\nwords in w are ordered such that w(1) is fully ob-\nserved before any words from w(2) are observed, then\na second estimator can be accumulated as in line 12 of\nalgorithm 3, for the positions involving tokens inw(2).\n6. Results\nIn this section, we present experimental results com-\nparing the evaluation methods described in the pre-\nvious two sections on both real and synthetic data.\nOur MATLAB and Java implementations are available\nfrom http://www.cs.umass.edu/~wallach/code/etm/.\n6.1. Description of data\nTwo synthetic data sets and three real-world corpora\nwere used to compare the methods. The synthetic data\nsets were generated using two LDA models. In order\nto make the statistics of the synthetic documents as\nclose as possible to real documents, the values of Φ,\nα andm were inferred from a collection of computer\nscience abstracts using an MCMC implementation in\nthe MALLET software package (McCallum, 2002).\nTable 2. Data sets used in the experiments. V is the vo-\ncabulary size, ¯N is the mean document length, “St. Dev.”\nis the estimated standard deviation in document length.\nData set V ¯N St. Dev.\nSynthetic, 3 topics 9242 500 0\nSynthetic, 50 topics 9242 200 0\n20 Newsgroups 22695 120.4 296.2\nPubMed Central abstracts 30262 101.8 49.2\nNew York Times articles 50412 230.6 250.5\nEach of the three real-world data sets was divided into\ntraining and held-out documents. For each data set,\nΦ, α and m values were inferred using the training\ndocuments. Given these values, the evaluation meth-\nods were compared using the held-out documents. For\nall three data sets the number of topics was set to 200.\nDescriptions of all ﬁve data sets are given in table 2.\n6.2. Estimating P (w | Φ,αm)\nFor each of the ﬁve data sets, P (w | Φ,αm) was es-\ntimated for ﬁfty held-out documents. The evaluation\nmethods are summarized in table 1. Like Murray and\nSalakhutdinov (2009), AIS with 10,000 temperatures\nwas intended as a gold standard. This method is com-\nputationally expensive, but is often accurate. For the\nharmonic mean method, B = 50, 000 burn-in itera-\ntions were used, followed by S = 50, 000 Gibbs sam-\n1110\nEvaluation Methods for T opic Models\npling iterations (without any thinning). The compu-\ntation time for this parameterization roughly matches\nthe computation time for AIS with 10,000 tempera-\ntures. For each of the data sets, the Chib-style esti-\nmator was run with two diﬀerent parameterizations:\nS = 1, 000 and S = 2, 000. The remaining meth-\nods were also run with two parameterizations, chosen\nto result in computation times equivalent to those of\nthe Chib-style estimator (which are much smaller than\nthose of either AIS or the harmonic mean method).\nFor each method and data set, the estimates of\nP (w(d) | Φ,αm) for each held-out documentw(d) were\naveraged over 10 runs, to give ¯P (w(d) | Φ,αm). The\nlog probability of the held-out documents was then\nestimated as ∑\nd log ¯P (w(d) | Φ,αm). Standard devi-\nations were obtained using a bootstrap method, in\nwhich 10,000 log probabilities for each data set were\nobtained by sampling with replacement from the 10\nruns for each held-out document. Figure 1 shows∑\nd log ¯P (w(d) | Φ,αm) for each method and data set.\nThe harmonic mean method wildly overestimated\n∑\nd logP (w(d) | Φ,αm) for all of the data sets. Es-\ntimates were eﬀectively from one or very few samples,\nmaking the harmonic mean method very unstable.\nThe main failure mode for the simple importance sam-\npling methods, AIS and the Chib-style estimator is in-\nadequately sampling the upper tail of the distribution\nover importance weights. This causes underestimation\nof both P (w | Φ,αm) and the variance of the estima-\ntor. Consequently, the largest estimate is likely to be\nthe best. Formal statements could be made using the\nbounds discussed by Gogate et al. (2007). AIS exhib-\nited this failure mode on the 20 Newsgroups data set,\nyielding a lower probability than the “left-to-right” al-\ngorithm due to poor performance on some long docu-\nments. Increasing the accuracy by using 20,000 tem-\nperatures gave larger probabilities in agreement with\nthe “left-to-right” algorithm. Long documents in the\nsynthetic data set with only 3 topics also caused AIS\nto exhibit higher variance than other methods.\nThe Chib-style estimator and the “left-to-right” algo-\nrithm both performed well, with the latter consistently\nperforming better on the real-world data sets. Results\non the synthetic data sets show that the “left-to-right”\nalgorithm does not universally dominate the Chib-\nstyle method, however. While more accurate than har-\nmonic mean, none of the simpler importance sampling\nmethods were competitive and generally performed ex-\nceedingly poorly, usually giving large underestimates.\nThe “iterated pseudo-counts” method was the best of\nthe simple importance sampling methods, but was still\nsigniﬁcantly worse than the Chib-style estimator.\n−\n−\n−\n−26330 −26150\n20 NewsAIS\nLR\nET\n−\n−\n−\n−20310 −20230\nPMCAIS\nLR\nET\n−\n−\n−\n−43960 −43810\nNYTAIS\nLR\nET\nFigure 2. P\nd logP (w(2,d) |w(1,d), Φ,αm) for document\ncompletion methods. “ET” is the estimated θ method.\n6.3. Document completion\nAnother way of evaluating topic models is to esti-\nmateP (w(2) |w(1), Φ,αm). As explained in section 5,\nthis probability can be directly approximated using\neither the estimated θ method, the “left-to-right” al-\ngorithm or AIS. These methods were compared us-\ning B = 5, 000 burn-in iterations and S = 20, 000\nsamples for the estimated θ method, B = 500 burn-\nin iterations and 1, 500 temperatures for AIS, and\nR = 4 · 2000/N particles for the “left-to-right” algo-\nrithm. Despite being allowed signiﬁcantly more com-\nputation time than the other methods, the estimatedθ\nmethod exhibited relatively poor performance and did\nnot achieve results close to those of AIS. The “left-to-\nright” algorithm did approach the estimates obtained\nusing AIS, with substantially less computation time.\n6.4. Sensitivity to perturbations in Φ and m\nIn this section, we investigate how the evaluation\nmethods described in sections 4 and 5 are aﬀected by\nperturbations in Φ and m. The methods were com-\npared using the synthetic data set with 50 topics, for\nwhich the true Φ, α andm values are known.\nSensitivity to perturbations in Φ was investigated by\ninterpolating between Φ and a randomly-generated\nset of topic-speciﬁc distribution over words Φ ′. For\neach method, either P (w | (1 − λ) Φ +λΦ′,αm) or\nP (w(2) |w(1), (1 −λ) Φ +λΦ′,αm) were calculated for\nλ ∈ { 0,. 25,. 5,. 75}. Figure 3 shows the log ratios be-\ntween the values computed using interpolated parame-\nters and the values computed using Φ only (λ = 0) for\nthe estimated θ method, importance sampling from\nP (θ |αm) and the “left-to-right” algorithm. Results\nfor the Chib-style estimator closely track those of the\n“left-to-right” algorithm, so we report only the latter.\nCompared to the “left-to-right” algorithm, importance\nsampling and the estimated θ method understate the\ndiﬀerence between the values computed using the true\nΦ and the values computed using a perturbed Φ.\n1111\nEvaluation Methods for T opic Models\n0.00 0.50 1.00−20000 −10000 0\nET\nLR\nISP\n0.00 0.50 1.00−2000 −1000 0\nFigure 3. The eﬀects of perturbing Φ (left) and m (right).\nThe x-axis shows the degree of perturbation λ. The y-axis\nshows the log ratio between the probabilities reported by\neach estimator with the given λ and with λ = 0.\nSensitivity to perturbations in the base measure m\nwas investigated similarly. A random m′ was gen-\nerated and either P (w | Φ,α ((1 − λ)m + λm′)) or\nP (w(2) |w(1), Φ,α ((1 −λ)m +λm′)) were calculated\nfor λ ∈ {0,. 25,. 5,. 75}. Log ratios between the val-\nues computed using interpolated base measures and\nthe values computed using m are shown in ﬁgure 3.\nImportance sampling is strongly aﬀected by perturba-\ntions in m; the estimated θ method is less sensitive.\n7. Discussion\nThe evaluation methods currently used in the topic\nmodeling community, including the harmonic mean\nmethod, importance sampling from P (θ |αm), and\ndocument completion methods, are generally inaccu-\nrate. Even if these methods do result in a correct rank-\ning of diﬀerent models, the relative advantage of one\nmodel over another may be incorrectly represented.\nMost of the evaluation methods described in this pa-\nper extend readily to more complicated topic models—\nincluding non-parametric versions based on hierarchi-\ncal Dirichlet processes (Teh et al., 2006)—since they\nonly require a MCMC algorithm for sampling the la-\ntent topic assignmentsz for each document and a way\nof evaluating probabilityP (w |z, Φ,αm). Importance\nsampling from P (θ |αm) is not obviously directly ap-\nplicable to non-parametric topic models, however.\nEstimating the probability of held-out documents pro-\nvides a clear, interpretable metric for evaluating the\nperformance of topic models relative to other topic-\nbased models as well as to other non-topic-based gen-\nerative models. We provide empirical evidence that\nseveral recently-used methods for estimating the prob-\nability of held-out documents are inaccurate and can\nchange the results of model comparison. In contrast,\nthe Chib-style estimator and “left-to-right” algorithm\npresented in this paper provide a clear methodology\nfor accurately assessing and selecting topic models.\nAcknowledgments\nThis work was supported by the Center for Intelligent\nInformation Retrieval and CIA, NSA & NSF under\nNSF grant #IIS-0326249. Any opinions, ﬁndings and\nconclusions or recommendations are the authors’ and\ndo not necessarily reﬂect those of the sponsor.\nReferences\nBlei, D., Ng, A., & Jordan, M. (2003). Latent Dirichlet\nallocation. J. Machine Learning Res., 3, 993–1022.\nChib, S. (1995). Marginal likelihood from the Gibbs\noutput. J. American Stat. Assoc. , 90, 1313–1321.\nDel Moral, P., Doucet, A., & Jasra, A. (2006). Se-\nquential Monte Carlo samplers. J. Royal Stat. Soc.\nB, 68, 1–26.\nGogate, V., Bidyuk, B., & Dechter, R. (2007). Studies\nin lower bounding probability of evidence using the\nMarkov inequality. Proc. Conf. on Uncertainty in\nArtiﬁcial Intelligence (pp. 141–148).\nGriﬃths, T., & Steyvers, M. (2004). Finding scientiﬁc\ntopics. Proc. Natl. Acad. Sci., 101, 5228–5235.\nGriﬃths, T. L., Steyvers, M., Blei, D. M., & Tenen-\nbaum, J. B. (2005). Integrating topics and syntax.\nProc. Neural Information Processing Systems (pp.\n537–544).\nLi, W., & McCallum, A. (2006). Pachinko alloca-\ntion: DAG-structured mixture models of topic cor-\nrelations. Proc. Int’l. Conf. on Machine Learning\n(pp. 577–584).\nMcCallum, A. (2002). MALLET: A machine learning\nfor language toolkit. http://mallet.cs.umass.edu.\nMurray, I., & Salakhutdinov, R. (2009). Evaluating\nprobabilities under high-dimensional latent variable\nmodels. Proc. Neural Information Processing Sys-\ntems (pp. 1137–1144).\nNeal, R. M. (2001). Annealed importance sampling.\nStatistics and Computing , 11, 125–139.\nNewton, M. A., & Raftery, A. E. (1994). Approx-\nimate Bayesian inference with the weighted likeli-\nhood bootstrap. J. Royal Stat. Soc. B, 56, 3–48.\nRosen-Zvi, M., Griﬃths, T., Steyvers, M., & Smyth,\nP. (2004). The author-topic model for authors and\ndocuments. Proc. Conf. on Uncertainty in Artiﬁcial\nIntelligence (pp. 487–494).\nTeh, Y., Jordan, M., Beal, M., & Blei, D. (2006). Hier-\narchical Dirichlet processes. J. American Stat. As-\nsoc., 101, 1566–1581.\nWallach, H. M. (2006). Topic modeling: beyond bag-\nof-words. Proc. Int’l. Conf. on Machine Learning\n(pp. 977–984).\nWallach, H. M. (2008). Structured topic models for\nlanguage. PhD thesis, University of Cambridge.\n1112",
  "values": {
    "Explicability": "No",
    "Critiqability": "No",
    "Collective influence": "No",
    "User influence": "No",
    "Beneficence": "No",
    "Fairness": "No",
    "Privacy": "No",
    "Justice": "No",
    "Not socially biased": "No",
    "Respect for Persons": "No",
    "Non-maleficence": "No",
    "Autonomy (power to decide)": "No",
    "Respect for Law and public interest": "No",
    "Deferral to humans": "No",
    "Interpretable (to users)": "No",
    "Transparent (to users)": "No"
  }
}