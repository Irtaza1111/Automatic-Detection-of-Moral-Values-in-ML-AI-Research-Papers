{
  "pdf": "NIPS-2008-clustered-multi-task-learning-a-convex-formulation-Paper",
  "title": "Clustered Multi-Task Learning: A Convex Formulation",
  "author": "Laurent Jacob, Jean-philippe Vert, Francis R. Bach",
  "paper_id": "NIPS-2008-clustered-multi-task-learning-a-convex-formulation-Paper",
  "text": "Clustered Multi-Task Learning:\na\nConvex Formulation\nLaurent Jacob\nM\nines ParisTech – CBIO\nINSERM U900, Institut Curie\n35, rue Saint Honor´e, 77300 Fontainebleau, France\nlaurent.jacob@mines-paristech.fr\nFrancis Bach\nINRIA – Willow Project\nEcole Normale Sup´erieure,\n45, rue d’Ulm, 75230 Paris, France\nfrancis.bach@mines.org\nJean-Philippe Vert\nMines ParisTech – CBIO\nINSERM U900, Institut Curie\n35, rue Saint Honor´e, 77300 Fontainebleau, France\njean-philippe.vert@mines-paristech.fr\nAbstract\nIn multi-task learning several related tasks are considered simultaneously, with\nthe hope that by an appropriate sharing of information across tasks, each task may\nbeneﬁt from the others. In the context of learning linear functions for supervised\nclassiﬁcation or regression, this can be achieved by including a priori informa-\ntion about the weight vectors associated with the tasks, and how they are expected\nto be related to each other. In this paper, we assume that tasks are clustered into\ngroups, which are unknown beforehand, and that tasks within a group have similar\nweight vectors. We design a new spectral norm that encodes this a priori assump-\ntion, without the prior knowledge of the partition of tasks into groups, resulting\nin a new convex optimization formulation for multi-task learning. We show in\nsimulations on synthetic examples and on the IEDB MHC-I binding dataset, that\nour approach outperforms well-known convex methods for multi-task learning, as\nwell as related non-convex methods dedicated to the same problem.\n1 Introduction\nRegularization has emerged as a dominant theme in machine learning and statistics, providing an\nintuitive and principled tool for learning from high-dimensional data. In particular, regularization\nby squared Euclidean norms or squared Hilbert norms has been thoroughly studied in various set-\ntings, leading to efﬁcient practical algorithms based on linear algebra, and to very good theoretical\nunderstanding (see, e.g., [1, 2]). In recent years, regularization by non Hilbert norms, such as ℓ p\nnorms with p ̸= 2 , has also generated considerable interest for the inference of linear functions in\nsupervised classiﬁcation or regression. Indeed, such norms can sometimes both make the problem\nstatistically and numerically better-behaved, and impose various prior knowledge on the problem.\nFor example, the ℓ 1-norm (the sum of absolute values) imposes some of the components to be equal\nto zero and is widely used to estimate sparse functions [3], while various combinations of ℓ p norms\ncan be deﬁned to impose various sparsity patterns.\nWhile most recent work has focused on studying the properties of simple well-known norms, we\ntake the opposite approach in this paper. That is, assuming a given prior knowledge, how can we\ndesign a norm that will enforce it?\nMore precisely, we consider the problem of multi-task learning, which has recently emerged as a\nvery promising research direction for various applications [4]. In multi-task learning several re-\nlated inference tasks are considered simultaneously, with the hope that by an appropriate sharing\n1\nof information across tasks, each one may beneﬁt from the othe rs. When linear functions are es-\ntimated, each task is associated with a weight vector, and a common strategy to design multi-task\nlearning algorithm is to translate some prior hypothesis about how the tasks are related to each other\ninto constraints on the different weight vectors. For example, such constraints are typically that the\nweight vectors of the different tasks belong (a) to a Euclidean ball centered at the origin [5], which\nimplies no sharing of information between tasks apart from the size of the different vectors, i.e., the\namount of regularization, (b) to a ball of unknown center [5], which enforces a similarity between\nthe different weight vectors, or (c) to an unknown low-dimensional subspace [6, 7].\nIn this paper, we consider a different prior hypothesis that we believe could be more relevant in some\napplications: the hypothesis thatthe different tasks are in fact clustered into different groups, and that\nthe weight vectors of tasks within a group are similar to each other. A key difference with [5], where\na similar hypothesis is studied, is that we don’t assume that the groups are known a priori, and in a\nsense our goal is both to identify the clusters and to use them for multi-task learning. An important\nsituation that motivates this hypothesis is the case where most of the tasks are indeed related to each\nother, but a few “outlier” tasks are very different, in which case it may be better to impose similarity\nor low-dimensional constraints only to a subset of the tasks (thus forming a cluster) rather than to\nall tasks. Another situation of interest is when one can expect a natural organization of the tasks\ninto clusters, such as when one wants to model the preferences of customers and believes that there\nare a few general types of customers with similar preferences within each type, although one does\nnot know beforehand which customers belong to which types. Besides an improved performance if\nthe hypothesis turns out to be correct, we also expect this approach to be able to identify the cluster\nstructure among the tasks as a by-product of the inference step, e.g., to identify outliers or groups of\ncustomers, which can be of interest for further understanding of the structure of the problem.\nIn order to translate this hypothesis into a working algorithm, we follow the general strategy men-\ntioned above which is to design a norm or a penalty over the set of weights which can be used as\nregularization in classical inference algorithms. We construct such a penalty by ﬁrst assuming that\nthe partition of the tasks into clusters is known, similarly to [5]. We then attempt to optimize the\nobjective function of the inference algorithm over the set of partitions, a strategy that has proved\nuseful in other contexts such as multiple kernel learning [8]. This optimization problem over the\nset of partitions being computationally challenging, we propose a convex relaxation of the problem\nwhich results in an efﬁcient algorithm.\n2 Multi-task learning with clustered tasks\nWe consider m related inference tasks that attempt to learn linear functions over X = Rd from a\ntraining set of input/output pairs (xi, y i)i=1,...,n, where xi ∈ X and yi ∈ Y . In the case of binary\nclassiﬁcation we usually take Y = {−1, +1}, while in the case of regression we take Y = R. Each\ntraining example (xi, y i) is associated to a particular task t ∈ [1, m] , and we denote by I(t) ⊂ [1, n]\nthe set of indices of training examples associated to the taskt. Our goal is to infer m linear functions\nft(x) = w⊤\nt x, for t = 1 , . . . , m , associated to the different tasks. We denote by W = ( w1 . . . w m)\nthe d × m matrix whose columns are the successive vectors we want to estimate.\nWe ﬁx a loss function l : R × Y ↦→ R that quantiﬁes by l(f (x), y ) the cost of predicting f (x)\nfor the input x when the correct output is y. Typical loss functions include the square error in\nregression l(u, y ) = 1\n2 (u − y)2 o r the hinge loss in binary classiﬁcation l(u, y ) = max(0 , 1 − uy)\nwith y ∈ {− 1, 1}. The empirical risk of a set of linear classiﬁers given in the matrix W is then\ndeﬁned as the average loss over the training set:\nℓ(W ) = 1\nn\n∑m\nt= 1\n∑\ni∈I(t) l(w⊤\nt xi, y i) . (1)\nIn the sequel, we will often use the m×1 vector 1 composed of ones, the m×m projection matrices\nU = 11⊤ /m whose entries are all equal to 1/m, as well as the projection matrix Π =I − U.\nIn order to learn simultaneously the m tasks, we follow the now well-established approach which\nlooks for a set of weight vectors W that minimizes the empirical risk regularized by a penalty\nfunctional, i.e., we consider the problem:\nminW ∈Rd×m ℓ(W ) + λΩ(W ) , (2)\nwhere Ω(W ) can be designed from prior knowledge to constrain some sharing of information be-\ntween tasks. For example, [5] suggests to penalize both the norms of the wi’s and their variance,\n2\ni.e., to consider a function of the form:\nΩvariance(W ) = ∥ ¯w∥2 + β\nm\n∑m\ni= 1 ∥wi − ¯w∥2 , (3)\nwhere ¯w = (∑n\ni=1 wi) /m is the mean weight vector. This penalty enforces a clustering of the w′\nis\ntowards their mean when β increases. Alternatively, [7] propose to penalize the trace norm of W :\nΩtrace(W ) = ∑min(d,m)\ni=1 σ i(W ) , (4)\nwhere σ 1(W ), . . . , σ min(d,m)(W ) are the successive singular values ofW . This enforces a low-rank\nsolution in W , i.e., constrains the different wi’s to live in a low-dimensional subspace.\nHere we would like to deﬁne a penalty function Ω(W ) that encodes as prior knowledge that tasks\nare clustered into r < m groups. To do so, let us ﬁrst assume that we know beforehand the clusters,\ni.e., we have a partition of the set of tasks into r groups. In that case we can follow an approach\nproposed by [5] which for clarity we rephrase with our notations and slightly generalize now. For a\ngiven cluster c ∈ [1, r ], let us denote J (c) ⊂ [1, m] the set of tasks in c, mc = |J (c)| the number\nof tasks in the cluster c, and E the m × r binary matrix which describes the cluster assignment\nfor the m tasks, i.e., Eij = 1 if task i is in cluster j, 0 otherwise. Let us further denote by ¯wc =\n(∑\ni∈J (c) wi)/m c the average weight vector for the tasks in c, and recall that ¯w = ( ∑m\ni=1 wi) /m\ndenotes the average weight vector over all tasks. Finally it will be convenient to introduce the matrix\nM = E(E⊤ E)−1 E⊤. M can also be written I − L, where L is the normalized Laplacian of the\ngraph G whose nodes are the tasks connected by an edge if and only if they are in the same cluster.\nThen we can deﬁne three semi-norms of interest on W that quantify different orthogonal aspects:\n• A global penalty, which measures on average how large the weight vectors are:\nΩmean(W ) = n∥ ¯w∥2 = trW U W⊤ .\n• A measure of between-cluster variance, which quantiﬁes how close to each other the dif-\nferent clusters are:\nΩbetween(W ) = ∑r\nc=1 mc∥ ¯wc − ¯w∥2 = trW (M − U )W ⊤ .\n• A measure of within-cluster variance, which quantiﬁes the compactness of the clusters:\nΩwithin(W ) = ∑r\nc=1\n{∑\ni∈J (c) ∥wi − ¯wc∥2\n}\n= trW (I − M )W ⊤ .\nWe note that both Ωbetween(W ) and Ωwithin(W ) depend on the particular choice of clusters E, or\nequivalently of M. We now propose to consider the following general penalty function:\nΩ(W ) = ε M Ωmean(W ) + ε BΩbetween(W ) + ε W Ωwithin(W ) , (5)\nwhere ε M , ε B and ε W are non-negative parameters that can balance the importance of the compo-\nnents of the penalty. Plugging this quadratic penalty into (2) leads to the general problem:\nminW ∈Rd×m ℓ(W ) + λtrW Σ(M )−1 W ⊤ , (6)\nwhere\nΣ(M )−1 = ε M U + ε B(M − U ) + ε W (I − M ) . (7)\nHere we use the notationΣ(M ) to insist on the fact that this quadratic penalty depends on the cluster\nstructure through the matrix M. Observing that the matrices U, M − U and I − M are orthogonal\nprojections onto orthogonal supplementary subspaces, we easily get from (7):\nΣ(M ) = ε −1\nM U + ε −1\nB (M − U ) + ε −1\nW (I − M ) = ε −1\nW I + (ε −1\nM − ε −1\nB )U + (ε −1\nB − ε −1\nW )M . (8)\nBy choosing particular values for ε M , ε B and ε W we can recover several situations, In particular:\n• For ε W = ε B = ε M = ε, we simply recover the Frobenius norm of W , which does not put\nany constraint on the relationship between the different tasks:\nΩ(W ) = εtrW W ⊤ = ε ∑m\ni=1 ∥wi∥2 .\n3\n• F or ε W = ε B > ε M , we recover the penalty of [5] without clusters:\nΩ(W ) = trW (ε M U + ε B(I − U )) W ⊤ = ε M n∥ ¯w∥2 + ε B\n∑m\ni=1 ∥wi − ¯w∥2 .\nIn that case, a global similarity between tasks is enforced, in addition to the general con-\nstraint on their mean. The structure in clusters plays no role since the sum of the between-\nand within-cluster variance is independent of the particular choice of clusters.\n• For ε W > ε B = ε M we recover the penalty of [5] with clusters:\nΩ(W ) = trW (ε M M + ε W (I − M )) W ⊤ = ε M\nr∑\nc=1\n{\nmc∥ ¯wc∥2 + εW\nεM\n∑\ni∈ J (c) ∥wi − ¯wc∥2\n}\n.\nIn order to enforce a cluster hypothesis on the tasks, we therefore see that a natural choice is to\ntake ε W > ε B > ε M in (5). This would have the effect of penalizing more the within-cluster\nvariance than the between-cluster variance, hence promoting compact clusters. Of course, a major\nlimitation at this point is that we assumed the cluster structure known a priori (through the matrix\nE, or equivalently M). In many cases of interest, we would like instead to learn the cluster structure\nitself from the data. We propose to learn the cluster structure in our framework by optimizing our\nobjective function (6) both in W and M, i.e., to consider the problem:\nminW ∈Rd×m,M ∈Mr ℓ(W ) + λtr W Σ(M )−1 W ⊤ , (9)\nwhere Mr denotes the set of matrices M = E(E⊤ E)−1 E⊤ deﬁned by a clustering of the m tasks\ninto r clusters and Σ(M ) is deﬁned in (8). Denoting by Sr = {Σ(M ) : M ∈ Mr} the correspond-\ning set of positive semideﬁnite matrices, we can equivalently rewrite the problem as:\nminW ∈Rd×m,Σ∈Sr ℓ(W ) + λtr W Σ−1 W ⊤ . (10)\nThe objective function in (10) is jointly convex inW ∈ Rd×m and Σ ∈ S m\n+ , the set ofm×m positive\nsemideﬁnite matrices, however the (ﬁnite) setSr is not convex, making this problem intractable. We\nare now going to propose a convex relaxation of (10) by optimizing over a convex set of positive\nsemideﬁnite matrices that contains Sr.\n3 Convex relaxation\nIn order to formulate a convex relaxation of (10), we observe that in the penalty term (5) the cluster\nstructure only contributes to the second and third terms Ωbetween(W ) and Ωwithin(W ), and that\nthese penalties only depend on the centered version of W . In terms of matrices, only the last two\nterms of Σ(M )−1 in (7) depend on M, i.e., on the clustering, and these terms can be re-written as:\nε B(M − U ) + ε W (I − M ) = Π( ε BM + ε W (I − M ))Π. (11)\nIndeed, it is easy to check that M − U = M Π = ΠM Π, and that I − M = I − U − (M − U ) =\nΠ − ΠM Π = Π( I − M )Π. Intuitively, multiplying by Π on the right (resp. on the left) centers the\nrows (resp. the columns) of a matrix, and both M − U and I − M are row- and column-centered.\nTo simplify notations, let us introduce ˜M = ΠM Π. Plugging (11) in (7) and (9), we get the penalty\ntrW Σ(M )−1 W ⊤ = ε M\n(\ntrW ⊤ W U\n)\n+ (W Π)(ε B ˜M + ε W (I − ˜M ))(W Π)⊤ , (12)\nin which, again, only the second part needs to be optimized with respect to the clusteringM. Denot-\ning Σ−1\nc (M ) = ε B ˜M + ε W (I − ˜M ), one can express Σc(M ), using the fact that ˜M is a projection:\nΣc(M ) =\n(\nε −1\nB − ε −1\nW\n) ˜M + ε −1\nW I. (13)\nΣc is characterized by ˜M = ΠM Π, that is discrete by construction, hence the non-convexity of Sr.\nWe have the natural constraints M ≥ 0 (i.e., ˜M ≥ −U ), 0 ⪯ M ⪯ I (i.e., 0 ⪯ ˜M ⪯ Π) and\ntrM = r (i.e., tr ˜M = r − 1). A possible convex relaxation of the discrete set of matrices ˜M is\ntherefore { ˜M : 0 ⪯ ˜M ⪯ I, tr ˜M = r − 1}. This gives an equivalent convex set Sc for Σc, namely:\nSc =\n{\nΣc ∈ S m\n+ : αI ⪯ Σc ⪯ βI, trΣc = γ\n}\n, (14)\nwith α = ε −1\nW , β = ε −1\nB and γ = ( m − r + 1)ε −1\nW + (r − 1)ε −1\nB . Incorporating the ﬁrst part of the\npenalty (12) into the empirical risk term by deﬁning ℓ c(W ) = λℓ( W ) + ε M\n(\ntrW ⊤ W U\n)\n, we are\nnow ready to state our relaxation of (10):\nminW ∈Rd×m,Σc∈Sc ℓ c(W ) + λtrW ΠΣ−1\nc (W Π)⊤ . (15)\n4\n3.1 Reinterpretation in terms of norms\nW\ne denote ∥W ∥2\nc = min Σc∈Sc trW Σ−1\nc W T the cluster norm (CN). For any convex set Sc, we ob-\ntain a norm on W (that we apply here to its centered version). By putting some different constraints\non the set Sc, we obtain different norms on W , and in fact all previous multi-task formulations may\nbe cast in this way, i.e., by choosing a speciﬁc set of positive matrices Sc (e.g., trace constraint for\nthe trace norm, and simply a singleton for the Frobenius norm). Thus, designing norms for multi-\ntask learning is equivalent to designing a set of positive matrices. In this paper, we have investigated\na speciﬁc set adapted for clustered-tasks, but other sets could be designed in other situations.\nNote that we have selected a simple spectral convex set Sc in order to make the optimization sim-\npler in Section 3.3, but we could also add some additional constraints that encode the point-wise\npositivity of the matrix M. Finally, when r = 1 (one cluster) and r = m (one cluster per task), we\nget back the formulation of [5].\n3.2 Reinterpretation as a convex relaxation of K-means\nIn this section we show that the semi-norm∥W Π∥2\nc that we have designed earlier, can be interpreted\nas a convex relaxation of K-means on the tasks [9]. Indeed, given W ∈ Rd×m, K-means aims\nto decompose it in the form W = µE⊤ where µ ∈ Rd×r are cluster centers and E represents\na partition. Given E, µ is found by minimizing minµ ∥W ⊤ − Eµ⊤ ∥2\nF . Thus, a natural strategy\noutlined by [9], is to alternate between optimizing µ, the partition E and the weight vectors W . We\nnow show that our convex norm is obtained when minimizing in closed form with respect to µ and\nrelaxing.\nBy translation invariance, this is equivalent to minimizing minµ ∥ΠW ⊤ − ΠEµ⊤ ∥2\nF . If we add a\npenalization on µ of the form λtrE ⊤ Eµµ⊤, then a short calculation shows that the minimum with\nrespect to µ (i.e., after optimization of the cluster centers) is equal to\ntrΠW ⊤ W Π(ΠE(E⊤ E)−1 E⊤ Π/λ + I)−1 = trΠW ⊤ W Π(ΠM Π/λ + I)−1 .\nBy comparing with Eq. (13), we see that our formulation is indeed a convex relaxation of K-means.\n3.3 Primal optimization\nLet us now show in more details how (15) can be solved efﬁciently. Whereas a dual formulation\ncould be easily derived following [8], a direct approach is to rewrite (15) as\nminW ∈Rd×m\n(\nℓ c(W ) + minΣc∈Sc trW ΠΣ−1\nc (W Π)⊤ )\n(16)\nwhich, if ℓ c is differentiable, can be directly optimized by gradient-based methods on W since\n∥W Π∥2\nc = min Σc∈Sc trW ΠΣ−1\nc (W Π)⊤ is a quadratic semi-norm of W Π. This regularization\nterm trW ΠΣ−1\nc (W Π)⊤ can be computed efﬁciently using a semi-closed form. Indeed, since Σc as\ndeﬁned in (14) is a spectral set (i.e., it does depend only on eigenvalues of covariance matrices), we\nobtain a function of the singular values of W Π (or equivalently the eigenvalues of W ΠW ⊤):\nminΣc∈Sc trW ΠΣ−1\nc (W Π)⊤ = min λ∈Rm, α≤λ i≤β, λ1 =γ, V ∈Om trW ΠV diag(λ) −1 V ⊤ (W Π)⊤ ,\nwhere Om is the set of orthogonal matrices in Rm×m. The optimal V is the matrix of the eigenvec-\ntors of W ΠW ⊤, and we obtain the value of the objective function at the optimum:\nminΣ∈S trW ΠΣ−1 (W Π)⊤ = min λ∈Rm, α≤λ i≤β, λ1 =γ\n∑m\ni=1\nσ2\ni\nλi\n,\nw\nhere σ and λ are the vectors containing the singular values of W Π and Σ respectively. Now, we\nsimply need to be able to compute this function of the singular values.\nThe only coupling in this formulation comes from the trace constraint. The Lagrangian correspond-\ning to this constraint is:\nL(λ, ν ) = ∑m\ni=1\nσ2\ni\nλi\n+ ν (∑m\ni=\n 1 λ i − γ ) . (17)\nFor ν ≤ 0, this is a decreasing function of λ i, so the minimum on λ i ∈ [α, β ] is reached for λ i = β .\nThe dual function is then a linear non-decreasing function of ν (since α ≤ γ/m ≤ β from the\ndeﬁnition of α, β, γ in (14)), which reaches it maximum value (on ν ≤ 0) at ν = 0. Let us therefore\nnow consider the dual for ν ≥ 0. (17) is then a convex function of λ i. Canceling its derivative with\nrespect to λ i gives that the minimum in λ ∈ R is reached for λ i = σ i/ √ ν . Now this may not be\n5\nin the constraint set (α , β ), so if σ i < α √ ν t hen the minimum in λ i ∈ [α, β ] of (17) is reached\nfor λ i = α , and if σ i > β √ ν i t is reached for λ i = β . Otherwise, it is reached for λ i = σ i/ √ ν .\nR\neporting this in (17), the dual problem is therefore\nmaxν≥0\n∑\ni,α√ ν≤σ i≤β √ ν 2σ i\n√ ν + ∑\ni ,σi<α√ ν\n(\nσ2\ni\nα + ν α\n)\n+ ∑\ni,β√ ν<σi\n(\nσ2\ni\nβ + ν β\n)\n− νγ . (18)\nSince a closed form for this expression is known for each ﬁxed value of ν , one can obtain ∥W Π∥2\nc\n(and the eigenvalues of Σ∗) by Algorithm 1. The cancellation condition in Algorithm 1 is that the\nAlgorithm 1 C omputing ∥A∥2\nc\nRequire: A , α, β, γ .\nEnsure: ∥A∥2\nc, λ ∗.\nCompute the singular values σ i of A.\nOrder the σ2\ni\nα2 , σ2\ni\nβ2 i n a vector I (with an additional 0 at the beginning).\nfor all interval (a, b ) of I do\nif ∂L(λ∗,ν)\n∂ν i s canceled on ν ∈ (a, b ) then\nReplace ν ∗ in the dual function L(λ ∗, ν ) to get ∥A∥2\nc, compute λ ∗ on (a, b ).\nreturn ∥A∥2\nc, λ ∗.\nend if\nend for\nvalue canceling the derivative belongs to (a , b ), i.e.,\nν =\n( P\ni,α√ν≤σi≤β√ν σi\nγ−(αn−+β n+)\n)2\n∈ (a, b ) ,\nwhere n− and n+ are the number of σ i < α √ ν a nd σ i > β √ ν r espectively. Denoting ∥A∥2\nc =\nF (A, Σ∗(A)), ∇ AF = ∂ AF + ∂ ΣF ∂ AΣ cannot be computed because of the non-differentiable\nconstraints on Σ for F . We followed an alternative direction, using only the ∂ AF part.\n4 Experiments\n4.1 Artiﬁcial data\nWe generated synthetic data consisting of two clusters of two tasks. The tasks are vectors ofRd, d =\n30. For each cluster, a center ¯wc was generated in Rd−2, so that the two clusters be orthogonal. More\nprecisely, each ¯wc had (d − 2)/2 random features randomly drawn from N (0, σ 2\nr ), σ 2\nr = 900, and\n(d − 2)/2 zero features. Then, each tasks t was computed as wt + ¯wc(t), where c(t) was the cluster\nof t. wt had the same zero feature as its cluster center, and the other features were drawn from\nN (0, σ 2\nc ), σ 2\nc = 16. The last two features were non-zero for all the tasks and drawn fromN (0, σ 2\nc ).\nFor each task, 2000 points were generated and a normal noise of variance σ 2\nn = 150 was added.\nIn a ﬁrst experiment, we compared our cluster norm ∥. ∥2\nc with the single-task learning given by the\nFrobenius norm, and with the trace norm, that corresponds to the assumption that the tasks live in a\nlow-dimension space. The multi-task kernel approach being a special case of CN, its performance\nwill always be between the performance of the single task and the performance of CN.\nIn a second setting, we compare CN to alternative methods that differ in the way they learn Σ:\n• The True metric approach, that simply plugs the actual clustering in E and optimizes W\nusing this ﬁxed metric. This necessitates to know the true clustering a priori, and can be\nthought of like a golden standard.\n• The k-means approach, that alternates between optimizing the tasks in W given the metric\nΣ and re-learning Σ by clustering the tasks wi [9]. The clustering is done by a k-means run\n3 times. This is a non convex approach, and different initialization of k-means may result\nin different local minima.\nWe also tried one run of CN followed by a run of True metric using the learned Σ reprojected\nin Sr by rounding, i.e., by performing k-means on the eigenvectors of the learned Σ (Reprojected\napproach), and a run of k-means starting from the relaxed solution (CNinit approach).\n6\nOnly the ﬁrst method requires to know the true clustering a pri ori, all the other methods can be run\nwithout any knowledge of the clustering structure of the tasks.\nEach method was run with different numbers of training points. The training points were equally\nseparated between the two clusters and for each cluster, 5/6th of the points were used for the ﬁrst\ntask and 1/6th for the second, in order to simulate a natural setting were some tasks have fewer data.\nWe used the 2000 points of each task to build 3 training folds, and the remaining points were used\nfor testing. We used the mean RMSE across the tasks as a criterion, and a quadratic loss for ℓ(W ).\nThe results of the ﬁrst experiment are shown on Figure 1 (left). As expected, both multi-task ap-\nproaches perform better than the approach that learns each task independently. CN penalization on\nthe other hand always gives better testing error than the trace norm penalization, with a stronger ad-\nvantage when very few training points are available. When more training points become available,\nall the methods give more and more similar performances. In particular, with large samples, it is not\nuseful anymore to use a multi-task approach.\n3 3.5 4 4.5 5 5.5 6 6.510\n15\n20\n25\n30\n35\nNumber of training points (log)\nRMSE\n \n \nFrob\nTrace\nCN\n3 3.5 4 4.5 5 5.5 6 6.514\n16\n18\n20\n22\n24\n26\n28\n30\n32\nNumber of training points (log)\nRMSE\n \n \nCN\nKM\nTrue\nRepr\nFigure 1: RMSE versus number of training points for the tested methods.\nFigure 2: Recovered Σ w ith CN (upper line) and k-means (lower line) for 28, 50 and 100 points.\nFigure 1 (right) shows the results of the second experiment. Using the true metric always gives the\nbest results. For 28 training points, no method recovers the correct clustering structure, as displayed\non Figure 2, although CN performs slightly better than the k-means approach since the metric it\nlearns is more diffuse. For 50 training points, CN performs much better than the k-means approach,\nwhich completely fails to recover the clustering structure as illustrated by the Σ learned for 28 and\n50 training points on Figure 2. In the latter setting, CN partially recovers the clusters. When more\ntraining points become available, the k-means approach perfectly recovers the clustering structure\nand outperforms the relaxed approach. The reprojected approach, on the other hand, performs al-\nways as well as the best of the two other methods. The CNinit approach results are not displayed\nsince the are the same as for the reprojected method.\n4.2 MHC-I binding data\nWe also applied our method to the IEDB MHC-I peptide binding benchmark proposed in [10]. This\ndatabase contains binding afﬁnities of various peptides, i.e., short amino-acid sequences, with dif-\nferent MHC-I molecules. This binding process is central in the immune system, and predicting it is\ncrucial, for example to design vaccines. The afﬁnities are thresholded to give a prediction problem.\nEach MHC-I molecule is considered as a task, and the goal is to predict whether a peptide binds a\nmolecule. We used an orthogonal coding of the amino acids to represent the peptides and balanced\n7\nTable 1: Prediction error for the 1 0 molecules with less than 200 training peptides in IEDB .\nMethod Pooling Frobenius norm Multi-task kernel Trace norm Cluster norm\nTest error 2 6. 53% ± 2. 0 11. 62% ± 1. 4 10. 10% ± 1. 4 9. 20% ± 1. 3 8. 71% ± 1. 5\nthe data by keeping only one negative example for each positive point, resulting in 15236 points\ninvolving 35 different molecules. We chose a logistic loss for ℓ(W ).\nMulti-task learning approaches have already proved useful for this problem, see for example [11,\n12]. Besides, it is well known in the vaccine design community that some molecules can be grouped\ninto empirically deﬁned supertypes known to have similar binding behaviors.\n[12] showed in particular that the multi-task approaches were very useful for molecules with few\nknown binders. Following this observation, we consider the mean error on the 10 molecules with\nless than 200 known ligands, and report the results in Table 1. We did not select the parameters by\ninternal cross validation, but chose them among a small set of values in order to avoid overﬁtting.\nMore accurate results could arise from such a cross validation, in particular concerning the number\nof clusters (here we limited the choice to 2 or 10 clusters).\nThe pooling approach simply considers one global prediction problem by pooling together the data\navailable for all molecules. The results illustrate that it is better to consider individual models than\none unique pooled model.On the other hand, all the multitask approaches improve the accuracy, the\ncluster norm giving the best performance. The learnedΣ, however, did not recover the known super-\ntypes, although it may contain some relevant information on the binding behavior of the molecules.\n5 Conclusion\nWe have presented a convex approach to clustered multi-task learning, based on the design of a\ndedicated norm. Promising results were presented on synthetic examples and on the IEDB dataset.\nWe are currently investigating more reﬁned convex relaxations and the natural extension to non-\nlinear multi-task learning as well as the inclusion of speciﬁc features on the tasks, which has shown\nto improve performance in other settings [6].\nReferences\n[1] G. Wahba. Spline Models for Observational Data, volume 59 of CBMS-NSF Regional Conference Series\nin Applied Mathematics. SIAM, Philadelphia, 1990.\n[2] F. Girosi, M. Jones, and T. Poggio. Regularization Theory and Neural Networks Architectures. Neural\nComput., 7(2):219–269, 1995.\n[3] R. Tibshirani. Regression shrinkage and selection via the lasso. J. Royal. Stat. Soc. B., 58:267–288, 1996.\n[4] B. Bakker and T. Heskes. Task clustering and gating for bayesian multitask learning. J. Mach. Learn.\nRes., 4:83–99, 2003.\n[5] T. Evgeniou, C. Micchelli, and M. Pontil. Learning multiple tasks with kernel methods. J. Mach. Learn.\nRes., 6:615–637, 2005.\n[6] J. Abernethy, F. Bach, T. Evgeniou, and J.-P. Vert. Low-rank matrix factorization with attributes. Technical\nReport cs/0611124, arXiv, 2006.\n[7] A. Argyriou, T. Evgeniou, and M. Pontil. Multi-task feature learning. In B. Sch ¨olkopf, J. Platt, and\nT. Hoffman, editors, Adv. NIPS 19, pages 41–48, Cambridge, MA, 2007. MIT Press.\n[8] G.R.G. Lanckriet, N. Cristianini, P. Bartlett, L. El Ghaoui, and M.I. Jordan. Learning the Kernel Matrix\nwith Semideﬁnite Programming. J. Mach. Learn. Res., 5:27–72, 2004.\n[9] M. Deodhar and J. Ghosh. A framework for simultaneous co-clustering and learning from complex data.\nIn KDD '07, pages 250–259, New York, NY , USA, 2007. ACM.\n[10] B. Peters, H.-H Bui, S. Frankild, M. Nielson, C. Lundegaard, E. Kostem, D. Basch, K. Lamberth,\nM. Harndahl, W. Fleri, S. S Wilson, J. Sidney, O. Lund, S. Buus, and A. Sette. A community resource\nbenchmarking predictions of peptide binding to MHC-I molecules. PLoS Comput Biol, 2(6):e65, 2006.\n[11] D. Heckerman, D. Kadie, and J. Listgarten. Leveraging information across HLA alleles/supertypes im-\nproves epitope prediction. J. Comput. Biol., 14(6):736–746, 2007.\n[12] L. Jacob and J.-P. Vert. Efﬁcient peptide-MHC-I binding prediction for alleles with few known binders.\nBioinformatics, 24(3):358–366, Feb 2008.\n8",
  "values": {
    "Explicability": "Yes",
    "Critiqability": "Yes",
    "Collective influence": "Yes",
    "Beneficence": "Yes",
    "User influence": "Yes",
    "Interpretable (to users)": "Yes",
    "Not socially biased": "No",
    "Respect for Persons": "No",
    "Deferral to humans": "No",
    "Transparent (to users)": "No",
    "Fairness": "No",
    "Privacy": "No",
    "Justice": "No",
    "Autonomy (power to decide)": "No",
    "Non-maleficence": "No",
    "Respect for Law and public interest": "No"
  }
}