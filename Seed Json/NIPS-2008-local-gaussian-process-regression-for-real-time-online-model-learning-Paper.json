{
  "pdf": "NIPS-2008-local-gaussian-process-regression-for-real-time-online-model-learning-Paper",
  "title": "Local Gaussian Process Regression for Real Time Online Model Learning",
  "author": "Duy Nguyen-tuong, Jan R. Peters, Matthias Seeger",
  "paper_id": "NIPS-2008-local-gaussian-process-regression-for-real-time-online-model-learning-Paper",
  "text": "Local Gaussian Process Regression\nfor Real Time Online Model Learning and Control\nDuy Nguyen-Tuong Jan Peters Matthias Seeger\nMax Planck Institute for Biological Cybernetics\nSpemannstraße 38, 72076 T¨ubingen, Germany\n{duy,jan.peters,matthias.seeger}@tuebingen.mpg.de\nAbstract\nLearning in real-time applications, e.g., online approximation of the inverse dy-\nnamics model for model-based robot control, requires fast online regression tech-\nniques. Inspired by local learning, we propose a method to speed up standard\nGaussian process regression (GPR) with local GP models (LGP). The training\ndata is partitioned in local regions, for each an individual GP model is trained.\nThe prediction for a query point is performed by weighted estimation using nearby\nlocal models. Unlike other GP approximations, such as mixtures of experts, we\nuse a distance based measure for partitioning of the data and weighted prediction.\nThe proposed method achieves online learning and prediction in real-time. Com-\nparisons with other non-parametric regression methods show that LGP has higher\naccuracy than LWPR and close to the performance of standard GPR andν-SVR.\n1 Introduction\nPrecise models of technical systems can be crucial in technical applications. Especially in robot\ntracking control, only a well-estimated inverse dynamics model can allow both high accuracy and\ncompliant control. For complex robots such as humanoids or light-weight arms, it is often hard to\nmodel the system sufﬁciently well and, thus, modern regression methods offer a viable alternative\n[7,8]. For most real-time applications, online model learning poses a difﬁcult regression problem due\nto three constraints, i.e., ﬁrstly, the learning and prediction process should be very fast (e.g., learning\nneeds to take place at a speed of 20-200Hz and prediction at 200Hz to a 1000Hz). Secondly, the\nlearning system needs to be capable at dealing with large amounts of data (i.e., with data arriving\nat 200Hz, less than ten minutes of runtime will result in more than a million data points). And,\nthirdly, the data arrives as a continuous stream, thus, the model has to be continuously adapted to\nnew training examples over time.\nThese problems have been addressed by real-time learning methods such as locally weighted pro-\njection regression (LWPR) [7,8]. Here, the true function is approximated with local linear functions\ncovering the relevant state-space and online learning became computationally feasible due to low\ncomputational demands of the local projection regression which can be performed in real-time. The\nmajor drawback of LWPR is the required manual tuning of many highly data-dependent metaparam-\neters [15]. Furthermore, for complex data, large numbers of linear models are necessary in order to\nachieve a competitive approximation.\nA powerful alternative for accurate function approximation in high-dimensional space is Gaussian\nprocess regression (GPR) [1]. Since the hyperparameters of a GP model can be adjusted by maxi-\nmizing the marginal likelihood, GPR requires little effort and is easy and ﬂexible to use. However,\nthe main limitation of GPR is that the computational complexity scales cubically with the training\nexamplesn. This drawback prevents GPR from applications which need large amounts of training\ndata and require fast computation, e.g., online learning of inverse dynamics model for model-based\n1\nrobot control. Many attempts have been made to alleviate this problem, for example, (i) sparse\nGaussian process (SGP) [2], and (ii) mixture of experts (ME) [3, 4]. In SGP, the training data is\napproximated by a smaller set of so-called inducing inputs [2,5]. Here, the difﬁculty is to choose an\nappropriate set of inducing inputs, essentially replacing the full data set [2]. In contrast to SGP, ME\ndivide the input space in smaller subspaces by a gating network, within which a Gaussian process\nexpert, i.e., Gaussian local model, is trained [4, 6]. The computational cost is then signiﬁcantly re-\nduced due to much smaller number of training examples within a local model. The ME performance\ndepends largely on the way of partitioning the training data and the choice of an optimal number of\nlocal models for a particular data set [4].\nIn this paper, we combine the basic idea behind both approaches, i.e., LWPR and GPR, attempting\nto get as close as possible to the speed of local learning while having a comparable accuracy to\nGaussian process regression. This results in an approach inspired by [6, 8] using many local GPs in\norder to obtain a signiﬁcant reduction of the computational cost during both prediction and learning\nstep allowing the application to online learning. For partitioning the training data, we use a dis-\ntance based measure, where the corresponding hyperparameters are optimized by maximizing the\nmarginal likelihood.\nThe remainder of the paper is organized as follows: ﬁrst, we give a short review of standard GPR in\nSection 2. Subsequently, we describe our local Gaussian process models (LGP) approach in Section\n3 and discuss how it inherits the advantages of both GPR and LWPR. Furthermore, the learning\naccuracy and performance of our LGP approach will be compared with other important standard\nmethods in Section 4, e.g., LWPR [8], standard GPR [1], sparse online Gaussian process regression\n(OGP) [5] and ν-support vector regression (ν-SVR) [11], respectively. Finally, our LGP method is\nevaluated for an online learning of the inverse dynamics models of real robots for accurate tracking\ncontrol in Section 5. Here, the online learning is demonstrated by rank-one update of the local GP\nmodels [9]. The tracking task is performed in real-time using model-based control [10]. To our best\nknowledge, it is the ﬁrst time that GPR is successfully used for high-speed online model learning\nin real time control on a physical robot. We present the results on a version of the Barrett W AM\nshowing that with the online learned model using LGP the tracking accuracy is superior compared\nto state-of-the art model-based methods [10] while remaining fully compliant.\n2 Regression with standard GPR\nGiven a set of n training data points {xi,y i}n\ni=1, we would like to learn a function f(xi) trans-\nforming the input vector xi into the target value yi given byyi =f(xi)+ϵi , where ϵi is Gaussian\nnoise with zero mean and variance σ2\nn [1]. As a result, the observed targets can also be described\nby y∼N\n(\n0, K(X, X) +σ2\nnI\n)\n, where K(X, X) denotes the covariance matrix. As covariance\nfunction, a Gaussian kernel is frequently used [1]\nk (xp, xq)=σ2\nsexp\n(\n−1\n2(xp−xq)T W(xp−xq)\n)\n, (1)\nwhere σ2\ns denotes the signal variance and W are the widths of the Gaussian kernel. The joint\ndistribution of the observed target values and predicted value for a query point x∗ is given by\n[\ny\nf(x∗)\n]\n∼N\n(\n0,\n[\nK(X, X) +σ2\nnI k (X, x∗)\nk(x∗, X) k(x∗, x∗)\n])\n. (2)\nThe conditional distribution yields the predicted mean valuef(x∗) with the corresponding variance\nV (x∗) [1]\nf(x∗) = kT\n∗\n(\nK +σ2\nnI\n)−1\ny = kT\n∗ α,\nV (x∗) =k(x∗, x∗)− kT\n∗\n(\nK +σ2\nnI\n)−1\nk∗,\n(3)\nwith k∗ = k(X, x∗), K = K(X, X) and α denotes the so-called prediction vector. The hyperpa-\nrameters of a Gaussian process with Gaussian kernel are θ = [σ2\nn,σ 2\nf, W] and their optimal value\nfor a particular data set can be derived by maximizing the log marginal likelihood using common\noptimization procedures, e.g., Quasi-Newton methods [1].\n2\nInput: new data point{x,y}.\nfork =1 to number of local models do\nCompute distance to thek-th local model:\nwk =exp(−0.5(x− ck)T W(x− ck))\nend for\nTake the nearest local model:\nv = max(wk)\nifv >wgen then\nInsert{x,y} to nearest local model:\nXnew =[ X, x]\nynew =[ y,y ]\nUpdate corresponding center:\ncnew = mean(Xnew)\nCompute inverse covariance matrix and\nprediction vector of local model:\nKnew = K(Xnew, Xnew)\nαnew = (Knew +σ2I)−1ynew\nelse\nCreate new model:\nck+1 = x,\nXk+1 =[ x], yk+1 =[y]\nInitialization new inverse covariance ma-\ntrix and new prediction vector.\nend if\nAlgorithm 1: Partitioning of training data and\nmodel learning.\nInput: query data point x,M .\nDetermineM local models next to x.\nfork = 1 toM do\nCompute distance to thek-th local model:\nwk =exp(−0.5(x− ck)T W(x− ck))\nCompute local mean using the k-th local\nmodel:\n¯yk = kT\nk αk\nend for\nCompute weighted prediction usingM local\nmodels:\nˆy =∑M\nk=1wk¯yk/∑M\nk=1wk .\nAlgorithm 2: Prediction for a query point.\n(a) SARCOS arm\n (b) Barrett W AM\nFigure 1: Robot arms used for data generation\nand evaluation.\n3 Approximation using Local GP Models\nThe major limitation of GPR is the expensive computation of the inverse matrix(K+σ2\nnI)−1 which\nyields a cost of O(n3). Reducing this computational cost, we cluster the training data in local\nregions and, subsequently, train the corresponding GP models on these local clusters. The mean\nprediction for a query point is then made by weighted prediction using the nearby local models\nin the neighborhood. Thus, the algorithm consists out of two stages: (i) localization of data, i.e.,\nallocation of new input points and learning of corresponding local models, (ii) prediction for a query\npoint.\n3.1 Partitioning and Training of Local Models\nClustering input data is efﬁciently performed by considering a distance measure of the input pointx\nto the centers of all local models. The distance measure wk is given by the kernel used to learn the\nlocal GP models, e.g., Gaussian kernel\nwk = exp\n(\n−1\n2 (x− ck)T W (x− ck)\n)\n, (4)\nwhere ck denotes the center of thek-th local model and W a diagonal matrix represented the kernel\nwidth. It should be noted, that we use thesame kernel width for computingwk as well as for training\nof all local GP models as given in Section 2. The kernel width W is obtained by maximizing the\nlog likelihood on a subset of the whole training data points. For doing so, we subsample the training\ndata and, subsequently, perform an optimization procedure.\nDuring the localization process, a new model with centerck+1 is created, if all distance measureswk\nfall below a limit valuewgen. The new data point x is then set as new centerck+1. Thus, the number\nof local models is allowed to increase as the trajectories become more complex. Otherwise, if a new\npoint is assigned to a particulark-th model, the center ck is updated as mean of corresponding local\n3\ndata points. With the new assigned input point, the inverse covariance matrix of the corresponding\nlocal model can be updated. The localization procedure is summarized in Algorithm 1.\nThe main computational cost of this algorithm is O(N 3) for inverting the local covariance matrix,\nwhere N presents the number of data points in a local model. Furthermore, we can control the\ncomplexity by limiting the number of data points in a local model. Since the number of local data\npoints increases continuously over time, we can adhere to comply with this limit by deleting old data\npoint as new ones are included. Insertion and deletion of data points can be decided by evaluating\nthe information gain of the operation. The cost for inverting the local covariance matrix can be\nfurther reduced, as we need only to update the full inverse matrix once it is computed. The update\ncan be efﬁciently performed in a stable manner using rank-one update [9] which has a complexity\nofO(N 2).\n3.2 Prediction using Local Models\nThe prediction for a mean value ˆy is performed using weighted averaging over M local predic-\ntions ¯yk for a query point x [8]. The weighted prediction ˆy is then given by ˆy = E{¯yk|x} =∑M\nk=1 ¯ykp(k|x). According to the Bayesian theorem, the probability of the modelk given x can be\nexpressed asp(k|x)=p(k, x)/∑M\nk=1p(k, x)=wk/∑M\nk=1wk. Hence, we have\nˆy =\n∑M\nk=1wk¯yk\n∑M\nk=1wk\n. (5)\nThe probability p(k|x) can be interpreted as a normalized distance of the query point x to the\nlocal model k where the measure metric wk is used as given in Equation (4). Thus, each local\nprediction ¯yk, determined using Equation (3), is additionally weighted by the distance wk between\nthe corresponding center ck and the query point x. The search for M local models can be quickly\ndone by evaluating the distances between the query pointx and all model centers ck. The prediction\nprocedure is summarized in Algorithm 2.\n4 Learning Inverse Dynamics\nWe have evaluated our algorithm using high-dimensional robot data taken from real robots, e.g.,\nthe 7 degree-of-freedom (DoF) anthropomorphic SARCOS master arm and 7-DoF Barrett whole\narm manipulator shown in Figure 1, as well as a physically realistic SL simulation [12]. We com-\npare the learning performance of LGP with the state-of-the-art in non-parametric regression, e.g.,\nLWPR,ν-SVR, OGP and standard GPR in the context of approximating inverse robot dynamics.\nFor evaluatingν-SVR and GPR, we have employed the libraries [13] and [14].\n4.1 Dynamics Learning Accuracy Comparison\nFor the comparison of the accuracy of our method in the setting of learning inverse dynamics, we\nuse three data sets, (i) SL simulation data (SARCOS model) as described in [15] (14094 training\npoints, 5560 test points), (ii) data from the SARCOS master arm (13622 training points, 5500 test\npoints) [8], (iii) a data set generated from our Barrett arm (13572 training points, 5000 test points).\nGiven samples x=[ q, ˙ q, ¨ q] as input, where q, ˙ q, ¨ qdenote the joint angles, velocity and acceleration,\nand using the corresponding joint torques y = [u] as targets, we have a proper regression problem.\nFor the considered 7 degrees of freedom robot arms, we, thus, have data with 21 input dimensions\n(for each joint, we have an angle, a velocity and an acceleration) and 7 targets (a torque for each\njoint). We learn the robot dynamics model in this 21-dim space for each DoF separately employing\nLWPR,ν-SVR, GPR, OGP and LGP, respectively.\nPartitioning of the training examples for LGP can be performed either in the same input space (where\nthe model is learned) or in another space which has to be physically consistent with the approximated\nfunction. In the following, we localize the data depending on the position of the robot. Thus, the\npartitioning of training data is performed in a 7-dim space (7 joint angles). After determining wk\nfor allk local models in the partitioning space, the input point will be assigned to the nearest local\nmodel, i.e., the local model with the maximal value of distance measurewk.\n4\n1 2 3 4 5 6 70\n0.01\n0.02\n0.03\n0.04\n0.05\nDegree of Freedom\nnMSE\n \n \nLWPR\nOGP\nν−SVR\nGPR\nLGP\n(a) Approximation Error us-\ning SL data (SARCOS model)\n1 2 3 4 5 6 70\n0.01\n0.02\n0.03\n0.04\n0.05\n0.06\n0.07\nDegree of Freedom\nnMSE\n \n \nLWPR\nOGP\nν−SVR\nGPR\nLGP\n(b) Approximation Error us-\ning SARCOS data\n1 2 3 4 5 6 70\n0.05\n0.1\n0.15\n0.2\n0.25\nDegree of Freedom\nnMSE\n \n \nLWPR\nOGP\nν−SVR\nGPR\nLGP\n(c) Approximation Error us-\ning Barrett W AM data\nFigure 2: Approximation error as nMSE for each DoF. The error is computed after prediction on\nthe test sets with simulated data from SL Sarcos-model, real robot data from Barrett and SARCOS\nmaster arm, respectively. In most cases, LGP outperforms LWPR and OGP in learning accuracy\nwhile being competitive toν-SVR and standard GPR. It should be noted that the nMSE depends on\nthe target variances. Due to smaller variances in the Barrett data, the corresponding nMSE has also\na larger scale compared to SARCOS.\nFigure 2 shows the normalized mean squared error (nMSE) of the evaluation on the test set for each\nof the three evaluated scenarios, i.e., the simulated SARCOS arm in (a), the real SARCOS arm in\n(b) and the Barrett arm in (c). Here, the normalized mean squared error is deﬁned as nMSE =\nMean squared error/Variance of target. During the prediction on the test set using LGP, we take the\nmost activated local models, i.e., the ones which are next to the query point.\n0 5000 10000 15000\n1\n2\n3\n4\n5\n67\nNr. of Training Points\nPrediction Time [ms] (log. Scale)\n \n \nLWPR\nν−SVR\nGPR\nLGP\nFigure 3: Average time in millisecond needed for\nprediction of 1 query point. The computation time\nis plotted logarithmic in respect of the number of\ntraining examples. The time as stated above is the\nrequired time for prediction of all 7 DoF. Here,\nLWPR presents the fastest method due to simple\nregression models. Compared to global regression\nmethods such as standard GPR and ν-SVR, local\nGP makes signiﬁcant improvement in term of pre-\ndiction time.\nIt should be noted that the choice of the limit\nvaluewgen during the partitioning step is cru-\ncial for the performance of LGP and, unfortu-\nnately, is an open parameter. If wgen is too\nsmall, a lot of local models will be generated\nwith small number of training points. It turns\nout that these small local models do not per-\nform well in generalization for unknown data.\nIfwgen is large, the local models become also\nlarge which increase the computational com-\nplexity. Here, the training data are clustered\nin about 30 local regions ensuring that each lo-\ncal model has a sufﬁcient amount of data points\nfor high accuracy (in practice, roughly a hun-\ndred data points for each local model sufﬁce)\nwhile having sufﬁciently few that the solution\nremains feasible in real-time (on our current\nhardware, a Core Duo at 2GHz, that means less\nthan 1000 data points). On average, each lo-\ncal model has approximately 500 training ex-\namples. This small number of training inputs\nenables a fast training for each local model, i.e.,\nthe matrix inversion. For estimating the hyper-\nparameters using likelihood optimization, we\nsubsample the training data which results in a\nsubset of about 1000 data points.\nConsidering the approximation error on the test set shown in Figure 2(a-c), it can be seen that\nLGP generalizes well using only few local models for prediction. In all cases, LGP outperforms\nLWPR and OGP while being close in learning accuracy to global methods such as GPR and ν-\nSVR. The mean-prediction for GPR is determined according to Equation (3) where we precomputed\n5\nthe prediction vector α from training data. When a query point appears, the kernel vector kT\n∗ is\nevaluated for this particular point. The operation of mean-prediction has then the order ofO(n) for\nstandard GPR (similarly, for ν-SVR) andO(NM ) for LGP, where n denotes the total number of\ntraining points,M number of local models andN number of data points in a local model.\n4.2 Comparison of Computation Speed for Prediction\nBeside the reduction of training time (i.e., matrix inversion), the prediction time is also reduced\nsigniﬁcantly compared to GPR andν-SVR due to the fact that only a small amount of local models\nin the vicinity of the query point are needed during prediction for LGP. Thus, the prediction time\ncan be controlled by the number of local models. A large number of local models may provide a\nsmooth prediction but on the other hand increases the time complexity.\nThe comparison of prediction speed is shown in Figure 3. Here, we train LWPR, ν-SVR, GPR\nand LGP on 5 different data sets with increasing training examples (1065, 3726, 7452, 10646 and\n14904 data points, respectively). Subsequently, using the trained models we compute the average\ntime needed to make a prediction for a query point for all 7 DoF. For LGP, we take a limited number\nof local models in the vicinity for prediction, e.g., M = 3. Since our control system requires a\nminimal prediction rate at 100 Hz (10 ms) in order to ensure system stability, data sets with more\nthan 15000 points are not applicable for standard GPR orν-SVR due to high computation demands\nfor prediction.\nThe results show that the computation time requirements of ν-SVR and GPR rises very fast with\nthe size of training data set as expected. LWPR remains the best method in terms of computational\ncomplexity only increasing at a very low speed. However, as shown in Figure 3, the cost for LGP is\nsigniﬁcantly lower than the oneν-SVR and GPR and increases at a much lower rate. In practice, we\ncan also curb the computation demands of single models by deleting old data points, if a new ones are\nassigned to the model. As approach to deleting and inserting data points, we can use the information\ngain of the corresponding local model as a principled measure. It can be seen from the results that\nLGP represents a compromise between learning accuracy and computational complexity. For large\ndata sets (e.g., more than 5000 training examples), LGP reduces the prediction cost considerably\nwhile keeping a good learning performance.\n5 Application in Model-based Robot Control\nLocal GP Robot\n¨qd\n˙qd\nqd\nKvKp\n∑\n∑\n∑\n+\n+ +\n−\n−+\n+\nu\nq˙q\n∑\nFigure 4: Schematic showing model-based robot\ncontrol. The learned dynamics model can be up-\ndated online using LGP.\nIn this section, ﬁrst, we use the inverse dynam-\nics models learned in Section 4.1 for a model-\nbased tracking control task [10] in the setting\nshown in Figure 4. Here, the learned model\nof the robot is applied for an online predic-\ntion of the feedforward torques uFF given the\ndesired trajectory [qd, ˙ qd, ¨ qd]. Subsequently,\nthe model approximated by LGP is used for\nan online learning performance. Demonstrat-\ning the online learning, the local GP models are\nadapted in real-time using rank-one update.\nAs shown in Figure 4, the controller command\nu consists of the feedforward part uFF and the\nfeedback part uFB = Kpe + Kv ˙ e, where e =\nqd− q denotes the tracking error and Kp, Kv\nposition-gain and velocity-gain, respectively.\nDuring the control experiment we set the gains\nto very low values taking the aim of compliant\ncontrol into account. As a result, the learned\nmodel has a stronger effect on computing the predicted torque uFF and, hence, a better learning\nperformance of each method results in a lower tracking error.\nFor comparison with the learned models, we also compute the feedforward torque using rigid-body\n(RB) formulation which is a common approach in robot control [10]. The control task is performed\n6\n1 2 3 4 5 6 70\n0.02\n0.04\n0.06\n0.08\n0.1\n0.12\nDegree of Freedom\nRMSE\n \n \nRBD\nLWPR\nν−SVR\nGPR\nLGP offline\n(a) Tracking Error on Barrett without on-\nline learning\n1 2 3 4 5 6 70\n0.01\n0.02\n0.03\n0.04\n0.05\n0.06\n0.07\nDegree of Freedom\nRMSE\n \n \nLGP offline\nGPR\nLGP online\n(b) Tracking Error after LGP online\nlearning on Barrett\nFigure 5: (a) Tracking error as RMSE on test trajectory for each DoF with Barrett W AM. (b) Track-\ning error after online learning with LGP. The model uncertainty is reduced with online learning\nusing LGP. With online learning, LGP is able to outperform ofﬂine learned models using standard\nGPR for test trajectories.\nin real-time on the Barrett W AM, as shown in Figure 1. As desired trajectory, we generate a test\ntrajectory which is similar to the one used for learning the inverse dynamics models in Section 4.1.\nFigure 5 (a) shows the tracking errors on test trajectory for 7 DoFs, where the error is computed as\nroot mean squared error (RMSE). Here, LGP provides a competitive control performance compared\nto GPR while being superior to LWPR and the state-of-the art rigid-body model. It can be seen that\nfor several DoFs the tracking errors are large, for example 5., 6. and 7. DoF. The reason is that for\nthese DoFs the unknown nonlinearities are time-dependent, e.g., gear drive for 7. DoF, which can\nnot be approximated well using just one ofﬂine learned model. Since it is not possible to learn the\ncomplete state space using a single data set, online learning is necessary.\n5.1 Online Learning of Inverse Dynamics Models with LGP\nThe ability of online adaptation of the learned inverse dynamics models with LGP is shown by the\nrank-one update of the local models which has a complexity of O(n2) [9]. Since the number of\ntraining examples in each local model is limited (500 points in average), the update procedure is fast\nenough for real-time application. For online learning the models are updated as shown in Figure 4.\nFor doing so, we regularly sample the joint torques u and the corresponding robot trajectories\n[q, ˙ q, ¨ q] online. For the time being, as a new point is inserted we randomly delete another data\npoint from the local model if the maximal number of data point is reached. The process of insertion\nand deletion of data points can be further improved by considering the information gain (and infor-\nmation lost) of the operation. Figure 5 (b) shows the tracking error after online learning with LGP.\nIt can be seen that the errors for each DoF are signiﬁcantly reduced with online LGP compared to\nthe ones with ofﬂine learned models. With online learning, LGP is also able to outperform standard\nGPR.\n6 Conclusion\nWe combine with LGP the fast computation of local regression with more accurate regression meth-\nods while having little tuning efforts. LGP achieves higher learning accuracy compared to locally\nlinear methods such as LWPR while having less computational cost compared to GPR and ν-SVR.\nThe reducing cost allows LGP for model online learning which is necessary in oder to generalize\nthe model for all trajectories. Model-based tracking control using online learned model achieves su-\nperior control performance compared to the state-of-the-art method as well as ofﬂine learned model\nfor unknown trajectories.\n7\nReferences\n[1] C. E. Rasmussen and C. K. Williams, Gaussian Processes for Machine Learning . Mas-\nsachusetts Institute of Technology: MIT-Press, 2006.\n[2] J. Q. Candela and C. E. Rasmussen, “A unifying view of sparse approximate gaussian process\nregression,” Journal of Machine Learning Research, 2005.\n[3] V . Treps, “Mixtures of gaussian process,”Advances in Neural Information Processing Systems,\n2001.\n[4] C. E. Rasmussen and Z. Ghahramani, “Inﬁnite mixtures of gaussian process experts,”Advances\nin Neural Information Processing Systems, 2002.\n[5] L. Csato and M. Opper, “Sparse online gaussian processes,” Neural Computation, 2002.\n[6] E. Snelson and Z. Ghahramani, “Local and global sparse gaussian process approximations,”\nArtiﬁcial Intelligence and Statistics, 2007.\n[7] S. Schaal, C. G. Atkeson, and S. Vijayakumar, “Scalable techniques from nonparameteric\nstatistics for real-time robot learning,” Applied Intelligence, pp. 49–60, 2002.\n[8] S. Vijayakumar, A. D’Souza, and S. Schaal, “Incremental online learning in high dimensions,”\nNeural Computation, 2005.\n[9] M. Seeger, “Low rank update for the cholesky decomposition,” Tech. Rep., 2007. [Online].\nAvailable: http://www.kyb.tuebingen.mpg.de/bs/people/seeger/\n[10] J. J. Craig, Introduction to Robotics: Mechanics and Control, 3rd ed. Prentice Hall, 2004.\n[11] B. Sch ¨olkopf and A. Smola, Learning with Kernels: Support Vector Machines, Regularization,\nOptimization and Beyond. Cambridge, MA: MIT-Press, 2002.\n[12] S. Schaal, “The SL simulation and real-time control software package,” Tech. Rep., 2006.\n[Online]. Available: http://www-clmc.usc.edu/publications/S/schaal-TRSL.pdf\n[13] C.-C. Chang and C.-J. Lin, LIBSVM: a library for support vector machines , 2001,\nhttp://www.csie.ntu.edu.tw/ cjlin/libsvm.\n[14] M. Seeger, LHOTSE: Toolbox for Adaptive Statistical Model , 2007,\nhttp://www.kyb.tuebingen.mpg.de/bs/people/seeger/lhotse/.\n[15] D. Nguyen-Tuong, J. Peters, and M. Seeger, “Computed torque control with nonparametric\nregression models,” Proceedings of the 2008 American Control Conference (ACC 2008), 2008.\n8",
  "values": {
    "Transparent (to users)": "Yes",
    "Critiqability": "Yes",
    "Interpretable (to users)": "Yes",
    "Explicability": "Yes",
    "Non-maleficence": "Yes",
    "Respect for Law and public interest": "Yes",
    "Respect for Persons": "Yes",
    "Autonomy (power to decide)": "Yes",
    "Not socially biased": "Yes",
    "User influence": "Yes",
    "Beneficence": "Yes",
    "Fairness": "Yes",
    "Privacy": "Yes",
    "Deferral to humans": "Yes",
    "Justice": "No",
    "Collective influence": "No"
  }
}