{
  "pdf": "NIPS-2008-online-metric-learning-and-fast-similarity-search-Paper",
  "title": "Online Metric Learning and Fast Similarity Search",
  "author": "Prateek Jain, Brian Kulis, Inderjit S. Dhillon, Kristen Grauman",
  "paper_id": "NIPS-2008-online-metric-learning-and-fast-similarity-search-Paper",
  "text": "Online Metric Learning and Fast Similarity Search\nPrateek Jain, Brian Kulis, Inderjit S. Dhillon, and Kristen G rauman\nDepartment of Computer Sciences\nUniversity of Texas at Austin\nAustin, TX 78712\n{pjain,kulis,inderjit,grauman}@cs.utexas.edu\nAbstract\nMetric learning algorithms can provide useful distance functions for a variety\nof domains, and recent work has shown good accuracy for problems where the\nlearner can access all distance constraints at once. However, in many real appli-\ncations, constraints are only available incrementally, thus necessitating methods\nthat can perform online updates to the learned metric. Existing online algorithms\noffer bounds on worst-case performance, but typically do not perform well in\npractice as compared to their ofﬂine counterparts. We present a new online metric\nlearning algorithm that updates a learned Mahalanobis metric based on LogDet\nregularization and gradient descent. We prove theoretical worst-case performance\nbounds, and empirically compare the proposed method against existing online\nmetric learning algorithms. To further boost the practicality of our approach, we\ndevelop an online locality-sensitive hashing scheme which leads to efﬁcient up-\ndates to data structures used for fast approximate similarity search. We demon-\nstrate our algorithm on multiple datasets and show that it outperforms relevant\nbaselines.\n1 Introduction\nA number of recent techniques address the problem of metric learning, in which a distance function\nbetween data objects is learned based on given (or inferred) similarity constraints between exam-\nples [4, 7, 11, 16, 5, 15]. Such algorithms have been applied to a variety of real-world learning\ntasks, ranging from object recognition and human body pose estimation [5, 9], to digit recogni-\ntion [7], and software support [4] applications. Most successful results have relied on having access\nto all constraints at the onset of the metric learning. However, in many real applications, the desired\ndistance function may need to change gradually over time as additional information or constraints\nare received. For instance, in image search applications on the internet, online click-through data\nthat is continually collected may impact the desired distance function. To address this need, recent\nwork on online metric learning algorithms attempts to handle constraints that are received one at a\ntime [13, 4]. Unfortunately, current methods suffer from a number of drawbacks, including speed,\nbound quality, and empirical performance.\nFurther complicating this scenario is the fact that fast retrieval methods must be in place on top\nof the learned metrics for many applications dealing with large-scale databases. For example, in\nimage search applications, relevant images within very large collections must be quickly returned\nto the user, and constraints and user queries may often be intermingled across time. Thus a good\nonline metric learner must also be able to support fast similarity search routines. This is problematic\nsince existing methods (e.g., locality-sensitive hashing [6, 1] or kd-trees) assume a static distance\nfunction, and are expensive to update when the underlying distance function changes.\n1\nThe goal of this work is to make metric learning practical for r eal-world learning tasks in which both\nconstraints and queries must be handled efﬁciently in an online manner. To that end, we ﬁrst develop\nan online metric learning algorithm that uses LogDet regularization and exact gradient descent. The\nnew algorithm is inspired by the metric learning algorithm studied in [4]; however, while the loss\nbounds for the latter method are dependent on the input data, our loss bounds are independent of\nthe sequence of constraints given to the algorithm. Furthermore, unlike the Pseudo-metric Online\nLearning Algorithm (POLA) [13], another recent online technique, our algorithm requires no eigen-\nvector computation, making it considerably faster in practice. We further show how our algorithm\ncan be integrated with large-scale approximate similarity search. We devise a method to incremen-\ntally update locality-sensitive hash keys during the updates of the metric learner, making it possible\nto perform accurate sub-linear time nearest neighbor searches over the data in an online manner.\nWe compare our algorithm to related existing methods using a variety of standard data sets. We\nshow that our method outperforms existing approaches, and even performs comparably to several\nofﬂine metric learning algorithms. To evaluate our approach for indexing a large-scale database, we\ninclude experiments with a set of 300,000 image patches; our online algorithm effectively learns to\ncompare patches, and our hashing construction allows accurate fast retrieval for online queries.\n1.1 Related Work\nA number of recent techniques consider the metric learning problem [16, 7, 11, 4, 5]. Most work\ndeals with learning Mahalanobis distances in an ofﬂine manner, which often leads to expensive opti-\nmization algorithms. The POLA algorithm [13], on the other hand, is an approach for online learning\nof Mahalanobis metrics that optimizes a large-margin objective and has provable regret bounds, al-\nthough eigenvector computation is required at each iteration to enforce positive deﬁniteness, which\ncan be slow in practice. The information-theoretic metric learning method of [4] includes an on-\nline variant that avoids eigenvector decomposition. However, because of the particular form of the\nonline update, positive-deﬁniteness still must be carefully enforced, which impacts bound quality\nand empirical performance, making it undesirable for both theoretical and practical purposes. In\ncontrast, our proposed algorithm has strong bounds, requires no extra work for enforcing positive\ndeﬁniteness, and can be implemented efﬁciently. There are a number of existing online algorithms\nfor other machine learning problems outside of metric learning, e.g. [10, 2, 12].\nFast search methods are becoming increasingly necessary for machine learning tasks that must cope\nwith large databases. Locality-sensitive hashing [6] is an effective technique that performs approx-\nimate nearest neighbor searches in time that is sub-linear in the size of the database. Most existing\nwork has considered hash functions for Lp norms [3], inner product similarity [1], and other stan-\ndard distances. While recent work has shown how to generate hash functions for (ofﬂine) learned\nMahalanobis metrics [9], we are not aware of any existing technique that allows incremental updates\nto locality-sensitive hash keys for online database maintenance, as we propose in this work.\n2 Online Metric Learning\nIn this section we introduce our model for online metric learning, develop an efﬁcient algorithm to\nimplement it, and prove regret bounds.\n2.1 Formulation and Algorithm\nAs in several existing metric learning methods, we restrict ourselves to learning a Mahalanobis\ndistance function over our input data, which is a distance function parameterized by ad × d positive\ndeﬁnite matrix A. Given d-dimensional vectors u and v, the squared Mahalanobis distance between\nthem is deﬁned as\ndA(u, v) = ( u − v)T A(u − v).\nPositive deﬁniteness of A assures that the distance function will return positive distances. We may\nequivalently view such distance functions as applying a linear transformation to the input data and\ncomputing the squared Euclidean distance in the transformed space; this may be seen by factorizing\nthe matrix A = GT G, and distributing G into the (u − v) terms.\nIn general, one learns a Mahalanobis distance by learning the appropriate positive deﬁnite matrix A\nbased on constraints over the distance function. These constraints are typically distance or similarity\nconstraints that arise from supervised information—for example, the distance between two points\nin the same class should be “small”. In contrast to ofﬂine approaches, which assume all constraints\n2\nare provided up front, online algorithms assume that constra ints are received one at a time. That\nis, we assume that at time step t, there exists a current distance function parameterized by At. A\nconstraint is received, encoded by the triple (ut, vt, y t), where yt is the target distance between ut\nand vt (we restrict ourselves to distance constraints, though other constraints are possible). Using\nAt, we ﬁrst predict the distance ˆyt = dAt (ut, vt) using our current distance function, and incur a\nloss ℓ(ˆyt, y t). Then we update our matrix from At to At+1. The goal is to minimize the sum of\nthe losses over all time steps, i.e. LA = ∑\nt ℓ(ˆyt, y t). One common choice is the squared loss:\nℓ(ˆyt, y t) = 1\n2 ( ˆyt − yt)2. We also consider a variant of the model where the input is a quadruple\n(ut, vt, y t, b t), where bt = 1 if we require that the distance between ut and vt be less than or equal\nto yt, and bt = −1 if we require that the distance between ut and vt be greater than or equal to yt.\nIn that case, the corresponding loss function is ℓ(ˆyt, y t, b t) = max(0 , 1\n2 bt( ˆyt − yt))2.\nA typical approach [10, 4, 13] for the above given online learning problem is to solve for At+1 by\nminimizing a regularized loss at each step:\nAt+1 = argmin\nA≻ 0\nD(A, A t) + ηℓ (dA(ut, vt), y t), (2.1)\nwhere D(A, A t) is a regularization function and η t > 0 is the regularization parameter. As in [4],\nwe use the LogDet divergence Dℓd (A, A t) as the regularization function. It is deﬁned over positive\ndeﬁnite matrices and is given by Dℓd (A, A t) = tr(AA− 1\nt ) − log det(AA− 1\nt ) − d. This divergence\nhas previously been shown to be useful in the context of metric learning [4]. It has a number\nof desirable properties for metric learning, including scale-invariance, automatic enforcement of\npositive deﬁniteness, and a maximum-likelihood interpretation.\nExisting approaches solve for At+1 by approximating the gradient of the loss function, i.e.\nℓ ′(dA(ut, vt), y t) is approximated by ℓ ′(dAt (ut, vt), y t) [10, 13, 4]. While for some regulariza-\ntion functions (e.g. Frobenius divergence, von-Neumann divergence) such a scheme works out well,\nfor LogDet regularization it can lead to non-deﬁnite matrices for which the regularization function\nis not even deﬁned. This results in a scheme that has to adapt the regularization parameter in order\nto maintain positive deﬁniteness [4].\nIn contrast, our algorithm proceeds by exactly solving for the updated parameters At+1 that mini-\nmize (2.1). Since we use the exact gradient, our analysis will become more involved; however, the\nresulting algorithm will have several advantages over existing methods for online metric learning.\nUsing straightforward algebra and the Sherman-Morrison inverse formula, we can show that the\nresulting solution to the minimization of (2.1) is:\nAt+1 = At − η (¯y − yt)AtztzT\nt At\n1 + η ( ¯ y − yt)zT\nt Atzt\n, (2.2)\nwhere zt = ut − vt and ¯y = dAt+1(ut, vt) = zT\nt At+1zt. The detailed derivation will appear in\na longer version. It is not immediately clear that this update can be applied, since ¯y is a function\nof At+1. However, by multiplying the update in (2.2) on the left by zT\nt and on the right by zt and\nnoting that ˆyt = zT\nt Atzt, we obtain the following:\n¯y = ˆyt − η (¯y − yt)ˆy2\nt\n1 + η ( ¯ y − yt)ˆyt\n, and so ¯y = ηy t ˆyt − 1 +\n√\n(η y t ˆyt − 1)2 + 4η ˆy2\nt\n2η ˆyt\n. ( 2.3)\nWe can solve directly for ¯y using this formula, and then plug this into the update (2.2). For the case\nwhen the input is a quadruple and the loss function is the squared hinge loss, we only perform the\nupdate (2.2) if the new constraint is violated.\nIt is possible to show that the resulting matrix At+1 is positive deﬁnite; the proof appears in our\nlonger version. The fact that this update maintains positive deﬁniteness is a key advantage of our\nmethod over existing methods; POLA, for example, requires projection to the positive semideﬁnite\ncone via an eigendecomposition. The ﬁnal loss bound in [4] depends on the regularization parameter\nη t from each iteration and is in turn dependent on the sequence of constraints, an undesirable prop-\nerty for online algorithms. In contrast, by minimizing the function ft we designate above in (2.1),\nour algorithm’s updates automatically maintain positive deﬁniteness. This means that the regulariza-\ntion parameter η need not be changed according to the current constraint, and the resulting bounds\n(Section 2.2) and empirical performance are notably stronger.\n3\nWe refer to our algorithm as LogDet Exact Gradient Online (LEG O), and use this name throughout\nto distinguish it from POLA [13] (which uses a Frobenius regularization) and the Information The-\noretic Metric Learning (ITML)-Online algorithm [4] (which uses an approximation to the gradient).\n2.2 Analysis\nWe now brieﬂy analyze the regret bounds for our online metric learning algorithm. Due to space\nissues, we do not present the full proofs; please see the longer version for further details.\nTo evaluate the online learner’s quality, we want to compare the loss of the online algorithm (which\nhas access to one constraint at a time in sequence) to the loss of the best possible ofﬂine algorithm\n(which has access to all constraints at once). Let ˆdt = dA∗ (ut, vt) be the learned distance between\npoints ut and vt with a ﬁxed positive deﬁnite matrix A∗, and let LA∗ = ∑\nt ℓ( ˆdt, y t) be the loss\nsuffered over all t time steps. Note that the loss LA∗ is with respect to a single matrix A∗, whereas\nLA (Section 2.1) is with respect to a matrix that is being updated every time step. Let A∗ be the\noptimal ofﬂine solution, i.e. it minimizes total loss incurred ( LA∗). The goal is to demonstrate that\nthe loss of the online algorithmLA is competitive with the loss of any ofﬂine algorithm. To that end,\nwe now show that LA ≤ c1LA∗ + c2, where c1 and c2 are constants.\nIn the result below, we assume that the length of the data points is bounded: ∥u∥2\n2 ≤ R for all u.\nThe following key lemma shows that we can bound the loss at each step of the algorithm:\nLemma 2.1. At each step t,\n1\n2 α t( ˆyt − yt)2 − 1\n2 β t(dA∗ (ut, vt) − yt)2 ≤ Dl d(A∗, A t) − Dld(A∗, A t+1),\nwhere 0 ≤ α t ≤ η\n1+η\n(\nR\n2 +\nq\nR2\n4 + 1\nη\n) 2 , β t = η ,\nand A∗ is the optimal ofﬂine solution.\nProof. See longer version.\nTheorem 2.2.\nLA ≤\n(\n1\n+ η\n( R\n2 +\n√\nR2\n4 + 1\nη\n) 2)\nLA∗ +\n( 1\nη +\n( R\n2 +\n√\nR2\n4 + 1\nη\n) 2)\nDl d(A∗, A 0),\nwhere LA = ∑\nt ℓ(ˆyt, y t) is the loss incurred by the series of matrices At generated by Equa-\ntion (2.3), A0 ≻ 0 is the initial matrix, and A∗ is the optimal ofﬂine solution.\nProof. The bound is obtained by summing the loss at each step using Lemma 2.1:\n∑\nt\n( 1\n2 α t( ˆyt − yt)2 − 1\n2 β t(dA∗ (ut, vt) − yt)2\n)\n≤\n∑\nt\n(\nDl d(A∗, A t) − Dld(A∗, A t+1)\n)\n.\nThe result follows by plugging in the appropriate α t and β t, and observing that the right-hand side\ntelescopes to Dld(A∗, A 0) − Dld(A∗, A t+1) ≤ Dld(A∗, A 0) since Dld(A∗, A t+1) ≥ 0.\nFor the squared hinge loss ℓ( ˆyt, y t, b t) = max(0 , b t(ˆyt − yt))2, the corresponding algorithm has the\nsame bound.\nThe regularization parameter affects the tradeoff between LA∗ and Dld(A∗, A 0): as η gets larger,\nthe coefﬁcient of LA∗ grows while the coefﬁcient of Dld(A∗, A 0) shrinks. In most scenarios,\nR is small; for example, in the case when R = 2 and η = 1 , then the bound is LA ≤\n(4 +\n√\n2)LA∗ + 2(4 +\n√\n2)Dl d(A∗, A 0). Furthermore, in the case when there exists an ofﬂine\nsolution with zero error, i.e., LA∗ = 0 , then with a sufﬁciently large regularization parameter, we\nknow that LA ≤ 2R2Dld(A∗, A 0). This bound is analogous to the bound proven in Theorem 1 of\nthe POLA method [13]. Note, however, that our bound is much more favorable to scaling of the op-\ntimal solution A∗, since the bound of POLA has a ∥A∗∥2\nF term while our bound uses Dld(A∗, A 0):\nif we scale the optimal solution byc, then the Dld(A∗, A 0) term will scale by O(c), whereas ∥A∗∥2\nF\nwill scale by O(c2). Similarly, our bound is tighter than that provided by the ITML-Online algo-\nrithm since, in the ITML-Online algorithm, the regularization parameter η t for step t is dependent\non the input data. An adversary can always provide an input (ut, vt, y t) so that the regularization\n4\nparameter has to be decreased arbitrarily; that is, the need t o maintain positive deﬁninteness for each\nupdate can prevent ITML-Online from making progress towards an optimal metric.\nIn summary, we have proven a regret bound for the proposed LEGO algorithm, an online metric\nlearning algorithm based on LogDet regularization and gradient descent. Our algorithm automati-\ncally enforces positive deﬁniteness every iteration and is simple to implement. The bound is compa-\nrable to POLA’s bound but is more favorable to scaling, and is stronger than ITML-Online’s bound.\n3 Fast Online Similarity Searches\nIn many applications, metric learning is used in conjunction with nearest-neighbor searching, and\ndata structures to facilitate such searches are essential. For online metric learning to be practical\nfor large-scale retrieval applications, we must be able to efﬁciently index the data as updates to the\nmetric are performed. This poses a problem for most fast similarity searching algorithms, since each\nupdate to the online algorithm would require a costly update to their data structures.\nOur goal is to avoid expensive naive updates, where all database items are re-inserted into the search\nstructure. We employ locality-sensitive hashing to enable fast queries; but rather than re-hash all\ndatabase examples every time an online constraint alters the metric, we show how to incorporate\na second level of hashing that determines which hash bits are changing during the metric learning\nupdates. This allows us to avoid costly exhaustive updates to the hash keys, though occasional\nupdating is required after substantial changes to the metric are accumulated.\n3.1 Background: Locality-Sensitive Hashing\nLocality-sensitive hashing (LSH) [6, 1] produces a binary hash key H(u) = [ h1(u)h2(u)...h b(u)]\nfor every data point. Each individual bit hi(u) is obtained by applying the locality sensitive hash\nfunction hi to input u. To allow sub-linear time approximate similarity search for a similarity\nfunction ‘sim’, a locality-sensitive hash function must satisfy the following property: P r[hi(u) =\nhi(v)] = sim(u, v), where ‘sim’ returns values between 0 and 1. This means that the more similar\nexamples are, the more likely they are to collide in the hash table.\nA LSH function when ‘sim’ is the inner product was developed in [1], in which a hash bit is the sign\nof an input’s inner product with a random hyperplane. For Mahalanobis distances, the similarity\nfunction of interest is sim(u, v) = uT Av. The hash function in [1] was extended to accommodate\na Mahalanobis similarity function in [9]: A can be decomposed as GT G, and the similarity function\nis then equivalently ˜uT ˜v, where ˜u = Gu and ˜v = Gv. Hence, a valid LSH function for uT Av is:\nhr,A (u) =\n{\n1, if rT Gu ≥ 0\n0, otherwise, (3.1)\nwhere r is the normal to a random hyperplane. To perform sub-linear time nearest neighbor searches,\na hash key is produced for all n data points in our database. Given a query, its hash key is formed\nand then, an appropriate data structure can be used to extract potential nearest neighbors (see [6, 1]\nfor details). Typically, the methods search only O(n1/(1+ ǫ )) of the data points, where ǫ > 0, to\nretrieve the (1 + ǫ)-nearest neighbors with high probability.\n3.2 Online Hashing Updates\nThe approach described thus far is not immediately amenable to online updates. We can imagine\nproducing a series of LSH functions hr1,A , ..., h rb,A , and storing the corresponding hash keys for\neach data point in our database. However, the hash functions as given in (3.1) are dependent on the\nMahalanobis distance; when we update our matrix At to At+1, the corresponding hash functions,\nparameterized by Gt, must also change. To update all hash keys in the database would require\nO(nd) time, which may be prohibitive. In the following we propose a more efﬁcient approach.\nRecall the update for A: At+1 = At − η (¯y− yt)AtztzT\nt At\n1+η ( ¯ y− yt)ˆyt\n, which we will write as At+1 = At +\nβ tAtztzT\nt At, where β t = −η (¯y − yt)/ (1 + η (¯y − yt)ˆyt). Let GT\nt Gt = At. Then At+1 =\nGT\nt (I + β tGtztzT\nt GT\nt )Gt. The square-root of I + β tGtztzT\nt GT\nt is I + α tGtztzT\nt GT\nt , where\nα t = (\n√\n1 + β tzT\nt Atzt− 1 )/ (zT\nt Atzt). As a result, Gt+1 = Gt+α tGtztzT\nt At. The corresponding\nupdate to (3.1) is to ﬁnd the sign of\nrT Gt+1x = rT Gtu + α trT GtztzT\nt Atu. (3.2)\n5\nSuppose that the hash functions have been updated in full at so me time step t1 in the past.\nNow at time t, we want to determine which hash bits have ﬂipped since t1, or more pre-\ncisely, which examples’ product with some rT Gt has changed from positive to negative, or vice\nversa. This amounts to determining all bits such that sign (rT Gt1 u) ̸= sign(rT Gtu), or equiv-\nalently, (rT Gt1 u)(rT Gtu) ≤ 0. Expanding the update given in (3.2), we can write rT Gtu as\nrT Gt1 u + ∑t− 1\nℓ =t1 α ℓ rT Gℓ zℓ zT\nℓ Aℓ u. Therefore, ﬁnding the bits that have changed sign is equiva-\nlent to ﬁnding all u such that (rT Gt1 u)2 + (rT Gt1 u)\n( ∑t− 1\nℓ =t1 α ℓ rT Gℓ zℓ zT\nℓ Aℓ u\n)\n≤ 0. We can\nuse a second level of locality-sensitive hashing to approximately ﬁnd all such u. Deﬁne a vec-\ntor ¯u = [( rT Gt1u)2; (rT Gt1u)u] and a “query” ¯q = [ −1; − ∑t− 1\nℓ =t1 α ℓ rT Aℓ zℓ zT\nℓ Gℓ ]. Then the\nbits that have changed sign can be approximately identiﬁed by ﬁnding all examples ¯u such that\n¯qT ¯u ≥ 0. In other words, we look for all ¯u that have a large inner product with ¯q, which translates\nthe problem to a similarity search problem. This may be solved approximately using the locality-\nsensitive hashing scheme given in [1] for inner product similarity. Note that ﬁnding¯u for each r can\nbe computationally expensive, so we search ¯u for only a randomly selected subset of the vectors r.\nIn summary, when performing online metric learning updates, instead of updating all the hash keys\nat every step (which costs O(nd)), we delay updating the hash keys and instead determine approxi-\nmately which bits have changed in the stored entries in the hash table since the last update. When we\nhave a nearest-neighbor query, we can quickly determine which bits have changed, and then use this\ninformation to ﬁnd a query’s approximate nearest neighbors using the current metric. Once many of\nthe bits have changed, we perform a full update to our hash functions.\nFinally, we note that the above can be extended to the case where computations are done in kernel\nspace. We omit details due to lack of space.\n4 Experimental Results\nIn this section we evaluate the proposed algorithm (LEGO) over a variety of data sets, and examine\nboth its online metric learning accuracy as well as the quality of its online similarity search updates.\nAs baselines, we consider the most relevant techniques from the literature: the online metric learners\nPOLA [13] and ITML-Online [4]. We also evaluate a baseline ofﬂine metric learner associated with\nour method. For all metric learners, we gauge improvements relative to the original (non-learned)\nEuclidean distance, and our classiﬁcation error is measured with the k-nearest neighbor algorithm.\nFirst we consider the same collection of UCI data sets used in [4]. For each data set, we provide the\nonline algorithms with 10,000 randomly-selected constraints, and generate their target distances as\nin [4]—for same-class pairs, the target distance is set to be equal to the 5th percentile of all distances\nin the data, while for different-class pairs, the 95th percentile is used. To tune the regularization\nparameter η for POLA and LEGO, we apply a pre-training phase using 1,000 constraints. (This is not\nrequired for ITML-Online, which automatically sets the regularization parameter at each iteration\nto guarantee positive deﬁniteness). The ﬁnal metric (AT ) obtained by each online algorithm is used\nfor testing (T is the total number of time-steps). The left plot of Figure 1 shows the k-nn error rates\nfor all ﬁve data sets. LEGO outperforms the Euclidean baseline as well as the other online learners,\nand even approaches the accuracy of the ofﬂine method (see [4] for additional comparable ofﬂine\nlearning results using [7, 15]). LEGO and ITML-Online have comparable running times. However,\nour approach has a signiﬁcant speed advantage over POLA on these data sets: on average, learning\nwith LEGO is 16.6 times faster, most likely due to the extra projection step required by POLA.\nNext we evaluate our approach on a handwritten digit classiﬁcation task, reproducing the experiment\nused to test POLA in [13]. We use the same settings given in that paper. Using the MNIST data set,\nwe pose a binary classiﬁcation problem between each pair of digits (45 problems in all). The training\nand test sets consist of 10,000 examples each. For each problem, 1,000 constraints are chosen and\nthe ﬁnal metric obtained is used for testing. The center plot of Figure 1 compares the test error\nbetween POLA and LEGO. Note that LEGO beats or matches POLA’s test error in 33/45 (73.33%)\nof the classiﬁcation problems. Based on the additional baselines provided in [13], this indicates that\nour approach also fares well compared to other ofﬂine metric learners on this data set.\nWe next consider a set of image patches from the Photo Tourism project [14], where user photos\nfrom Flickr are used to generate 3-d reconstructions of various tourist landmarks. Forming the\nreconstructions requires solving for the correspondence between local patches from multiple images\nof the same scene. We use the publicly available data set that contains about 300,000 total patches\n6\nWine Iris Bal−Scale Ionosphere Soybean0\n0.05\n0.1\n0.15\n0.2\n0.25\n0.3\n0.35\n0.4\n0.45k−NN Error\nUCI data sets (order of bars = order of legend)\n \n \nITML Offline\nLEGO\nITML Online\nPOLA\nBaseline Euclidean\n0 0.005 0.01 0.015 0.02 0.025 0.03 0.035 0.040\n0.005\n0.01\n0.015\n0.02\n0.025\n0.03\n0.035\n0.04\nLEGO Error\nPOLA Error\nMNIST data set\n0 0.05 0.1 0.15 0.2 0.25 0.30.6\n0.65\n0.7\n0.75\n0.8\n0.85\n0.9\n0.95\n1\nFalse Positives\nTrue Positives\nPhotoTourism Dataset\nLEGO\nITML Offline\nPOLA\nITML Online\nBaseline Euclidean\nFigure 1: C omparison with existing online metric learning methods. Left: On the UCI data sets, our method\n(LEGO) outperforms both the Euclidean distance baseline as well as existing metric learning methods, and\neven approaches the accuracy of the ofﬂine algorithm. Center: Comparison of errors for LEGO and POLA\non 45 binary classiﬁcation problems using the MNIST data; LEGO matches or outperforms POLA on 33 of the\n45 total problems. Right: On the Photo Tourism data, our online algorithm signiﬁcantly outperforms the L2\nbaseline and ITML-Online, does well relative to POLA, and nearly matches the accuracy of the ofﬂine method.\nfrom images of three landmarks 1. Each patch has a dimensionality of 4096, so for efﬁciency we\napply all algorithms in kernel space, and use a linear kernel. The goal is to learn a metric that\nmeasures the distance between image patches better than L2, so that patches of the same 3-d scene\npoint will be matched together, and (ideally) others will not. Since the database is large, we can also\nuse it to demonstrate our online hash table updates. Following [8], we add random jitter (scaling,\nrotations, shifts) to all patches, and generate 50,000 patch constraints (50% matching and 50% non-\nmatching patches) from a mix of the Trevi and Halfdome images. We test with 100,000 patch pairs\nfrom the Notre Dame portion of the data set, and measure accuracy with precision and recall.\nThe right plot of Figure 1 shows that LEGO and POLA are able to learn a distance function that\nsigniﬁcantly outperforms the baseline squared Euclidean distance. However, LEGO is more accurate\nthan POLA, and again nearly matches the performance of the ofﬂine metric learning algorithm. On\nthe other hand, the ITML-Online algorithm does not improve beyond the baseline. We attribute\nthe poor accuracy of ITML-Online to its need to continually adjust the regularization parameter to\nmaintain positive deﬁniteness; in practice, this often leads to signiﬁcant drops in the regularization\nparameter, which prevents the method from improving over the Euclidean baseline. In terms of\ntraining time, on this data LEGO is 1.42 times faster than POLA (on average over 10 runs).\nFinally, we present results using our online metric learning algorithm together with our online hash\ntable updates described in Section 3.2 for the Photo Tourism data. For our ﬁrst experiment, we\nprovide each method with 50,000 patch constraints, and then search for nearest neighbors for 10,000\ntest points sampled from the Notre Dame images. Figure 2 (left plot) shows the recall as a function\nof the number of patches retrieved for four variations: LEGO with a linear scan, LEGO with our\nLSH updates, the L2 baseline with a linear scan, and L2 with our LSH updates. The results show\nthat the accuracy achieved by our LEGO+LSH algorithm is comparable to the LEGO+linear scan\n(and similarly, L2+LSH is comparable to L2+linear scan), thus validating the effectiveness of our\nonline hashing scheme. Moreover, LEGO+LSH needs to search only 10% of the database, which\ntranslates to an approximate speedup factor of 4.7 over the linear scan for this data set.\nNext we show that LEGO+LSH performs accurate and efﬁcient retrievals in the case where con-\nstraints and queries are interleaved in any order. Such a scenario is useful in many applications: for\nexample, an image retrieval system such as Flickr continually acquires new image tags from users\n(which could be mapped to similarity constraints), but must also continually support intermittent\nuser queries. For the Photo Tourism setting, it would be useful in practice to allow new constraints\nindicating true-match patch pairs to stream in while users continually add photos that should partic-\nipate in new 3-d reconstructions with the improved match distance functions. To experiment with\nthis scenario, we randomly mix online additions of 50,000 constraints with 10,000 queries, and mea-\nsure performance by the recall value for 300 retrieved nearest neighbor examples. We recompute the\nhash-bits for all database examples if we detect changes in more than 10% of the database examples.\nFigure 2 (right plot) compares the average recall value for various methods after each query. As\nexpected, as more constraints are provided, the LEGO-based accuracies all improve (in contrast to\nthe static L2 baseline, as seen by the straight line in the plot). Our method achieves similar accuracy\nto both the linear scan method (LEGO Linear) as well as the naive LSH method where the hash\ntable is fully recomputed after every constraint update (LEGO Naive LSH). The curves stack up\n1h ttp://phototour.cs.washington.edu/patches/default.htm\n7\n100 200 300 400 500 600 700 800 900 1000\n0.62\n0.64\n0.66\n0.68\n0.7\n0.72\n0.74\n0.76\n0.78\n0.8\nNumber of nearest neighbors (N)\nRecall\n \n \nL2 Linear Scan\nL2 LSH\nLEGO Linear Scan\nLEGO LSH\n0 2000 4000 6000 8000 100000.62\n0.64\n0.66\n0.68\n0.7\n0.72\n0.74\nNumber of queries\nAverage Recall\n \n \nLEGO LSH\nLEGO Linear Scan\nLEGO Naive LSH\nL2 Linear Scan\nFigure 2: R esults with online hashing updates. The left plot shows the recall value for increasing numbers of\nnearest neighbors retrieved. ‘LEGO LSH’ denotes LEGO metric learning in conjunction with online searches\nusing our LSH updates, ‘LEGO Linear’ denotes LEGO learning with linear scan searches. L2 denotes the\nbaseline Euclidean distance. The right plot shows the average recall values for all methods at different time\ninstances as more queries are made and more constraints are added. Our online similarity search updates make\nit possible to efﬁciently interleave online learning and querying. See text for details.\nappropriately given the levels of approximation: LEGO Linear yields the upper bound in terms of\naccuracy, LEGO Naive LSH with its exhaustive updates is slightly behind that, followed by our\nLEGO LSH with its partial and dynamic updates. In reward for this minor accuracy loss, however,\nour method provides a speedup factor of 3.8 over the naive LSH update scheme. (In this case the\nnaive LSH scheme is actually slower than a linear scan, as updating the hash tables after every update\nincurs a large overhead cost.) For larger data sets, we can expect even larger speed improvements.\nConclusions: We have developed an online metric learning algorithm together with a method to\nperform online updates to fast similarity search structures, and have demonstrated their applicability\nand advantages on a variety of data sets. We have proven regret bounds for our online learner that\noffer improved reliability over state-of-the-art methods in terms of regret bounds, and empirical\nperformance. A disadvantage of our algorithm is that the LSH parameters, e.g. ǫ and the number of\nhash-bits, need to be selected manually, and may depend on the ﬁnal application. For future work,\nwe hope to tune the LSH parameters automatically using a deeper theoretical analysis of our hash\nkey updates in conjunction with the relevant statistics of the online similarity search task at hand.\nAcknowledgments: This research was supported in part by NSF grant CCF-0431257, NSF-\nITR award IIS-0325116, NSF grant IIS-0713142, NSF CAREER award 0747356, Microsoft\nResearch, and the Henry Luce Foundation.\nReferences\n[1] M. Charikar. Similarity Estimation Techniques from Rounding Algorithms. In STOC, 2002.\n[2] L. Cheng, S. V . N. Vishwanathan, D. Schuurmans, S. Wang, and T. Caelli. Implicit Online Learning with\nKernels. In NIPS, 2006.\n[3] M. Datar, N. Immorlica, P. Indyk, and V . Mirrokni. Locality-Sensitive Hashing Scheme Based on p-Stable\nDistributions. In SOCG, 2004.\n[4] J. Davis, B. Kulis, P. Jain, S. Sra, and I. Dhillon. Information-Theoretic Metric Learning. In ICML, 2007.\n[5] A. Frome, Y . Singer, and J. Malik. Image retrieval and classiﬁcation using local distance functions. In\nNIPS, 2007.\n[6] A. Gionis, P. Indyk, and R. Motwani. Similarity Search in High Dimensions via Hashing. InVLDB, 1999.\n[7] A. Globerson and S. Roweis. Metric Learning by Collapsing Classes. In NIPS, 2005.\n[8] G. Hua, M. Brown, and S. Winder. Discriminant embedding for local image descriptors. In ICCV, 2007.\n[9] P. Jain, B. Kulis, and K. Grauman. Fast Image Search for Learned Metrics. In CVPR, 2008.\n[10] J. Kivinen and M. K. Warmuth. Exponentiated Gradient Versus Gradient Descent for Linear Predictors.\nInf. Comput., 132(1):1–63, 1997.\n[11] M. Schultz and T. Joachims. Learning a Distance Metric from Relative Comparisons. In NIPS, 2003.\n[12] S. Shalev-Shwartz and Y . Singer. Online Learning meets Optimization in the Dual. In COLT, 2006.\n[13] S. Shalev-Shwartz, Y . Singer, and A. Ng. Online and Batch Learning of Pseudo-metrics. In ICML, 2004.\n[14] N. Snavely, S. Seitz, and R. Szeliski. Photo Tourism: Exploring Photo Collections in 3D. In SIGGRAPH\nConference Proceedings, pages 835–846, New York, NY , USA, 2006. ACM Press. ISBN 1-59593-364-6.\n[15] K. Weinberger, J. Blitzer, and L. Saul. Distance Metric Learning for Large Margin Nearest Neighbor\nClassiﬁcation. In NIPS, 2006.\n[16] E. Xing, A. Ng, M. Jordan, and S. Russell. Distance Metric Learning, with Application to Clustering with\nSide-Information. In NIPS, 2002.\n8",
  "values": {
    "Interpretable (to users)": "Yes",
    "Respect for Law and public interest": "Yes",
    "Privacy": "Yes",
    "Transparent (to users)": "Yes",
    "Not socially biased": "Yes",
    "Non-maleficence": "Yes",
    "Explicability": "Yes",
    "User influence": "Yes",
    "Respect for Persons": "Yes",
    "Autonomy (power to decide)": "Yes",
    "Beneficence": "Yes",
    "Critiqability": "Yes",
    "Collective influence": "Yes",
    "Justice": "Yes",
    "Fairness": "Yes",
    "Deferral to humans": "Yes"
  }
}