{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b876796",
   "metadata": {},
   "source": [
    "\n",
    "# Automatic Detection of Moral Values in Research Papers\n",
    "\n",
    "This notebook implements an end-to-end pipeline for **automatic detection of moral values** in AI/ML research papers.\n",
    "\n",
    "**Pipeline Overview**\n",
    "1. Load annotated JSON papers  \n",
    "2. Tokenize text using RoBERTa  \n",
    "3. Train a multi-label classifier  \n",
    "4. Evaluate moral vs non-moral predictions  \n",
    "5. Visualize results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb43f249",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Environment Setup\n",
    "Run this cell once in a fresh environment (e.g., Google Colab).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b685571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install -q transformers==4.45.2 datasets==2.19.1 scikit-learn torch evaluate pandas seaborn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bc2e4d",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3181107f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df2634b",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Moral Values Schema\n",
    "\n",
    "The model predicts **16 moral values** adopted from Birhane et al. (2022).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e88adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MORAL_VALUES = [\n",
    "    \"Interpretable (to users)\", \"Transparent (to users)\", \"Privacy\", \"Fairness\",\n",
    "    \"Not socially biased\", \"User influence\", \"Collective influence\",\n",
    "    \"Deferral to humans\", \"Critiqability\", \"Beneficence\", \"Non-maleficence\",\n",
    "    \"Justice\", \"Respect for Persons\", \"Autonomy (power to decide)\",\n",
    "    \"Explicability\", \"Respect for Law and public interest\"\n",
    "]\n",
    "\n",
    "IDX = {v: i for i, v in enumerate(MORAL_VALUES)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3b7b65",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Load Training Data (JSON Files)\n",
    "\n",
    "Each JSON file contains extracted paper text and Yes/No annotations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f8173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "JSON_DIR = Path(\"data/seed_json\") \n",
    "\n",
    "examples = []\n",
    "for fp in JSON_DIR.glob(\"*.json\"):\n",
    "    d = json.load(open(fp, encoding=\"utf-8\"))\n",
    "    text = d.get(\"text\", \"\").strip()\n",
    "    if not text:\n",
    "        continue\n",
    "\n",
    "    labels = np.zeros(len(MORAL_VALUES), dtype=np.float32)\n",
    "    for k, v in d.get(\"values\", {}).items():\n",
    "        if k in IDX and str(v).lower() == \"yes\":\n",
    "            labels[IDX[k]] = 1.0\n",
    "\n",
    "    examples.append({\"text\": text, \"labels\": labels.tolist()})\n",
    "\n",
    "print(\"Total training examples:\", len(examples))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9c3258",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Trainâ€“Validation Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeaf2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data, val_data = train_test_split(\n",
    "    examples, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_ds = Dataset.from_list(train_data)\n",
    "val_ds = Dataset.from_list(val_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5289d6a",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Tokenization (RoBERTa Base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16c00d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_NAME = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True, max_length=512)\n",
    "\n",
    "train_ds = train_ds.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "val_ds = val_ds.map(tokenize, batched=True, remove_columns=[\"text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddad0e61",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Model Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80672171",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(MORAL_VALUES),\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"outputs\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=2e-5,\n",
    "    report_to=[]\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer)\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b5caca",
   "metadata": {},
   "source": [
    "\n",
    "## 8. Evaluation Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88048996",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred = trainer.predict(val_ds)\n",
    "probs = 1 / (1 + np.exp(-pred.predictions))\n",
    "preds = (probs >= 0.5).astype(int)\n",
    "labels = pred.label_ids\n",
    "\n",
    "print(\"Micro Precision:\", precision_score(labels, preds, average=\"micro\"))\n",
    "print(\"Micro Recall   :\", recall_score(labels, preds, average=\"micro\"))\n",
    "print(\"Micro F1       :\", f1_score(labels, preds, average=\"micro\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a888067",
   "metadata": {},
   "source": [
    "\n",
    "## 9. Moral vs Non-Moral Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d539ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "true_bin = (labels.sum(axis=1) > 0).astype(int)\n",
    "pred_bin = (preds.sum(axis=1) > 0).astype(int)\n",
    "\n",
    "cm = confusion_matrix(true_bin, pred_bin)\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[\"Pred: Non-Moral\", \"Pred: Moral\"],\n",
    "            yticklabels=[\"True: Non-Moral\", \"True: Moral\"])\n",
    "plt.title(\"Moral vs Non-Moral Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09ce4c4",
   "metadata": {},
   "source": [
    "\n",
   
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
